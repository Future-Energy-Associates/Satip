{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Satip Documentation Site \u00b6 Satip is a library for sat ellite i mage p rocessing, and provides all of the functionality necessary for retrieving, transforming and storing EUMETSAT data This site provides user-guides, developer documentation and other information about the satip module Installation \u00b6 To install the satip library please run: pip install satip Development Set-Up \u00b6 To create a new environment you can follow the following code blocks or run the setup_env batch script located in the batch_scripts directory. git clone conda env create -f environment.yml conda activate sat_image_processing We'll also install Jupyter lab interactive plotting for matplotlib See the jupyter-matplotlib docs for more info . The short version is to run these commands from within the sat_image_processing env: jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter labextension install jupyter-matplotlib Publishing to PyPi \u00b6 To publish the satip module to PyPi simply run the following from the batch_scripts directory pypi_publish <anaconda_dir> Where <anaconda_dir> is the path to your anaconda directory - e.g. C:\\Users\\User\\anaconda3 When prompted you should enter your PyPi username and password After this you will be able to install the latest version of satip using pip install satip Pipeline \u00b6 To run the dagster pipeline for continuous data retrieval you can use: dagster pipeline execute -m satip.mario -c pipeline_inputs.yaml","title":"Home"},{"location":"#welcome-to-the-satip-documentation-site","text":"Satip is a library for sat ellite i mage p rocessing, and provides all of the functionality necessary for retrieving, transforming and storing EUMETSAT data This site provides user-guides, developer documentation and other information about the satip module","title":"Welcome to the Satip Documentation Site"},{"location":"#installation","text":"To install the satip library please run: pip install satip","title":"Installation"},{"location":"#development-set-up","text":"To create a new environment you can follow the following code blocks or run the setup_env batch script located in the batch_scripts directory. git clone conda env create -f environment.yml conda activate sat_image_processing We'll also install Jupyter lab interactive plotting for matplotlib See the jupyter-matplotlib docs for more info . The short version is to run these commands from within the sat_image_processing env: jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter labextension install jupyter-matplotlib","title":"Development Set-Up"},{"location":"#publishing-to-pypi","text":"To publish the satip module to PyPi simply run the following from the batch_scripts directory pypi_publish <anaconda_dir> Where <anaconda_dir> is the path to your anaconda directory - e.g. C:\\Users\\User\\anaconda3 When prompted you should enter your PyPi username and password After this you will be able to install the latest version of satip using pip install satip","title":"Publishing to PyPi"},{"location":"#pipeline","text":"To run the dagster pipeline for continuous data retrieval you can use: dagster pipeline execute -m satip.mario -c pipeline_inputs.yaml","title":"Pipeline"},{"location":"00_tests/","text":"Tests \u00b6 setup \u00b6 import os import dotenv import json import pandas as pd from pandas.util.testing import assert_frame_equal from satip import eumetsat, io, mario, reproj, usage, utils, gcp_helpers, cicd, backfill Need to set data directories (maybe this should be in a config file) data_dir = '../data/raw' compressed_dir = '../data/compressed' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' Need to load environment variables, as a lot of functionality won't work without some credentials dotenv.load_dotenv(env_vars_fp) user_key = os.environ.get('USER_KEY') user_secret = os.environ.get('USER_SECRET') slack_id = os.environ.get('SLACK_ID') slack_webhook_url = os.environ.get('SLACK_WEBHOOK_URL') 01_eumetsat \u00b6 def test_query_data_products(): \"\"\"Checks EUMETSAT API Looks for a data product from a search query, but does not check details. Expects to find one value in the time range. \"\"\" start_date = '2019-10-01T00:00:00' end_date = '2019-10-01T00:05:00' actual = eumetsat.query_data_products(start_date, end_date).json() a_id = actual['type'] a_results = actual['properties']['totalResults'] assert a_id == 'FeatureCollection' assert a_results == 1 def test_identify_available_datasets(): \"\"\"Checks count of available datasets for a timeframe is consistent\"\"\" start_date = '2020-01-01' end_date = '2020-02-01' actual = len(eumetsat.identify_available_datasets(start_date, end_date)) expected = 1548 assert actual == expected def test_DownloadManager_download(user_key, user_secret, data_dir, metadata_db_fp, debug_fp): \"\"\"Downloads 1 file from the EUMETSAT API and compares with saved data. Drops the 'downloaded' column which varies based on time of last download. \"\"\" dm = eumetsat.DownloadManager(user_key, user_secret, data_dir, metadata_db_fp, debug_fp) start_date = '2020-10-01 12:00' end_date = '2020-10-01 12:05' actual = dm.download_date_range(start_date, end_date).drop('downloaded', axis=1) expected = pd.DataFrame(data=[[pd.Timestamp('2020-10-01 12:00:09.607000+0000', tz='UTC'), pd.Timestamp('2020-10-01 12:04:15.953000+0000', tz='UTC'), pd.Timestamp('2020-10-01 12:04:15.953000+0000', tz='UTC'), 'MSG3', 'GEO', 'SEVIRI', 'RSS', 'EPSG:4326', '0 9.5', 'MSG3-SEVI-MSG15-0100-NA-20201001120415.953000000Z-NA', 99819, 0.0]], columns=['start_date', 'end_date', 'result_time', 'platform_short_name','platform_orbit_type', 'instrument_name', 'sensor_op_mode', 'center_srs_name', 'center_position', 'file_name', 'file_size', 'missing_pct']) assert_frame_equal(actual, expected) Export \u00b6","title":"Tests"},{"location":"00_tests/#tests","text":"","title":"Tests"},{"location":"00_tests/#setup","text":"import os import dotenv import json import pandas as pd from pandas.util.testing import assert_frame_equal from satip import eumetsat, io, mario, reproj, usage, utils, gcp_helpers, cicd, backfill Need to set data directories (maybe this should be in a config file) data_dir = '../data/raw' compressed_dir = '../data/compressed' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' Need to load environment variables, as a lot of functionality won't work without some credentials dotenv.load_dotenv(env_vars_fp) user_key = os.environ.get('USER_KEY') user_secret = os.environ.get('USER_SECRET') slack_id = os.environ.get('SLACK_ID') slack_webhook_url = os.environ.get('SLACK_WEBHOOK_URL')","title":"setup"},{"location":"00_tests/#01_eumetsat","text":"def test_query_data_products(): \"\"\"Checks EUMETSAT API Looks for a data product from a search query, but does not check details. Expects to find one value in the time range. \"\"\" start_date = '2019-10-01T00:00:00' end_date = '2019-10-01T00:05:00' actual = eumetsat.query_data_products(start_date, end_date).json() a_id = actual['type'] a_results = actual['properties']['totalResults'] assert a_id == 'FeatureCollection' assert a_results == 1 def test_identify_available_datasets(): \"\"\"Checks count of available datasets for a timeframe is consistent\"\"\" start_date = '2020-01-01' end_date = '2020-02-01' actual = len(eumetsat.identify_available_datasets(start_date, end_date)) expected = 1548 assert actual == expected def test_DownloadManager_download(user_key, user_secret, data_dir, metadata_db_fp, debug_fp): \"\"\"Downloads 1 file from the EUMETSAT API and compares with saved data. Drops the 'downloaded' column which varies based on time of last download. \"\"\" dm = eumetsat.DownloadManager(user_key, user_secret, data_dir, metadata_db_fp, debug_fp) start_date = '2020-10-01 12:00' end_date = '2020-10-01 12:05' actual = dm.download_date_range(start_date, end_date).drop('downloaded', axis=1) expected = pd.DataFrame(data=[[pd.Timestamp('2020-10-01 12:00:09.607000+0000', tz='UTC'), pd.Timestamp('2020-10-01 12:04:15.953000+0000', tz='UTC'), pd.Timestamp('2020-10-01 12:04:15.953000+0000', tz='UTC'), 'MSG3', 'GEO', 'SEVIRI', 'RSS', 'EPSG:4326', '0 9.5', 'MSG3-SEVI-MSG15-0100-NA-20201001120415.953000000Z-NA', 99819, 0.0]], columns=['start_date', 'end_date', 'result_time', 'platform_short_name','platform_orbit_type', 'instrument_name', 'sensor_op_mode', 'center_srs_name', 'center_position', 'file_name', 'file_size', 'missing_pct']) assert_frame_equal(actual, expected)","title":"01_eumetsat"},{"location":"00_tests/#export","text":"","title":"Export"},{"location":"00_utils/","text":"Repository Helpers \u00b6 Loading Environment Variables \u00b6 First we'll load the the environment variables env_vars_fp = '../.env' dotenv.load_dotenv(env_vars_fp) slack_id = os.environ.get('slack_id') slack_webhook_url = os.environ.get('slack_webhook_url') Notebook Information \u00b6 We can now easily construct markdown tables notebook_info = { # development 'Utilities': { 'Directory': 'nbs', 'Number': '00', 'Description': 'Code for keeping the repository tidy', 'Maintainer': 'Ayrton Bourn' }, 'EUMETSAT': { 'Directory': 'nbs', 'Number': '01', 'Description': 'Development of the API wrapper for ems', 'Maintainer': 'Ayrton Bourn' }, 'Reprojection': { 'Directory': 'nbs', 'Number': '02', 'Description': 'Development of the reprojection operator', 'Maintainer': 'Ayrton Bourn' }, 'Zarr': { 'Directory': 'nbs', 'Number': '03', 'Description': 'Development of wrappers for loading/saving to Zarr', 'Maintainer': 'Ayrton Bourn' }, 'GCP': { 'Directory': 'nbs', 'Number': '04', 'Description': 'Development of GCP interface wrappers', 'Maintainer': 'Laurence Watson' }, 'Pipeline': { 'Directory': 'nbs', 'Number': '05', 'Description': 'Development of the pipeline processes', 'Maintainer': 'Ayrton Bourn' }, 'Downloading': { 'Directory': 'nbs', 'Number': '101', 'Description': 'Guidance for using the ems download manager', 'Maintainer': 'Ayrton Bourn' }, 'Reprojecting': { 'Directory': 'nbs', 'Number': '102', 'Description': 'Guidance for using the reprojection operator', 'Maintainer': 'Ayrton Bourn' }, 'Loading': { 'Directory': 'nbs', 'Number': '103', 'Description': 'Guidance for retrieving saved data from Zarr', 'Maintainer': 'Ayrton Bourn' }, 'Documentation': { 'Directory': 'docs', 'Number': '-', 'Description': 'Automated generation of docs from notebooks', 'Maintainer': 'Ayrton Bourn' }, } nb_table_str = create_markdown_table(notebook_info) print(nb_table_str) | Id | Directory | Number | Description | Maintainer | |:--------------|:------------|:---------|:---------------------------------------------------|:----------------| | utils | nbs | 00 | Code for keeping the repository tidy | Ayrton Bourn | | EUMETSAT | nbs | 01 | Development of the API wrapper for ems | Ayrton Bourn | | Reprojection | nbs | 02 | Development of the reprojection operator | Ayrton Bourn | | Zarr | nbs | 03 | Development of wrappers for loading/saving to Zarr | Ayrton Bourn | | GCP | nbs | 04 | Development of GCP interface wrappers | Laurence Watson | | Pipeline | nbs | 05 | Development of the pipeline processes | Ayrton Bourn | | Downloading | nbs | 101 | Guidance for using the ems download manager | Ayrton Bourn | | Reprojecting | nbs | 102 | Guidance for using the reprojection operator | Ayrton Bourn | | Loading | nbs | 103 | Guidance for retrieving saved data from Zarr | Ayrton Bourn | | Documentation | docs | - | Automated generation of docs from notebooks | Ayrton Bourn | Logging \u00b6 We'll now initialise the logger and make a test log logger = set_up_logging(__name__, '.', slack_id=slack_id, slack_webhook_url=slack_webhook_url) logger.log(logging.INFO, 'This will output to file and Jupyter but not to Slack as it is not critical') 2020-11-12 09:58:41,301 - INFO - This will output to file and Jupyter but not to Slack as it is not critical We'll now shutdown the logger handlers and then delete the log file we just made handlers = logger.handlers[:] for handler in handlers: handler.close() logger.removeHandler(handler) os.remove(f'{__name__}.txt') Finally we'll export the specified functions to the utils.py module","title":"Utilities"},{"location":"00_utils/#repository-helpers","text":"","title":"Repository Helpers"},{"location":"00_utils/#loading-environment-variables","text":"First we'll load the the environment variables env_vars_fp = '../.env' dotenv.load_dotenv(env_vars_fp) slack_id = os.environ.get('slack_id') slack_webhook_url = os.environ.get('slack_webhook_url')","title":"Loading Environment Variables"},{"location":"00_utils/#notebook-information","text":"We can now easily construct markdown tables notebook_info = { # development 'Utilities': { 'Directory': 'nbs', 'Number': '00', 'Description': 'Code for keeping the repository tidy', 'Maintainer': 'Ayrton Bourn' }, 'EUMETSAT': { 'Directory': 'nbs', 'Number': '01', 'Description': 'Development of the API wrapper for ems', 'Maintainer': 'Ayrton Bourn' }, 'Reprojection': { 'Directory': 'nbs', 'Number': '02', 'Description': 'Development of the reprojection operator', 'Maintainer': 'Ayrton Bourn' }, 'Zarr': { 'Directory': 'nbs', 'Number': '03', 'Description': 'Development of wrappers for loading/saving to Zarr', 'Maintainer': 'Ayrton Bourn' }, 'GCP': { 'Directory': 'nbs', 'Number': '04', 'Description': 'Development of GCP interface wrappers', 'Maintainer': 'Laurence Watson' }, 'Pipeline': { 'Directory': 'nbs', 'Number': '05', 'Description': 'Development of the pipeline processes', 'Maintainer': 'Ayrton Bourn' }, 'Downloading': { 'Directory': 'nbs', 'Number': '101', 'Description': 'Guidance for using the ems download manager', 'Maintainer': 'Ayrton Bourn' }, 'Reprojecting': { 'Directory': 'nbs', 'Number': '102', 'Description': 'Guidance for using the reprojection operator', 'Maintainer': 'Ayrton Bourn' }, 'Loading': { 'Directory': 'nbs', 'Number': '103', 'Description': 'Guidance for retrieving saved data from Zarr', 'Maintainer': 'Ayrton Bourn' }, 'Documentation': { 'Directory': 'docs', 'Number': '-', 'Description': 'Automated generation of docs from notebooks', 'Maintainer': 'Ayrton Bourn' }, } nb_table_str = create_markdown_table(notebook_info) print(nb_table_str) | Id | Directory | Number | Description | Maintainer | |:--------------|:------------|:---------|:---------------------------------------------------|:----------------| | utils | nbs | 00 | Code for keeping the repository tidy | Ayrton Bourn | | EUMETSAT | nbs | 01 | Development of the API wrapper for ems | Ayrton Bourn | | Reprojection | nbs | 02 | Development of the reprojection operator | Ayrton Bourn | | Zarr | nbs | 03 | Development of wrappers for loading/saving to Zarr | Ayrton Bourn | | GCP | nbs | 04 | Development of GCP interface wrappers | Laurence Watson | | Pipeline | nbs | 05 | Development of the pipeline processes | Ayrton Bourn | | Downloading | nbs | 101 | Guidance for using the ems download manager | Ayrton Bourn | | Reprojecting | nbs | 102 | Guidance for using the reprojection operator | Ayrton Bourn | | Loading | nbs | 103 | Guidance for retrieving saved data from Zarr | Ayrton Bourn | | Documentation | docs | - | Automated generation of docs from notebooks | Ayrton Bourn |","title":"Notebook Information"},{"location":"00_utils/#logging","text":"We'll now initialise the logger and make a test log logger = set_up_logging(__name__, '.', slack_id=slack_id, slack_webhook_url=slack_webhook_url) logger.log(logging.INFO, 'This will output to file and Jupyter but not to Slack as it is not critical') 2020-11-12 09:58:41,301 - INFO - This will output to file and Jupyter but not to Slack as it is not critical We'll now shutdown the logger handlers and then delete the log file we just made handlers = logger.handlers[:] for handler in handlers: handler.close() logger.removeHandler(handler) os.remove(f'{__name__}.txt') Finally we'll export the specified functions to the utils.py module","title":"Logging"},{"location":"01_eumetsat/","text":"EUMETSAT API Wrapper Development \u00b6 Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.31rows/s] User Input \u00b6 data_dir = '../data/raw' compressed_dir = '../data/compressed' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' download_data = True Authorising API Access \u00b6 First we'll load the the environment variables dotenv.load_dotenv(env_vars_fp) user_key = os.environ.get('USER_KEY') user_secret = os.environ.get('USER_SECRET') slack_id = os.environ.get('SLACK_ID') slack_webhook_url = os.environ.get('SLACK_WEBHOOK_URL') And test they were loaded successfully def check_env_vars_have_loaded(env_vars): for name, value in env_vars.items(): assert value is not None, f'{name}` should not be None' return env_vars = { 'user_key': user_key, 'user_secret': user_secret, 'slack_id': slack_id, 'slack_webhook_url': slack_webhook_url } check_env_vars_have_loaded(env_vars) We'll then use them to request an access token for the API We'll then use them to request an access token for the API access_token = request_access_token(user_key, user_secret) Querying Available Data \u00b6 Before we can download any data we have to know where it's stored. To learn this we can query their search-products API, which returns a JSON containing a list of file metadata. Dcumentation for the Swagger API endpoint can be found here: https://eumetsatspace.atlassian.net/wiki/spaces/DSDS/pages/316080237/Swagger+UI+OpenSearch+API We'll quickly make a test request to this end-point start_date = '2019-10-01' end_date = '2020-10-01' r = query_data_products(start_date, end_date) r_json = r.json() JSON(r_json) <IPython.core.display.JSON object> However the search-api is capped (at 10,000) for the number of files it will return metadata for, so we'll create a while loop that waits until all the relevant data has been returned. We'll then extract just the list of features from the returned JSONs. While the search-api returns max 10,000 results, using start-index etc doesn't seem to work for wide time searches, so we will need to do multiple queries. Also key to note the results are returned most recent first, so we must proceed backwards in iterations of 10,000 We'll check that the same number of available datasets are identified %%time start_date = '2020-01-01' end_date = '2020-04-01' datasets = identify_available_datasets(start_date, end_date) print(f'{len(datasets)} datasets have been identified') identify_available_datasets: found 18142 results from API 18142 datasets have been identified CPU times: user 940 ms, sys: 114 ms, total: 1.05 s Wall time: 6.2 s # JSON(datasets) Finally we'll create a helper function for converting the dataset ids into their file urls. We'll now test this works. N.b. You cannot use the link returned here directly as it will not be OAuth'ed dataset_ids = sorted([dataset['id'] for dataset in datasets]) example_data_link = dataset_id_to_link(dataset_ids[0]) example_data_link 'https://api.eumetsat.int/data/download/products/MSG2-SEVI-MSG15-0100-NA-20200303090418.826000000Z-NA' Downloading Data \u00b6 Now that we know where our data is located we want to download it. First we'll check that the directory we wish to save the data in exists, if not we'll create it for folder in [data_dir, compressed_dir]: if not os.path.exists(folder): os.makedirs(folder) We also want to extract the relevant metadata information from each file. Here we'll create a generalised framework for extracting data from any product, to add a new one please add its metadata mapping under the relevant product_id . We're now ready to create a download manager that will handle all of the querying, processing and retrieving for us We'll now see what it looks like when we initialise the download manager dm = DownloadManager(user_key, user_secret, data_dir, metadata_db_fp, debug_fp, slack_webhook_url=slack_webhook_url, slack_id=slack_id) start_date = '2020-10-01 12:00' end_date = '2020-10-01 12:05' if download_data == True: dm.download_date_range(start_date, end_date) df_metadata = dm.get_df_metadata() df_metadata.head() 2021-03-08 09:48:44,953 - INFO - ********** Download Manager Initialised ************** 2021-03-08 09:48:45,280 - INFO - 1 files queried, 0 found in ../data/raw, 1 to download. identify_available_datasets: found 1 results from API 0% 0/1 [0 < 0, 0.00s/it] The get_size function was adapted from this stackoverflow answer data_dir_size = get_dir_size(data_dir) print(f'The data directory is currently {round(data_dir_size/1_000_000_000, 2):,} Gb') Integration with Google Cloud Storage \u00b6 If Google Cloud Platform (GCP) flags are passed ( bucket_name and bucket_prefix ), when downloading, then the DownloadManager should first check to see if the files already exist in the specified cloud storage bucket. If the files already exist, then they will not be downloaded locally - if the storage bucket arguments are passed. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2020\" dm = DownloadManager(user_key, user_secret, data_dir, metadata_db_fp, debug_fp, bucket_name=BUCKET_NAME, bucket_prefix=PREFIX) # Bucket filenames can be accessed len(dm.bucket_filenames) Lets test this by examining some dates at the start of 2020 # Timings: around 2 hours to download 1 day. # DownloadManager should find these 2020 files on the VM start_date = '2020-01-01 00:00' end_date = '2020-01-01 00:02' dm.download_date_range(start_date, end_date) Name Convention changes in EUMETSAT files \u00b6 Probably due to the changes / creation of the EUMETSAT API around the end of 2019, newer files do not contain the previous 'order number' parts at the end of the filename. Some previously downloaded files follow a different file name convention: Files through new API: MSG3-SEVI-MSG15-0100-NA-20191001120415.883000000Z-NA.nat SatProgram-Instrument-SatNumber-AlgoVersion-InstrumentMode(?)-ReceptionStartDateUTC Files on GCP: MSG3-SEVI-MSG15-0100-NA-20191001120415.883000000Z-20191001120433-1399526-1.nat.bz2 SatProgram-Instrument-SatNumber-AlgoVersion-InstrumentMode(?)-ReceptionStartDateUTC-SensingStartDateUTC-OrderNumber-PartNumber We can use regex to take the first part of the filename for comparisons txt = \"MSG3-SEVI-MSG15-0100-NA-20190101000417.314000000Z-20190101000435-1377854-1.nat\" re.match(\"([A-Z\\d.]+-){6}\", txt)[0][:-1] # [:-1] to trim the trailing - To ensure we are comparing the same filenames, this regex is added into DownloadManager and the GCP helpers. Set up logging locally. debug_fp = '../logs/EUMETSAT_download.txt' log = utils.set_up_logging('EUMETSAT Processing', debug_fp) Helper utils \u00b6 For local testing, this command downloads some files from the Google Cloud bucket: # get test files from GCP - these are compressed # !gsutil cp -r gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/2019/10/01/00/04 ../data/raw Compress downloaded native image files \u00b6 Once files have been downloaded from the EUMETSAT API in some location, they need to be compressed and saved in a cloud storage bucket. First, see which files have already been downloaded locally to test this functionality. full_native_filenames = glob.glob(os.path.join(data_dir, '*.nat')) full_native_filenames We will compress locally downloaded files here using pbzip2 On ubuntu: sudo apt-get install -y pbzip2 On mac: brew install pbzip2 compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir) Syncing files to GCP Storage \u00b6 Compressed native files should be stored in a Google Cloud Storage Bucket. The folder structure follows the following convention: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/<year>/<month>/<day>/<hour>/<minute>/ # sync downloaded files in compressed_dir to the bucket BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/\"","title":"Downloading"},{"location":"01_eumetsat/#eumetsat-api-wrapper-development","text":"Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.31rows/s]","title":"EUMETSAT API Wrapper Development"},{"location":"01_eumetsat/#user-input","text":"data_dir = '../data/raw' compressed_dir = '../data/compressed' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' download_data = True","title":"User Input"},{"location":"01_eumetsat/#authorising-api-access","text":"First we'll load the the environment variables dotenv.load_dotenv(env_vars_fp) user_key = os.environ.get('USER_KEY') user_secret = os.environ.get('USER_SECRET') slack_id = os.environ.get('SLACK_ID') slack_webhook_url = os.environ.get('SLACK_WEBHOOK_URL') And test they were loaded successfully def check_env_vars_have_loaded(env_vars): for name, value in env_vars.items(): assert value is not None, f'{name}` should not be None' return env_vars = { 'user_key': user_key, 'user_secret': user_secret, 'slack_id': slack_id, 'slack_webhook_url': slack_webhook_url } check_env_vars_have_loaded(env_vars) We'll then use them to request an access token for the API We'll then use them to request an access token for the API access_token = request_access_token(user_key, user_secret)","title":"Authorising API Access"},{"location":"01_eumetsat/#querying-available-data","text":"Before we can download any data we have to know where it's stored. To learn this we can query their search-products API, which returns a JSON containing a list of file metadata. Dcumentation for the Swagger API endpoint can be found here: https://eumetsatspace.atlassian.net/wiki/spaces/DSDS/pages/316080237/Swagger+UI+OpenSearch+API We'll quickly make a test request to this end-point start_date = '2019-10-01' end_date = '2020-10-01' r = query_data_products(start_date, end_date) r_json = r.json() JSON(r_json) <IPython.core.display.JSON object> However the search-api is capped (at 10,000) for the number of files it will return metadata for, so we'll create a while loop that waits until all the relevant data has been returned. We'll then extract just the list of features from the returned JSONs. While the search-api returns max 10,000 results, using start-index etc doesn't seem to work for wide time searches, so we will need to do multiple queries. Also key to note the results are returned most recent first, so we must proceed backwards in iterations of 10,000 We'll check that the same number of available datasets are identified %%time start_date = '2020-01-01' end_date = '2020-04-01' datasets = identify_available_datasets(start_date, end_date) print(f'{len(datasets)} datasets have been identified') identify_available_datasets: found 18142 results from API 18142 datasets have been identified CPU times: user 940 ms, sys: 114 ms, total: 1.05 s Wall time: 6.2 s # JSON(datasets) Finally we'll create a helper function for converting the dataset ids into their file urls. We'll now test this works. N.b. You cannot use the link returned here directly as it will not be OAuth'ed dataset_ids = sorted([dataset['id'] for dataset in datasets]) example_data_link = dataset_id_to_link(dataset_ids[0]) example_data_link 'https://api.eumetsat.int/data/download/products/MSG2-SEVI-MSG15-0100-NA-20200303090418.826000000Z-NA'","title":"Querying Available Data"},{"location":"01_eumetsat/#downloading-data","text":"Now that we know where our data is located we want to download it. First we'll check that the directory we wish to save the data in exists, if not we'll create it for folder in [data_dir, compressed_dir]: if not os.path.exists(folder): os.makedirs(folder) We also want to extract the relevant metadata information from each file. Here we'll create a generalised framework for extracting data from any product, to add a new one please add its metadata mapping under the relevant product_id . We're now ready to create a download manager that will handle all of the querying, processing and retrieving for us We'll now see what it looks like when we initialise the download manager dm = DownloadManager(user_key, user_secret, data_dir, metadata_db_fp, debug_fp, slack_webhook_url=slack_webhook_url, slack_id=slack_id) start_date = '2020-10-01 12:00' end_date = '2020-10-01 12:05' if download_data == True: dm.download_date_range(start_date, end_date) df_metadata = dm.get_df_metadata() df_metadata.head() 2021-03-08 09:48:44,953 - INFO - ********** Download Manager Initialised ************** 2021-03-08 09:48:45,280 - INFO - 1 files queried, 0 found in ../data/raw, 1 to download. identify_available_datasets: found 1 results from API 0% 0/1 [0 < 0, 0.00s/it] The get_size function was adapted from this stackoverflow answer data_dir_size = get_dir_size(data_dir) print(f'The data directory is currently {round(data_dir_size/1_000_000_000, 2):,} Gb')","title":"Downloading Data"},{"location":"01_eumetsat/#integration-with-google-cloud-storage","text":"If Google Cloud Platform (GCP) flags are passed ( bucket_name and bucket_prefix ), when downloading, then the DownloadManager should first check to see if the files already exist in the specified cloud storage bucket. If the files already exist, then they will not be downloaded locally - if the storage bucket arguments are passed. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2020\" dm = DownloadManager(user_key, user_secret, data_dir, metadata_db_fp, debug_fp, bucket_name=BUCKET_NAME, bucket_prefix=PREFIX) # Bucket filenames can be accessed len(dm.bucket_filenames) Lets test this by examining some dates at the start of 2020 # Timings: around 2 hours to download 1 day. # DownloadManager should find these 2020 files on the VM start_date = '2020-01-01 00:00' end_date = '2020-01-01 00:02' dm.download_date_range(start_date, end_date)","title":"Integration with Google Cloud Storage"},{"location":"01_eumetsat/#name-convention-changes-in-eumetsat-files","text":"Probably due to the changes / creation of the EUMETSAT API around the end of 2019, newer files do not contain the previous 'order number' parts at the end of the filename. Some previously downloaded files follow a different file name convention: Files through new API: MSG3-SEVI-MSG15-0100-NA-20191001120415.883000000Z-NA.nat SatProgram-Instrument-SatNumber-AlgoVersion-InstrumentMode(?)-ReceptionStartDateUTC Files on GCP: MSG3-SEVI-MSG15-0100-NA-20191001120415.883000000Z-20191001120433-1399526-1.nat.bz2 SatProgram-Instrument-SatNumber-AlgoVersion-InstrumentMode(?)-ReceptionStartDateUTC-SensingStartDateUTC-OrderNumber-PartNumber We can use regex to take the first part of the filename for comparisons txt = \"MSG3-SEVI-MSG15-0100-NA-20190101000417.314000000Z-20190101000435-1377854-1.nat\" re.match(\"([A-Z\\d.]+-){6}\", txt)[0][:-1] # [:-1] to trim the trailing - To ensure we are comparing the same filenames, this regex is added into DownloadManager and the GCP helpers. Set up logging locally. debug_fp = '../logs/EUMETSAT_download.txt' log = utils.set_up_logging('EUMETSAT Processing', debug_fp)","title":"Name Convention changes in EUMETSAT files"},{"location":"01_eumetsat/#helper-utils","text":"For local testing, this command downloads some files from the Google Cloud bucket: # get test files from GCP - these are compressed # !gsutil cp -r gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/2019/10/01/00/04 ../data/raw","title":"Helper utils"},{"location":"01_eumetsat/#compress-downloaded-native-image-files","text":"Once files have been downloaded from the EUMETSAT API in some location, they need to be compressed and saved in a cloud storage bucket. First, see which files have already been downloaded locally to test this functionality. full_native_filenames = glob.glob(os.path.join(data_dir, '*.nat')) full_native_filenames We will compress locally downloaded files here using pbzip2 On ubuntu: sudo apt-get install -y pbzip2 On mac: brew install pbzip2 compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir)","title":"Compress downloaded native image files"},{"location":"01_eumetsat/#syncing-files-to-gcp-storage","text":"Compressed native files should be stored in a Google Cloud Storage Bucket. The folder structure follows the following convention: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/<year>/<month>/<day>/<hour>/<minute>/ # sync downloaded files in compressed_dir to the bucket BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/\"","title":"Syncing files to GCP Storage"},{"location":"02_reproj/","text":"Data Transformation \u00b6 #exports import json import pandas as pd import xarray as xr import numpy as np import numpy.ma as ma import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import colors import seaborn as sns import os import time from itertools import product from collections import OrderedDict from datetime import datetime from ipypb import track import FEAutils as hlp import satpy from satpy import Scene from satpy.readers import seviri_l1b_native import pyresample from pyresample.geometry import AreaDefinition try : import pyinterp import pyinterp.backends.xarray except : pass We'll separately install libraries that wont be needed for the satip module import rasterio from rasterio import Affine as A from rasterio.warp import reproject , Resampling , calculate_default_transform , transform from rasterio.control import GroundControlPoint from rasterio.transform import xy import geopandas as gpd from shapely.geometry import Point import cartopy.crs as ccrs from IPython.display import JSON User Input \u00b6 data_dir = '../data/raw' intermediate_data_dir = '../data/intermediate' calculate_reproj_coords = False Exploratory Data Analysis \u00b6 We'll start by identifying the available files native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fps [ 0 ] '../data/raw/MSG2-SEVI-MSG15-0100-NA-20201208090415.301000000Z-NA.nat' Then load one of them in as a SatPy scene native_fp = native_fps [ 0 ] scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) scene <satpy.scene.Scene at 0x294fae42e50> We can get a list of the available datasets (bands) scene . all_dataset_names () ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] Each band contains an XArray DataArray scene . load ([ 'HRV' ]) scene [ 'HRV' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'reshape-3b944f9ca9a40a223ab6382d90bfb37d' (y: 4176, x: 5568)> dask.array<mul, shape=(4176, 5568), dtype=float32, chunksize=(1392, 5568), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unknown\",E... * y (y) float64 1.395e+06 1.396e+06 1.397e+06 ... 5.57e+06 5.571e+06 * x (x) float64 3.164e+06 3.163e+06 3.162e+06 ... -2.402e+06 -2.403e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9697642568677852 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-9 sensor: seviri start_time: 2020-12-08 09:00:08.206321 end_time: 2020-12-08 09:05:08.329479 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'reshape-3b944f9ca9a40a223ab6382d90bfb37d' y : 4176 x : 5568 dask.array<chunksize=(1392, 5568), meta=np.ndarray> Array Chunk Bytes 93.01 MB 31.00 MB Shape (4176, 5568) (1392, 5568) Count 214 Tasks 3 Chunks Type float32 numpy.ndarray 5568 4176 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Geostationary Satellite (Sweep Y) Datum: unknown - Ellipsoid: unknown - Prime Meridian: Greenwich , dtype=object) y (y) float64 1.395e+06 1.396e+06 ... 5.571e+06 units : meter array([1395187.416673, 1396187.551022, 1397187.68537 , ..., 5568748.054504, 5569748.188853, 5570748.323202]) x (x) float64 3.164e+06 3.163e+06 ... -2.403e+06 units : meter array([ 3164425.079823, 3163424.945474, 3162424.811125, ..., -2401322.571635, -2402322.705984, -2403322.840333]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We can see that the DataArray contains a crs, however we'll make our own custom area definition that's more accurate. First we'll create a helper function that will create our area definitions. #exports def calculate_x_offset ( native_fp ): handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) lower_east_column_planned = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] x_offset = 32500 + (( 2733 - lower_east_column_planned ) * 1000 ) return x_offset def get_seviri_area_def ( native_fp , num_x_pixels = 5568 , num_y_pixels = 4176 ) -> AreaDefinition : \"\"\" The HRV channel on Meteosat Second Generation satellites doesn't scan the full number of columns. The east boundary of the HRV channel changes (e.g. to maximise the amount of the image which is illuminated by sunlight. Parameters: native_fp: Data filepath \"\"\" x_offset = calculate_x_offset ( native_fp ) # The EUMETSAT docs say \"The distance between spacecraft and centre of earth is 42,164 km. The idealized earth # is a perfect ellipsoid with an equator radius of 6378.1690 km and a polar radius of 6356.5838 km.\" # The projection used by SatPy expresses height as height above the Earth's surface (not distance # to the centre of the Earth). projection = { 'proj' : 'geos' , 'lon_0' : 9.5 , 'a' : 6378169.0 , 'b' : 6356583.8 , 'h' : 35785831.00 , 'units' : 'm' } seviri = AreaDefinition ( area_id = 'seviri' , description = 'SEVIRI RSS HRV' , proj_id = 'seviri' , projection = projection , width = num_x_pixels , height = num_y_pixels , area_extent = [ - 2768872.0236 + x_offset , # left 1394687.3495 , # bottom (from scene['HRV'].area) 2799876.1893 + x_offset , # right 5570248.4773 ] # top (from scene['HRV'].area) ) return seviri Then we'll use it to construct the relevant one for Seviri seviri = get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () seviri_crs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2020-12-16T23:15:15.552296 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +a=6378169.0 +rf=295.488065897001 +h=35785831.0 +lon_0=9.5 +no_defs=True +proj=geos +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We'll create a loader function that will extract the relevant data for lower_east_column_planned automatically #exports def load_scene ( native_fp ): # Reading scene and loading HRV scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) # Identifying and recording lower_east_column_planned handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) scene . attrs [ 'lower_east_column_planned' ] = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] return scene We'll see how quickly this loads %% time scene = load_scene ( native_fp ) scene . load ([ 'HRV' ]) Wall time: 1.18 s C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() We can visualise what a specific band looks like fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c808e50> One of the benefits of having access to the underlying XArray object is that we can more easily start to do some analysis with the data, for example defining a reflectance threshold reflectance_threshold = 35 cmap = colors . ListedColormap ([ ( 0 , 0 , 0 , 0 ), # transparent ( 251 / 255 , 242 / 255 , 180 / 255 , 1 ) # yellow # (0.533, 0.808, 0.922, 1) # grey-like blue ]) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , vmin = 0 , vmax = 50 , cmap = 'magma' , add_colorbar = False ) ( scene [ 'HRV' ] > reflectance_threshold ) . plot . imshow ( ax = ax , cmap = cmap , add_colorbar = False ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c809f40> We'll extract the values from the XArray object, then mask all NaN values to enable us to carry out statistical analysis HRV = scene [ \"HRV\" ] . values HRV_masked = ma . masked_array ( HRV , mask = xr . ufuncs . isnan ( scene [ \"HRV\" ]) . values ) np . mean ( HRV_masked ) 12.372444717553362 We can also visualise the full distribution. N.b. to reduce the time it takes to calculate the best KDE fit we'll take only a sample of the data. HRV_sample = np . random . choice ( HRV_masked . flatten (), 1_000_000 ) # Plotting fig , ax = plt . subplots ( dpi = 250 ) sns . kdeplot ( HRV_sample , ax = ax , fill = True ) ax . set_yticks ([]) ax . set_ylabel ( '' ) ax . set_xlabel ( 'HRV Reflectance' ) hlp . hide_spines ( ax , positions = [ 'top' , 'left' , 'right' ]) Evaluating Reprojection to Tranverse Mercator \u00b6 Before we can resample we need to define the area we're resampling to, we'll write a constructor to help us do this #exports def construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , pixel_size = None ): # If None then will use same number of x and y points # HRV's resolution will be more like 4km for Europe if pixel_size is not None : width = int (( east - west ) / pixel_size ) height = int (( north - south ) / pixel_size ) else : width = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . x . values . shape [ 0 ] height = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . y . values . shape [ 0 ] area_extent = ( west , south , east , north ) area_def = AreaDefinition ( area_id , description , proj_id , projection , width , height , area_extent ) return area_def def construct_TM_area_def ( scene ): meters_per_pixel = 4000 west , south , east , north = ( - 3090000 , 1690000 , 4390000 , 9014000 ) area_id = 'TM' description = 'Transverse Mercator' proj_id = 'TM' projection = { 'ellps' : 'WGS84' , 'proj' : 'tmerc' , # Transverse Mercator 'units' : 'm' # meters } tm_area_def = construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , meters_per_pixel ) return tm_area_def tm_area_def = construct_TM_area_def ( scene ) tm_area_def . to_cartopy_crs () C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2020-12-16T23:15:54.380829 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +k=1.0 +lat_0=0.0 +lon_0=0.0 +no_defs=True +proj=tmerc +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We can now carry out the resampling using the pyresample library %% time resampled_scene = scene . resample ( tm_area_def , resampler = 'nearest' ) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:123: RuntimeWarning: invalid value encountered in true_divide self.cart /= np.sqrt(np.einsum('...i, ...i', self.cart, self.cart)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:178: RuntimeWarning: invalid value encountered in double_scalars return (val + mod) % (2 * mod) - mod C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) Wall time: 8.86 s We'll quickly check that the reprojection looks ok fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-20-ec0e500c536a>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948d7e00d0> We want to gain a deeper understanding of the reprojection that's being carried out, to do this we'll manually reproject a sample of the original gridded coordinates %% time orig_x_values = scene [ 'HRV' ] . x . values [:: 50 ] orig_y_values = scene [ 'HRV' ] . y . values [:: 50 ] XX , YY = np . meshgrid ( orig_x_values , orig_y_values ) df_proj_points = ( gpd . GeoSeries ([ Point ( x , y ) for x , y in np . stack ([ XX . flatten (), YY . flatten ()], axis = 1 ) ]) . set_crs ( crs = scene [ 'HRV' ] . area . crs_wkt ) . to_crs ( crs = resampled_scene [ 'HRV' ] . area . crs_wkt ) . apply ( lambda point : pd . Series ( list ( point . coords )[ 0 ])) . rename ( columns = { 0 : 'x_reproj' , 1 : 'y_reproj' }) . replace ( np . inf , np . nan ) . pipe ( lambda df : df . assign ( x_orig = XX . flatten ())) . pipe ( lambda df : df . assign ( y_orig = YY . flatten ())) ) df_proj_points . head () Wall time: 5.41 s x_reproj y_reproj x_orig y_orig 0 4.86340e+06 1.91779e+06 3.16442e+06 1.39519e+06 1 4.78132e+06 1.89942e+06 3.11442e+06 1.39519e+06 2 4.70062e+06 1.88175e+06 3.06441e+06 1.39519e+06 3 4.62123e+06 1.86473e+06 3.01440e+06 1.39519e+06 4 4.5431e+06 1.84834e+06 2.9644e+06 1.39519e+06 We can then visualise the reprojection of the original grid against the regridded reprojection %% time fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) ax . scatter ( df_proj_points [ 'x_reproj' ][:: 10 ], df_proj_points [ 'y_reproj' ][:: 10 ], s = 2 , color = 'red' ) <timed exec>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) Wall time: 27.8 s <matplotlib.collections.PathCollection at 0x294fb0be3a0> This is useful for quick visual inspection, for example we can see that the y axis gets stretched further the nearer to the pole. However, we want to get a better understanding of how the local cell resolution is changing for any given point, we'll begin by looking at this change for Greenwich. def lon_lat_to_new_crs ( lon , lat , crs ): x , y = list ( gpd . GeoSeries ([ Point ( lon , lat )]) . set_crs ( 4326 ) . to_crs ( crs ) . iloc [ 0 ] . coords )[ 0 ] return x , y def calc_res_change ( src_x , src_y , src_da , dst_da , src_dx = 10 , src_dy = 10 ): src_crs = src_da . area . crs_wkt dst_crs = dst_da . area . crs_wkt src_x_width = np . abs ( np . diff ( src_da . x . values )[ 0 ]) src_y_width = np . abs ( np . diff ( src_da . y . values )[ 0 ]) dst_x_width = np . abs ( np . diff ( dst_da . x . values )[ 0 ]) dst_y_width = np . abs ( np . diff ( dst_da . y . values )[ 0 ]) s_points = ( gpd . GeoSeries ([ Point ( src_x , src_y ), Point ( src_x + src_dx , src_y ), Point ( src_x , src_y + src_dy ) ]) . set_crs ( src_crs ) . to_crs ( dst_crs ) ) dst_dx = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) dst_dy = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) x_ratio_change = ( dst_dx / dst_x_width ) / ( src_dx / src_x_width ) y_ratio_change = ( dst_dy / dst_y_width ) / ( src_dy / src_y_width ) return x_ratio_change , y_ratio_change lon = 0 lat = 51.4934 src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) x_ratio_change , y_ratio_change = calc_res_change ( src_x , src_y , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) x_ratio_change , y_ratio_change (0.27381567467569573, 0.528776076616483) We'll double check this by calculating it through a different method, in this case by locating the nearest cell for each scene and comparing their sizes in a common coordinate system def get_da_nearest_cell_width_height ( da , x , y , units_crs ): nearest_loc = da . sel ( x = x , y = y , method = 'nearest' ) nearest_x = nearest_loc . x . values nearest_y = nearest_loc . y . values next_nearest_x = da . x . values [ list ( da . x . values ) . index ( nearest_x ) + 1 ] next_nearest_y = da . y . values [ list ( da . y . values ) . index ( nearest_y ) + 1 ] s_points = ( gpd . GeoSeries ([ Point ( nearest_x , nearest_y ), Point ( next_nearest_x , nearest_y ), Point ( nearest_x , next_nearest_y ) ]) . set_crs ( da . area . crs_wkt ) . to_crs ( units_crs ) ) x_width = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) y_height = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) return x_width , y_height src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , resampled_scene [ 'HRV' ] . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( resampled_scene [ 'HRV' ], dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) The width has changed from 1.09 km to 4.0 km The height has changed from 2.12 km to 4.0 km This can easily be converted into a x and y pixel size ratio change which almost exactly matches our previous calculation. The first calculation is more accurate as the dx and dy can approach 0 and get closer to the true ratio change, however the get_da_nearest_cell_width_height function is still useful as it allows us to determine the cell width and height in more interpretable units x_ratio_change , y_ratio_change = src_x_width / dst_x_width , src_y_height / dst_y_height x_ratio_change , y_ratio_change (0.2738180115545141, 0.5290020702784486) Iceland is stretched further still def print_pixel_change ( lon , lat , da_src , da_dst ): src_x , src_y = lon_lat_to_new_crs ( lon , lat , da_src . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , da_dst . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( da_src , src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( da_dst , dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) return lon = - 18.779208 lat = 64.887370 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.52 km to 3.99 km The height has changed from 4.75 km to 3.99 km And contrasts with Marrakesh which is stretched less than Greenwich in the y axis lon = - 8.005657 lat = 31.636355 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km We can check what the cell height and width are at the center of the image, they should both be close to 1km according to the SEVIRI documentation LineDirGridStep gives the grid step size in km SSP in the line direction. Default value is 3km for VIS and IR, and 1km for HRV. The on-ground grid step size of 3 km at the SSP represents an instrument scan step of 251.53 microrad divided by 3. - EUMETSAT round_m_to_km = lambda m : round ( m / 1000 , 2 ) UTM_35N_epsg = 32632 # should be relatively accurate and is in meters src_x = np . median ( scene [ 'HRV' ] . x . values ) src_y = np . median ( scene [ 'HRV' ] . y . values ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , UTM_35N_epsg ) round_m_to_km ( src_x_width ), round_m_to_km ( src_y_height ) (1.04, 1.36) Comparing Reprojection Libraries \u00b6 In the last section we used pyresample to carry out the data reprojection, here we'll explore pyinterp . Before we start we'll quickly extract the xarrays for the original and reprojected coordinates. def extract_formatted_scene ( scene , variable = 'HRV' , x_coords_name = 'x' , y_coords_name = 'y' , x_units = 'metre' , y_units = 'metre' ): da = ( scene [ variable ] . copy () . rename ({ 'x' : x_coords_name , 'y' : y_coords_name }) ) da [ x_coords_name ] . attrs [ 'units' ] = x_units da [ y_coords_name ] . attrs [ 'units' ] = y_units return da da = extract_formatted_scene ( scene ) da_resampled = extract_formatted_scene ( resampled_scene ) da_resampled /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'my_index-25c95e08ed138cbd282b6596ed55c066' (y: 1831, x: 1870)> dask.array<copy, shape=(1831, 1870), dtype=float32, chunksize=(1831, 1870), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unknown ba... * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 -3.08e+06 ... 4.384e+06 4.388e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9697642568677852 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-9 sensor: seviri start_time: 2020-12-08 09:00:08.206321 end_time: 2020-12-08 09:05:08.329479 area: Area ID: TM\\nDescription: Transve... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'my_index-25c95e08ed138cbd282b6596ed55c066' y : 1831 x : 1870 dask.array<chunksize=(1831, 1870), meta=np.ndarray> Array Chunk Bytes 13.70 MB 13.70 MB Shape (1831, 1870) (1831, 1870) Count 360 Tasks 1 Chunks Type float32 numpy.ndarray 1870 1831 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Transverse Mercator Datum: Unknown based on WGS84 ellipsoid - Ellipsoid: WGS 84 - Prime Meridian: Greenwich , dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 units : metre array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 units : metre array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: TM Description: Transverse Mercator Projection ID: TM Projection: {'ellps': 'WGS84', 'k': '1', 'lat_0': '0', 'lon_0': '0', 'no_defs': 'None', 'proj': 'tmerc', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 1870 Number of rows: 1831 Area extent: (-3090000, 1690000, 4390000, 9014000) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We'll now save the coordinates of the grid we're using in the new projection new_grid_4km_TM = { 'x_coords' : list ( da_resampled . x . values ), 'y_coords' : list ( da_resampled . y . values ) } save_data = True if save_data == True : with open ( '../data/intermediate/new_grid_4km_TM.json' , 'w' ) as fp : json . dump ( new_grid_4km_TM , fp ) JSON ( new_grid_4km_TM ) <IPython.core.display.JSON object> As well as calculate the locations of those points in the original CRS %% time def chunks ( list_ , n ): \"\"\" Yield successive n-sized chunks from `list_`. \"\"\" for i in range ( 0 , len ( list_ ), n ): yield list_ [ i : i + n ] def reproject_geometries ( da , old_crs , new_crs , chunk_size = 5000 ): xx , yy = np . meshgrid ( da . x . values , da . y . values , indexing = 'ij' ) geometry = gpd . points_from_xy ( xx . flatten (), yy . flatten ()) new_coords_samples = [] for geometry_sample in chunks ( geometry , chunk_size ): df_new_coords_sample = ( gpd . GeoSeries ( geometry_sample , crs = old_crs ) . to_crs ( new_crs ) . apply ( lambda x : list ( x . coords [ 0 ])) . apply ( pd . Series ) . rename ( columns = { 0 : 'x' , 1 : 'y' }) ) new_coords_samples += [ df_new_coords_sample ] df_new_coords = pd . concat ( new_coords_samples , ignore_index = True ) return df_new_coords if not os . path . exists ( intermediate_data_dir ): os . makedirs ( intermediate_data_dir ) if calculate_reproj_coords == True : df_new_coords = reproject_geometries ( da_resampled , '+proj=tmerc' , seviri_crs . proj4_init ) df_new_coords . to_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' , index = False ) elif 'reproj_coords.csv' not in os . listdir ( intermediate_data_dir ): df_new_coords = pd . read_csv ( 'https://storage.googleapis.com/reprojection_cache/reproj_coords_TM_4km.csv' ) else : df_new_coords = pd . read_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' ) df_new_coords . head () Wall time: 3.36 s x y 0 inf inf 1 inf inf 2 inf inf 3 inf inf 4 inf inf We can layer these on top of each other to get an alternative view of the transform operation %% time old_x_positions , old_y_positions = [ elem . flatten () for elem in np . meshgrid ( da . x . values [:: 100 ], da . y . values [:: 100 ], indexing = 'ij' )] new_x_positions , new_y_positions = df_new_coords [ 'x' ][:: 100 ], df_new_coords [ 'y' ][:: 100 ] # Plotting fig , ax = plt . subplots ( dpi = 150 ) ax . scatter ( old_x_positions , old_y_positions , s = 0.1 ) ax . scatter ( new_x_positions , new_y_positions , s = 0.1 ) hlp . hide_spines ( ax ) Wall time: 98.8 ms We'll now use pyinterp to take these and use them to carry out the resampling. We'll also create a wrapper for converting the result back into an Xarray object. #exports def reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ): x_axis = pyinterp . Axis ( da . x . values ) y_axis = pyinterp . Axis ( da . y . values ) grid = pyinterp . Grid2D ( x_axis , y_axis , da . data . T ) reproj_data = ( pyinterp . bivariate ( grid , x_coords , y_coords ) . reshape (( len ( new_grid [ 'x_coords' ]), len ( new_grid [ 'y_coords' ]))) ) return reproj_data def reproj_to_xarray ( da , x_coords , y_coords , new_grid ): # We'll reproject the data reproj_data = reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ) # Then put it in an XArray DataArray da_reproj = xr . DataArray ( np . flip ( reproj_data . T , axis = ( 0 , 1 )), dims = ( 'y' , 'x' ), coords = { 'x' : new_grid [ 'x_coords' ][:: - 1 ], 'y' : new_grid [ 'y_coords' ][:: - 1 ] }, attrs = da . attrs ) return da_reproj We'll load the grid back in with open ( '../data/intermediate/new_grid_4km_TM.json' , 'r' ) as fp : new_grid = json . load ( fp ) JSON ( new_grid ) <IPython.core.display.JSON object> Confirm that the size of the grid definition arrays match the number of coordinates we have df_new_coords [ 'y' ] . size == len ( new_grid [ 'x_coords' ]) * len ( new_grid [ 'y_coords' ]) True And finally carry out the reprojection %% timeit da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) 1.78 s \u00c2\u00b1 239 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) Most importantly we'll carry out a visual check that the reprojection was carried out properly. da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_reproj . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-37-c765a7c3ab68>:5: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c866b50> #exports def full_scene_pyresample ( native_fp ): # Loading scene scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) # Constructing target area definition tm_area_def = construct_TM_area_def ( scene ) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da = scene [ dataset_name ] . sortby ( 'y' , ascending = False ) . sortby ( 'x' ) num_y_pixels , num_x_pixels = da . shape seviri_area_def = get_seviri_area_def ( native_fp , num_x_pixels = num_x_pixels , num_y_pixels = num_y_pixels ) resampler = satpy . resample . KDTreeResampler ( seviri_area_def , tm_area_def ) da_reproj = resampler . resample ( da ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = ( xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) . drop ( labels = 'crs' ) ) return ds_reproj def full_scene_pyinterp ( native_fp , new_x_coords , new_y_coords , new_grid_fp ): # Loading data scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) with open ( new_grid_fp , 'r' ) as fp : new_grid = json . load ( fp ) # Correcting x coordinates seviri_area_def = get_seviri_area_def ( native_fp ) area_extent = seviri_area_def . area_extent x_offset = calculate_x_offset ( native_fp ) width = scene [ 'HRV' ] . x . size corrected_x_coords = np . linspace ( area_extent [ 2 ], area_extent [ 0 ], width ) scene [ 'HRV' ] = scene [ 'HRV' ] . assign_coords ({ 'x' : corrected_x_coords }) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da_reproj = reproj_to_xarray ( scene [ dataset_name ], new_x_coords , new_y_coords , new_grid ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) return ds_reproj class Reprojector : def __init__ ( self , new_coords_fp = None , new_grid_fp = None ): if new_coords_fp is None and new_grid_fp is None : return df_new_coords = pd . read_csv ( new_coords_fp ) self . new_x_coords = df_new_coords [ 'x' ] self . new_y_coords = df_new_coords [ 'y' ] self . new_grid_fp = new_grid_fp return def reproject ( self , native_fp , reproj_library = 'pyresample' ): if reproj_library == 'pyinterp' : ds_reproj = full_scene_pyinterp ( native_fp , self . new_x_coords , self . new_y_coords , self . new_grid_fp ) elif reproj_library == 'pyresample' : ds_reproj = full_scene_pyresample ( native_fp ) else : raise ValueError ( f '`reproj_library` must be one of: pyresample, pyinterp. { reproj_library } can not be passed.' ) return ds_reproj %% capture -- no - stdout %% timeit new_coords_fp = f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) 15.9 s \u00c2\u00b1 2.24 s per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout %% timeit reprojector = Reprojector () ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) 9.24 s \u00c2\u00b1 1.18 s per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout ds_reproj = reprojector . reproject ( native_fp ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-41-4aa2b08f07bf> in <module> ----> 1 ds_reproj = reprojector.reproject(native_fp) 2 3 # Plotting 4 fig = plt.figure(dpi=250, figsize=(10, 10)) 5 ax = plt.axes(projection=ccrs.TransverseMercator()) NameError: name 'reprojector' is not defined","title":"Reprojection"},{"location":"02_reproj/#data-transformation","text":"#exports import json import pandas as pd import xarray as xr import numpy as np import numpy.ma as ma import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import colors import seaborn as sns import os import time from itertools import product from collections import OrderedDict from datetime import datetime from ipypb import track import FEAutils as hlp import satpy from satpy import Scene from satpy.readers import seviri_l1b_native import pyresample from pyresample.geometry import AreaDefinition try : import pyinterp import pyinterp.backends.xarray except : pass We'll separately install libraries that wont be needed for the satip module import rasterio from rasterio import Affine as A from rasterio.warp import reproject , Resampling , calculate_default_transform , transform from rasterio.control import GroundControlPoint from rasterio.transform import xy import geopandas as gpd from shapely.geometry import Point import cartopy.crs as ccrs from IPython.display import JSON","title":"Data Transformation"},{"location":"02_reproj/#user-input","text":"data_dir = '../data/raw' intermediate_data_dir = '../data/intermediate' calculate_reproj_coords = False","title":"User Input"},{"location":"02_reproj/#exploratory-data-analysis","text":"We'll start by identifying the available files native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fps [ 0 ] '../data/raw/MSG2-SEVI-MSG15-0100-NA-20201208090415.301000000Z-NA.nat' Then load one of them in as a SatPy scene native_fp = native_fps [ 0 ] scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) scene <satpy.scene.Scene at 0x294fae42e50> We can get a list of the available datasets (bands) scene . all_dataset_names () ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] Each band contains an XArray DataArray scene . load ([ 'HRV' ]) scene [ 'HRV' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'reshape-3b944f9ca9a40a223ab6382d90bfb37d' (y: 4176, x: 5568)> dask.array<mul, shape=(4176, 5568), dtype=float32, chunksize=(1392, 5568), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unknown\",E... * y (y) float64 1.395e+06 1.396e+06 1.397e+06 ... 5.57e+06 5.571e+06 * x (x) float64 3.164e+06 3.163e+06 3.162e+06 ... -2.402e+06 -2.403e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9697642568677852 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-9 sensor: seviri start_time: 2020-12-08 09:00:08.206321 end_time: 2020-12-08 09:05:08.329479 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'reshape-3b944f9ca9a40a223ab6382d90bfb37d' y : 4176 x : 5568 dask.array<chunksize=(1392, 5568), meta=np.ndarray> Array Chunk Bytes 93.01 MB 31.00 MB Shape (4176, 5568) (1392, 5568) Count 214 Tasks 3 Chunks Type float32 numpy.ndarray 5568 4176 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Geostationary Satellite (Sweep Y) Datum: unknown - Ellipsoid: unknown - Prime Meridian: Greenwich , dtype=object) y (y) float64 1.395e+06 1.396e+06 ... 5.571e+06 units : meter array([1395187.416673, 1396187.551022, 1397187.68537 , ..., 5568748.054504, 5569748.188853, 5570748.323202]) x (x) float64 3.164e+06 3.163e+06 ... -2.403e+06 units : meter array([ 3164425.079823, 3163424.945474, 3162424.811125, ..., -2401322.571635, -2402322.705984, -2403322.840333]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We can see that the DataArray contains a crs, however we'll make our own custom area definition that's more accurate. First we'll create a helper function that will create our area definitions. #exports def calculate_x_offset ( native_fp ): handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) lower_east_column_planned = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] x_offset = 32500 + (( 2733 - lower_east_column_planned ) * 1000 ) return x_offset def get_seviri_area_def ( native_fp , num_x_pixels = 5568 , num_y_pixels = 4176 ) -> AreaDefinition : \"\"\" The HRV channel on Meteosat Second Generation satellites doesn't scan the full number of columns. The east boundary of the HRV channel changes (e.g. to maximise the amount of the image which is illuminated by sunlight. Parameters: native_fp: Data filepath \"\"\" x_offset = calculate_x_offset ( native_fp ) # The EUMETSAT docs say \"The distance between spacecraft and centre of earth is 42,164 km. The idealized earth # is a perfect ellipsoid with an equator radius of 6378.1690 km and a polar radius of 6356.5838 km.\" # The projection used by SatPy expresses height as height above the Earth's surface (not distance # to the centre of the Earth). projection = { 'proj' : 'geos' , 'lon_0' : 9.5 , 'a' : 6378169.0 , 'b' : 6356583.8 , 'h' : 35785831.00 , 'units' : 'm' } seviri = AreaDefinition ( area_id = 'seviri' , description = 'SEVIRI RSS HRV' , proj_id = 'seviri' , projection = projection , width = num_x_pixels , height = num_y_pixels , area_extent = [ - 2768872.0236 + x_offset , # left 1394687.3495 , # bottom (from scene['HRV'].area) 2799876.1893 + x_offset , # right 5570248.4773 ] # top (from scene['HRV'].area) ) return seviri Then we'll use it to construct the relevant one for Seviri seviri = get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () seviri_crs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2020-12-16T23:15:15.552296 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +a=6378169.0 +rf=295.488065897001 +h=35785831.0 +lon_0=9.5 +no_defs=True +proj=geos +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We'll create a loader function that will extract the relevant data for lower_east_column_planned automatically #exports def load_scene ( native_fp ): # Reading scene and loading HRV scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) # Identifying and recording lower_east_column_planned handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) scene . attrs [ 'lower_east_column_planned' ] = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] return scene We'll see how quickly this loads %% time scene = load_scene ( native_fp ) scene . load ([ 'HRV' ]) Wall time: 1.18 s C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() We can visualise what a specific band looks like fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c808e50> One of the benefits of having access to the underlying XArray object is that we can more easily start to do some analysis with the data, for example defining a reflectance threshold reflectance_threshold = 35 cmap = colors . ListedColormap ([ ( 0 , 0 , 0 , 0 ), # transparent ( 251 / 255 , 242 / 255 , 180 / 255 , 1 ) # yellow # (0.533, 0.808, 0.922, 1) # grey-like blue ]) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , vmin = 0 , vmax = 50 , cmap = 'magma' , add_colorbar = False ) ( scene [ 'HRV' ] > reflectance_threshold ) . plot . imshow ( ax = ax , cmap = cmap , add_colorbar = False ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c809f40> We'll extract the values from the XArray object, then mask all NaN values to enable us to carry out statistical analysis HRV = scene [ \"HRV\" ] . values HRV_masked = ma . masked_array ( HRV , mask = xr . ufuncs . isnan ( scene [ \"HRV\" ]) . values ) np . mean ( HRV_masked ) 12.372444717553362 We can also visualise the full distribution. N.b. to reduce the time it takes to calculate the best KDE fit we'll take only a sample of the data. HRV_sample = np . random . choice ( HRV_masked . flatten (), 1_000_000 ) # Plotting fig , ax = plt . subplots ( dpi = 250 ) sns . kdeplot ( HRV_sample , ax = ax , fill = True ) ax . set_yticks ([]) ax . set_ylabel ( '' ) ax . set_xlabel ( 'HRV Reflectance' ) hlp . hide_spines ( ax , positions = [ 'top' , 'left' , 'right' ])","title":"Exploratory Data Analysis"},{"location":"02_reproj/#evaluating-reprojection-to-tranverse-mercator","text":"Before we can resample we need to define the area we're resampling to, we'll write a constructor to help us do this #exports def construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , pixel_size = None ): # If None then will use same number of x and y points # HRV's resolution will be more like 4km for Europe if pixel_size is not None : width = int (( east - west ) / pixel_size ) height = int (( north - south ) / pixel_size ) else : width = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . x . values . shape [ 0 ] height = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . y . values . shape [ 0 ] area_extent = ( west , south , east , north ) area_def = AreaDefinition ( area_id , description , proj_id , projection , width , height , area_extent ) return area_def def construct_TM_area_def ( scene ): meters_per_pixel = 4000 west , south , east , north = ( - 3090000 , 1690000 , 4390000 , 9014000 ) area_id = 'TM' description = 'Transverse Mercator' proj_id = 'TM' projection = { 'ellps' : 'WGS84' , 'proj' : 'tmerc' , # Transverse Mercator 'units' : 'm' # meters } tm_area_def = construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , meters_per_pixel ) return tm_area_def tm_area_def = construct_TM_area_def ( scene ) tm_area_def . to_cartopy_crs () C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2020-12-16T23:15:54.380829 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +k=1.0 +lat_0=0.0 +lon_0=0.0 +no_defs=True +proj=tmerc +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We can now carry out the resampling using the pyresample library %% time resampled_scene = scene . resample ( tm_area_def , resampler = 'nearest' ) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:123: RuntimeWarning: invalid value encountered in true_divide self.cart /= np.sqrt(np.einsum('...i, ...i', self.cart, self.cart)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:178: RuntimeWarning: invalid value encountered in double_scalars return (val + mod) % (2 * mod) - mod C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) Wall time: 8.86 s We'll quickly check that the reprojection looks ok fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-20-ec0e500c536a>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948d7e00d0> We want to gain a deeper understanding of the reprojection that's being carried out, to do this we'll manually reproject a sample of the original gridded coordinates %% time orig_x_values = scene [ 'HRV' ] . x . values [:: 50 ] orig_y_values = scene [ 'HRV' ] . y . values [:: 50 ] XX , YY = np . meshgrid ( orig_x_values , orig_y_values ) df_proj_points = ( gpd . GeoSeries ([ Point ( x , y ) for x , y in np . stack ([ XX . flatten (), YY . flatten ()], axis = 1 ) ]) . set_crs ( crs = scene [ 'HRV' ] . area . crs_wkt ) . to_crs ( crs = resampled_scene [ 'HRV' ] . area . crs_wkt ) . apply ( lambda point : pd . Series ( list ( point . coords )[ 0 ])) . rename ( columns = { 0 : 'x_reproj' , 1 : 'y_reproj' }) . replace ( np . inf , np . nan ) . pipe ( lambda df : df . assign ( x_orig = XX . flatten ())) . pipe ( lambda df : df . assign ( y_orig = YY . flatten ())) ) df_proj_points . head () Wall time: 5.41 s x_reproj y_reproj x_orig y_orig 0 4.86340e+06 1.91779e+06 3.16442e+06 1.39519e+06 1 4.78132e+06 1.89942e+06 3.11442e+06 1.39519e+06 2 4.70062e+06 1.88175e+06 3.06441e+06 1.39519e+06 3 4.62123e+06 1.86473e+06 3.01440e+06 1.39519e+06 4 4.5431e+06 1.84834e+06 2.9644e+06 1.39519e+06 We can then visualise the reprojection of the original grid against the regridded reprojection %% time fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) ax . scatter ( df_proj_points [ 'x_reproj' ][:: 10 ], df_proj_points [ 'y_reproj' ][:: 10 ], s = 2 , color = 'red' ) <timed exec>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) Wall time: 27.8 s <matplotlib.collections.PathCollection at 0x294fb0be3a0> This is useful for quick visual inspection, for example we can see that the y axis gets stretched further the nearer to the pole. However, we want to get a better understanding of how the local cell resolution is changing for any given point, we'll begin by looking at this change for Greenwich. def lon_lat_to_new_crs ( lon , lat , crs ): x , y = list ( gpd . GeoSeries ([ Point ( lon , lat )]) . set_crs ( 4326 ) . to_crs ( crs ) . iloc [ 0 ] . coords )[ 0 ] return x , y def calc_res_change ( src_x , src_y , src_da , dst_da , src_dx = 10 , src_dy = 10 ): src_crs = src_da . area . crs_wkt dst_crs = dst_da . area . crs_wkt src_x_width = np . abs ( np . diff ( src_da . x . values )[ 0 ]) src_y_width = np . abs ( np . diff ( src_da . y . values )[ 0 ]) dst_x_width = np . abs ( np . diff ( dst_da . x . values )[ 0 ]) dst_y_width = np . abs ( np . diff ( dst_da . y . values )[ 0 ]) s_points = ( gpd . GeoSeries ([ Point ( src_x , src_y ), Point ( src_x + src_dx , src_y ), Point ( src_x , src_y + src_dy ) ]) . set_crs ( src_crs ) . to_crs ( dst_crs ) ) dst_dx = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) dst_dy = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) x_ratio_change = ( dst_dx / dst_x_width ) / ( src_dx / src_x_width ) y_ratio_change = ( dst_dy / dst_y_width ) / ( src_dy / src_y_width ) return x_ratio_change , y_ratio_change lon = 0 lat = 51.4934 src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) x_ratio_change , y_ratio_change = calc_res_change ( src_x , src_y , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) x_ratio_change , y_ratio_change (0.27381567467569573, 0.528776076616483) We'll double check this by calculating it through a different method, in this case by locating the nearest cell for each scene and comparing their sizes in a common coordinate system def get_da_nearest_cell_width_height ( da , x , y , units_crs ): nearest_loc = da . sel ( x = x , y = y , method = 'nearest' ) nearest_x = nearest_loc . x . values nearest_y = nearest_loc . y . values next_nearest_x = da . x . values [ list ( da . x . values ) . index ( nearest_x ) + 1 ] next_nearest_y = da . y . values [ list ( da . y . values ) . index ( nearest_y ) + 1 ] s_points = ( gpd . GeoSeries ([ Point ( nearest_x , nearest_y ), Point ( next_nearest_x , nearest_y ), Point ( nearest_x , next_nearest_y ) ]) . set_crs ( da . area . crs_wkt ) . to_crs ( units_crs ) ) x_width = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) y_height = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) return x_width , y_height src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , resampled_scene [ 'HRV' ] . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( resampled_scene [ 'HRV' ], dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) The width has changed from 1.09 km to 4.0 km The height has changed from 2.12 km to 4.0 km This can easily be converted into a x and y pixel size ratio change which almost exactly matches our previous calculation. The first calculation is more accurate as the dx and dy can approach 0 and get closer to the true ratio change, however the get_da_nearest_cell_width_height function is still useful as it allows us to determine the cell width and height in more interpretable units x_ratio_change , y_ratio_change = src_x_width / dst_x_width , src_y_height / dst_y_height x_ratio_change , y_ratio_change (0.2738180115545141, 0.5290020702784486) Iceland is stretched further still def print_pixel_change ( lon , lat , da_src , da_dst ): src_x , src_y = lon_lat_to_new_crs ( lon , lat , da_src . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , da_dst . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( da_src , src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( da_dst , dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) return lon = - 18.779208 lat = 64.887370 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.52 km to 3.99 km The height has changed from 4.75 km to 3.99 km And contrasts with Marrakesh which is stretched less than Greenwich in the y axis lon = - 8.005657 lat = 31.636355 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km We can check what the cell height and width are at the center of the image, they should both be close to 1km according to the SEVIRI documentation LineDirGridStep gives the grid step size in km SSP in the line direction. Default value is 3km for VIS and IR, and 1km for HRV. The on-ground grid step size of 3 km at the SSP represents an instrument scan step of 251.53 microrad divided by 3. - EUMETSAT round_m_to_km = lambda m : round ( m / 1000 , 2 ) UTM_35N_epsg = 32632 # should be relatively accurate and is in meters src_x = np . median ( scene [ 'HRV' ] . x . values ) src_y = np . median ( scene [ 'HRV' ] . y . values ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , UTM_35N_epsg ) round_m_to_km ( src_x_width ), round_m_to_km ( src_y_height ) (1.04, 1.36)","title":"Evaluating Reprojection to Tranverse Mercator"},{"location":"02_reproj/#comparing-reprojection-libraries","text":"In the last section we used pyresample to carry out the data reprojection, here we'll explore pyinterp . Before we start we'll quickly extract the xarrays for the original and reprojected coordinates. def extract_formatted_scene ( scene , variable = 'HRV' , x_coords_name = 'x' , y_coords_name = 'y' , x_units = 'metre' , y_units = 'metre' ): da = ( scene [ variable ] . copy () . rename ({ 'x' : x_coords_name , 'y' : y_coords_name }) ) da [ x_coords_name ] . attrs [ 'units' ] = x_units da [ y_coords_name ] . attrs [ 'units' ] = y_units return da da = extract_formatted_scene ( scene ) da_resampled = extract_formatted_scene ( resampled_scene ) da_resampled /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'my_index-25c95e08ed138cbd282b6596ed55c066' (y: 1831, x: 1870)> dask.array<copy, shape=(1831, 1870), dtype=float32, chunksize=(1831, 1870), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unknown ba... * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 -3.08e+06 ... 4.384e+06 4.388e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9697642568677852 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-9 sensor: seviri start_time: 2020-12-08 09:00:08.206321 end_time: 2020-12-08 09:05:08.329479 area: Area ID: TM\\nDescription: Transve... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'my_index-25c95e08ed138cbd282b6596ed55c066' y : 1831 x : 1870 dask.array<chunksize=(1831, 1870), meta=np.ndarray> Array Chunk Bytes 13.70 MB 13.70 MB Shape (1831, 1870) (1831, 1870) Count 360 Tasks 1 Chunks Type float32 numpy.ndarray 1870 1831 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Transverse Mercator Datum: Unknown based on WGS84 ellipsoid - Ellipsoid: WGS 84 - Prime Meridian: Greenwich , dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 units : metre array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 units : metre array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: TM Description: Transverse Mercator Projection ID: TM Projection: {'ellps': 'WGS84', 'k': '1', 'lat_0': '0', 'lon_0': '0', 'no_defs': 'None', 'proj': 'tmerc', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 1870 Number of rows: 1831 Area extent: (-3090000, 1690000, 4390000, 9014000) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We'll now save the coordinates of the grid we're using in the new projection new_grid_4km_TM = { 'x_coords' : list ( da_resampled . x . values ), 'y_coords' : list ( da_resampled . y . values ) } save_data = True if save_data == True : with open ( '../data/intermediate/new_grid_4km_TM.json' , 'w' ) as fp : json . dump ( new_grid_4km_TM , fp ) JSON ( new_grid_4km_TM ) <IPython.core.display.JSON object> As well as calculate the locations of those points in the original CRS %% time def chunks ( list_ , n ): \"\"\" Yield successive n-sized chunks from `list_`. \"\"\" for i in range ( 0 , len ( list_ ), n ): yield list_ [ i : i + n ] def reproject_geometries ( da , old_crs , new_crs , chunk_size = 5000 ): xx , yy = np . meshgrid ( da . x . values , da . y . values , indexing = 'ij' ) geometry = gpd . points_from_xy ( xx . flatten (), yy . flatten ()) new_coords_samples = [] for geometry_sample in chunks ( geometry , chunk_size ): df_new_coords_sample = ( gpd . GeoSeries ( geometry_sample , crs = old_crs ) . to_crs ( new_crs ) . apply ( lambda x : list ( x . coords [ 0 ])) . apply ( pd . Series ) . rename ( columns = { 0 : 'x' , 1 : 'y' }) ) new_coords_samples += [ df_new_coords_sample ] df_new_coords = pd . concat ( new_coords_samples , ignore_index = True ) return df_new_coords if not os . path . exists ( intermediate_data_dir ): os . makedirs ( intermediate_data_dir ) if calculate_reproj_coords == True : df_new_coords = reproject_geometries ( da_resampled , '+proj=tmerc' , seviri_crs . proj4_init ) df_new_coords . to_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' , index = False ) elif 'reproj_coords.csv' not in os . listdir ( intermediate_data_dir ): df_new_coords = pd . read_csv ( 'https://storage.googleapis.com/reprojection_cache/reproj_coords_TM_4km.csv' ) else : df_new_coords = pd . read_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' ) df_new_coords . head () Wall time: 3.36 s x y 0 inf inf 1 inf inf 2 inf inf 3 inf inf 4 inf inf We can layer these on top of each other to get an alternative view of the transform operation %% time old_x_positions , old_y_positions = [ elem . flatten () for elem in np . meshgrid ( da . x . values [:: 100 ], da . y . values [:: 100 ], indexing = 'ij' )] new_x_positions , new_y_positions = df_new_coords [ 'x' ][:: 100 ], df_new_coords [ 'y' ][:: 100 ] # Plotting fig , ax = plt . subplots ( dpi = 150 ) ax . scatter ( old_x_positions , old_y_positions , s = 0.1 ) ax . scatter ( new_x_positions , new_y_positions , s = 0.1 ) hlp . hide_spines ( ax ) Wall time: 98.8 ms We'll now use pyinterp to take these and use them to carry out the resampling. We'll also create a wrapper for converting the result back into an Xarray object. #exports def reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ): x_axis = pyinterp . Axis ( da . x . values ) y_axis = pyinterp . Axis ( da . y . values ) grid = pyinterp . Grid2D ( x_axis , y_axis , da . data . T ) reproj_data = ( pyinterp . bivariate ( grid , x_coords , y_coords ) . reshape (( len ( new_grid [ 'x_coords' ]), len ( new_grid [ 'y_coords' ]))) ) return reproj_data def reproj_to_xarray ( da , x_coords , y_coords , new_grid ): # We'll reproject the data reproj_data = reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ) # Then put it in an XArray DataArray da_reproj = xr . DataArray ( np . flip ( reproj_data . T , axis = ( 0 , 1 )), dims = ( 'y' , 'x' ), coords = { 'x' : new_grid [ 'x_coords' ][:: - 1 ], 'y' : new_grid [ 'y_coords' ][:: - 1 ] }, attrs = da . attrs ) return da_reproj We'll load the grid back in with open ( '../data/intermediate/new_grid_4km_TM.json' , 'r' ) as fp : new_grid = json . load ( fp ) JSON ( new_grid ) <IPython.core.display.JSON object> Confirm that the size of the grid definition arrays match the number of coordinates we have df_new_coords [ 'y' ] . size == len ( new_grid [ 'x_coords' ]) * len ( new_grid [ 'y_coords' ]) True And finally carry out the reprojection %% timeit da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) 1.78 s \u00c2\u00b1 239 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) Most importantly we'll carry out a visual check that the reprojection was carried out properly. da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_reproj . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-37-c765a7c3ab68>:5: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c866b50> #exports def full_scene_pyresample ( native_fp ): # Loading scene scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) # Constructing target area definition tm_area_def = construct_TM_area_def ( scene ) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da = scene [ dataset_name ] . sortby ( 'y' , ascending = False ) . sortby ( 'x' ) num_y_pixels , num_x_pixels = da . shape seviri_area_def = get_seviri_area_def ( native_fp , num_x_pixels = num_x_pixels , num_y_pixels = num_y_pixels ) resampler = satpy . resample . KDTreeResampler ( seviri_area_def , tm_area_def ) da_reproj = resampler . resample ( da ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = ( xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) . drop ( labels = 'crs' ) ) return ds_reproj def full_scene_pyinterp ( native_fp , new_x_coords , new_y_coords , new_grid_fp ): # Loading data scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) with open ( new_grid_fp , 'r' ) as fp : new_grid = json . load ( fp ) # Correcting x coordinates seviri_area_def = get_seviri_area_def ( native_fp ) area_extent = seviri_area_def . area_extent x_offset = calculate_x_offset ( native_fp ) width = scene [ 'HRV' ] . x . size corrected_x_coords = np . linspace ( area_extent [ 2 ], area_extent [ 0 ], width ) scene [ 'HRV' ] = scene [ 'HRV' ] . assign_coords ({ 'x' : corrected_x_coords }) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da_reproj = reproj_to_xarray ( scene [ dataset_name ], new_x_coords , new_y_coords , new_grid ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) return ds_reproj class Reprojector : def __init__ ( self , new_coords_fp = None , new_grid_fp = None ): if new_coords_fp is None and new_grid_fp is None : return df_new_coords = pd . read_csv ( new_coords_fp ) self . new_x_coords = df_new_coords [ 'x' ] self . new_y_coords = df_new_coords [ 'y' ] self . new_grid_fp = new_grid_fp return def reproject ( self , native_fp , reproj_library = 'pyresample' ): if reproj_library == 'pyinterp' : ds_reproj = full_scene_pyinterp ( native_fp , self . new_x_coords , self . new_y_coords , self . new_grid_fp ) elif reproj_library == 'pyresample' : ds_reproj = full_scene_pyresample ( native_fp ) else : raise ValueError ( f '`reproj_library` must be one of: pyresample, pyinterp. { reproj_library } can not be passed.' ) return ds_reproj %% capture -- no - stdout %% timeit new_coords_fp = f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) 15.9 s \u00c2\u00b1 2.24 s per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout %% timeit reprojector = Reprojector () ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) 9.24 s \u00c2\u00b1 1.18 s per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout ds_reproj = reprojector . reproject ( native_fp ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-41-4aa2b08f07bf> in <module> ----> 1 ds_reproj = reprojector.reproject(native_fp) 2 3 # Plotting 4 fig = plt.figure(dpi=250, figsize=(10, 10)) 5 ax = plt.axes(projection=ccrs.TransverseMercator()) NameError: name 'reprojector' is not defined","title":"Comparing Reprojection Libraries"},{"location":"02_reprojection/","text":"Data Transformation \u00b6 #exports import json import pandas as pd import xarray as xr import numpy as np import numpy.ma as ma import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import colors import seaborn as sns import os import time from itertools import product from collections import OrderedDict from datetime import datetime from ipypb import track import FEAutils as hlp import satpy from satpy import Scene from satpy.readers import seviri_l1b_native import pyresample from pyresample.geometry import AreaDefinition # pyinterp fails to import on some machines for unknown reasons - leave it optional try : import pyinterp import pyinterp.backends.xarray except : pass We'll separately install libraries that wont be needed for the satip module import rasterio from rasterio import Affine as A from rasterio.warp import reproject , Resampling , calculate_default_transform , transform from rasterio.control import GroundControlPoint from rasterio.transform import xy import geopandas as gpd from shapely.geometry import Point import cartopy.crs as ccrs from IPython.display import JSON User Input \u00b6 data_dir = '../data/raw' intermediate_data_dir = '../data/intermediate' calculate_reproj_coords = False Exploratory Data Analysis \u00b6 We'll start by identifying the available files native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fps [ 0 ] '../data/raw/MSG3-SEVI-MSG15-0100-NA-20210121204918.196000000Z-NA.nat' Then load one of them in as a SatPy scene native_fp = native_fps [ 0 ] scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) scene <satpy.scene.Scene at 0x1c2a2940eb0> We can get a list of the available datasets (bands) scene . all_dataset_names () ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] Each band contains an XArray DataArray scene . load ([ 'HRV' ]) scene [ 'HRV' ] C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'reshape-d4e0a459824b09e38634d18c1de710b4' (y: 4176, x: 5568)> dask.array<mul, shape=(4176, 5568), dtype=float32, chunksize=(1392, 5568), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unknown\",E... * y (y) float64 1.395e+06 1.396e+06 1.397e+06 ... 5.57e+06 5.571e+06 * x (x) float64 2.83e+06 2.829e+06 2.828e+06 ... -2.736e+06 -2.737e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9683646614038233 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2021-01-21 20:45:11.814324 end_time: 2021-01-21 20:50:10.471270 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'reshape-d4e0a459824b09e38634d18c1de710b4' y : 4176 x : 5568 dask.array<chunksize=(1392, 5568), meta=np.ndarray> Array Chunk Bytes 93.01 MB 31.00 MB Shape (4176, 5568) (1392, 5568) Count 214 Tasks 3 Chunks Type float32 numpy.ndarray 5568 4176 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Geostationary Satellite (Sweep Y) Datum: unknown - Ellipsoid: unknown - Prime Meridian: Greenwich , dtype=object) y (y) float64 1.395e+06 1.396e+06 ... 5.571e+06 units : meter array([1395187.416673, 1396187.551022, 1397187.68537 , ..., 5568748.054504, 5569748.188853, 5570748.323202]) x (x) float64 2.83e+06 2.829e+06 ... -2.737e+06 units : meter array([ 2830380.2073 , 2829380.072951, 2828379.938602, ..., -2735367.444158, -2736367.578506, -2737367.712855]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9683646614038233 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2021-01-21 20:45:11.814324 end_time : 2021-01-21 20:50:10.471270 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2830880.2745, 5571248.3904, -2737867.78, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We can see that the DataArray contains a crs, however we'll make our own custom area definition that's more accurate. First we'll create a helper function that will create our area definitions. #exports def calculate_x_offset ( native_fp ): handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) lower_east_column_planned = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] x_offset = 32500 + (( 2733 - lower_east_column_planned ) * 1000 ) return x_offset def get_seviri_area_def ( native_fp , num_x_pixels = 5568 , num_y_pixels = 4176 ) -> AreaDefinition : \"\"\" The HRV channel on Meteosat Second Generation satellites doesn't scan the full number of columns. The east boundary of the HRV channel changes (e.g. to maximise the amount of the image which is illuminated by sunlight. Parameters: native_fp: Data filepath \"\"\" x_offset = calculate_x_offset ( native_fp ) # The EUMETSAT docs say \"The distance between spacecraft and centre of earth is 42,164 km. The idealized earth # is a perfect ellipsoid with an equator radius of 6378.1690 km and a polar radius of 6356.5838 km.\" # The projection used by SatPy expresses height as height above the Earth's surface (not distance # to the centre of the Earth). projection = { 'proj' : 'geos' , 'lon_0' : 9.5 , 'a' : 6378169.0 , 'b' : 6356583.8 , 'h' : 35785831.00 , 'units' : 'm' } seviri = AreaDefinition ( area_id = 'seviri' , description = 'SEVIRI RSS HRV' , proj_id = 'seviri' , projection = projection , width = num_x_pixels , height = num_y_pixels , area_extent = [ - 2768872.0236 + x_offset , # left 1394687.3495 , # bottom (from scene['HRV'].area) 2799876.1893 + x_offset , # right 5570248.4773 ] # top (from scene['HRV'].area) ) return seviri Then we'll use it to construct the relevant one for Seviri seviri = get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () seviri_crs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2021-03-26T14:44:22.150408 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +a=6378169.0 +rf=295.488065897001 +h=35785831.0 +lon_0=9.5 +no_defs=True +proj=geos +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We'll create a loader function that will extract the relevant data for lower_east_column_planned automatically #exports def load_scene ( native_fp ): # Reading scene and loading HRV scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) # Identifying and recording lower_east_column_planned handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) scene . attrs [ 'lower_east_column_planned' ] = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] return scene We'll see how quickly this loads %% time scene = load_scene ( native_fp ) scene . load ([ 'HRV' ]) Wall time: 779 ms C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() We can visualise what a specific band looks like fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x1c2af21bb20> One of the benefits of having access to the underlying XArray object is that we can more easily start to do some analysis with the data, for example defining a reflectance threshold reflectance_threshold = 35 cmap = colors . ListedColormap ([ ( 0 , 0 , 0 , 0 ), # transparent ( 251 / 255 , 242 / 255 , 180 / 255 , 1 ) # yellow # (0.533, 0.808, 0.922, 1) # grey-like blue ]) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , vmin = 0 , vmax = 50 , cmap = 'magma' , add_colorbar = False ) ( scene [ 'HRV' ] > reflectance_threshold ) . plot . imshow ( ax = ax , cmap = cmap , add_colorbar = False ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x1c2a4d10ee0> We'll extract the values from the XArray object, then mask all NaN values to enable us to carry out statistical analysis HRV = scene [ \"HRV\" ] . values HRV_masked = ma . masked_array ( HRV , mask = xr . ufuncs . isnan ( scene [ \"HRV\" ]) . values ) np . mean ( HRV_masked ) 0.03837633008116254 We can also visualise the full distribution. N.b. to reduce the time it takes to calculate the best KDE fit we'll take only a sample of the data. HRV_sample = np . random . choice ( HRV_masked . flatten (), 1_000_000 ) # Plotting fig , ax = plt . subplots ( dpi = 250 ) sns . kdeplot ( HRV_sample , ax = ax , fill = True ) ax . set_yticks ([]) ax . set_ylabel ( '' ) ax . set_xlabel ( 'HRV Reflectance' ) hlp . hide_spines ( ax , positions = [ 'top' , 'left' , 'right' ]) Evaluating Reprojection to Tranverse Mercator \u00b6 Before we can resample we need to define the area we're resampling to, we'll write a constructor to help us do this #exports def construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , pixel_size = None ): # If None then will use same number of x and y points # HRV's resolution will be more like 4km for Europe if pixel_size is not None : width = int (( east - west ) / pixel_size ) height = int (( north - south ) / pixel_size ) else : width = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . x . values . shape [ 0 ] height = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . y . values . shape [ 0 ] area_extent = ( west , south , east , north ) area_def = AreaDefinition ( area_id , description , proj_id , projection , width , height , area_extent ) return area_def def construct_TM_area_def ( scene ): meters_per_pixel = 4000 west , south , east , north = ( - 3090000 , 1690000 , 4390000 , 9014000 ) area_id = 'TM' description = 'Transverse Mercator' proj_id = 'TM' projection = { 'ellps' : 'WGS84' , 'proj' : 'tmerc' , # Transverse Mercator 'units' : 'm' # meters } tm_area_def = construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , meters_per_pixel ) return tm_area_def tm_area_def = construct_TM_area_def ( scene ) tm_area_def . to_cartopy_crs () C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2021-03-26T14:44:44.261206 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +k=1.0 +lat_0=0.0 +lon_0=0.0 +no_defs=True +proj=tmerc +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We can now carry out the resampling using the pyresample library %% time resampled_scene = scene . resample ( tm_area_def , resampler = 'nearest' ) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:123: RuntimeWarning: invalid value encountered in true_divide self.cart /= np.sqrt(np.einsum('...i, ...i', self.cart, self.cart)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:178: RuntimeWarning: invalid value encountered in double_scalars return (val + mod) % (2 * mod) - mod C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() Wall time: 4.81 s We'll quickly check that the reprojection looks ok fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-20-ec0e500c536a>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x1c2b58957f0> We want to gain a deeper understanding of the reprojection that's being carried out, to do this we'll manually reproject a sample of the original gridded coordinates %% time orig_x_values = scene [ 'HRV' ] . x . values [:: 50 ] orig_y_values = scene [ 'HRV' ] . y . values [:: 50 ] XX , YY = np . meshgrid ( orig_x_values , orig_y_values ) df_proj_points = ( gpd . GeoSeries ([ Point ( x , y ) for x , y in np . stack ([ XX . flatten (), YY . flatten ()], axis = 1 ) ]) . set_crs ( crs = scene [ 'HRV' ] . area . crs_wkt ) . to_crs ( crs = resampled_scene [ 'HRV' ] . area . crs_wkt ) . apply ( lambda point : pd . Series ( list ( point . coords )[ 0 ])) . rename ( columns = { 0 : 'x_reproj' , 1 : 'y_reproj' }) . replace ( np . inf , np . nan ) . pipe ( lambda df : df . assign ( x_orig = XX . flatten ())) . pipe ( lambda df : df . assign ( y_orig = YY . flatten ())) ) df_proj_points . head () Wall time: 8.13 s x_reproj y_reproj x_orig y_orig 0 4.3395e+06 1.80726e+06 2.83038e+06 1.39519e+06 1 4.26554e+06 1.79291e+06 2.78037e+06 1.39519e+06 2 4.19261e+06 1.77906e+06 2.73037e+06 1.39519e+06 3 4.12066e+06 1.76567e+06 2.68036e+06 1.39519e+06 4 4.04965e+06 1.75274e+06 2.63035e+06 1.39519e+06 We can then visualise the reprojection of the original grid against the regridded reprojection %% time fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) ax . scatter ( df_proj_points [ 'x_reproj' ][:: 10 ], df_proj_points [ 'y_reproj' ][:: 10 ], s = 2 , color = 'red' ) <timed exec>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) Wall time: 20.8 s <matplotlib.collections.PathCollection at 0x1c2af1a3400> This is useful for quick visual inspection, for example we can see that the y axis gets stretched further the nearer to the pole. However, we want to get a better understanding of how the local cell resolution is changing for any given point, we'll begin by looking at this change for Greenwich. def lon_lat_to_new_crs ( lon , lat , crs ): x , y = list ( gpd . GeoSeries ([ Point ( lon , lat )]) . set_crs ( 4326 ) . to_crs ( crs ) . iloc [ 0 ] . coords )[ 0 ] return x , y def calc_res_change ( src_x , src_y , src_da , dst_da , src_dx = 10 , src_dy = 10 ): src_crs = src_da . area . crs_wkt dst_crs = dst_da . area . crs_wkt src_x_width = np . abs ( np . diff ( src_da . x . values )[ 0 ]) src_y_width = np . abs ( np . diff ( src_da . y . values )[ 0 ]) dst_x_width = np . abs ( np . diff ( dst_da . x . values )[ 0 ]) dst_y_width = np . abs ( np . diff ( dst_da . y . values )[ 0 ]) s_points = ( gpd . GeoSeries ([ Point ( src_x , src_y ), Point ( src_x + src_dx , src_y ), Point ( src_x , src_y + src_dy ) ]) . set_crs ( src_crs ) . to_crs ( dst_crs ) ) dst_dx = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) dst_dy = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) x_ratio_change = ( dst_dx / dst_x_width ) / ( src_dx / src_x_width ) y_ratio_change = ( dst_dy / dst_y_width ) / ( src_dy / src_y_width ) return x_ratio_change , y_ratio_change lon = 0 lat = 51.4934 src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) x_ratio_change , y_ratio_change = calc_res_change ( src_x , src_y , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) x_ratio_change , y_ratio_change (0.27381567467569573, 0.528776076616483) We'll double check this by calculating it through a different method, in this case by locating the nearest cell for each scene and comparing their sizes in a common coordinate system def get_da_nearest_cell_width_height ( da , x , y , units_crs ): nearest_loc = da . sel ( x = x , y = y , method = 'nearest' ) nearest_x = nearest_loc . x . values nearest_y = nearest_loc . y . values next_nearest_x = da . x . values [ list ( da . x . values ) . index ( nearest_x ) + 1 ] next_nearest_y = da . y . values [ list ( da . y . values ) . index ( nearest_y ) + 1 ] s_points = ( gpd . GeoSeries ([ Point ( nearest_x , nearest_y ), Point ( next_nearest_x , nearest_y ), Point ( nearest_x , next_nearest_y ) ]) . set_crs ( da . area . crs_wkt ) . to_crs ( units_crs ) ) x_width = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) y_height = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) return x_width , y_height src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , resampled_scene [ 'HRV' ] . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( resampled_scene [ 'HRV' ], dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) The width has changed from 1.09 km to 4.0 km The height has changed from 2.12 km to 4.0 km This can easily be converted into a x and y pixel size ratio change which almost exactly matches our previous calculation. The first calculation is more accurate as the dx and dy can approach 0 and get closer to the true ratio change, however the get_da_nearest_cell_width_height function is still useful as it allows us to determine the cell width and height in more interpretable units x_ratio_change , y_ratio_change = src_x_width / dst_x_width , src_y_height / dst_y_height x_ratio_change , y_ratio_change (0.2738180115545141, 0.5290020702784486) Iceland is stretched further still def print_pixel_change ( lon , lat , da_src , da_dst ): src_x , src_y = lon_lat_to_new_crs ( lon , lat , da_src . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , da_dst . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( da_src , src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( da_dst , dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) return lon = - 18.779208 lat = 64.887370 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.52 km to 3.99 km The height has changed from 4.75 km to 3.99 km And contrasts with Marrakesh which is stretched less than Greenwich in the y axis lon = - 8.005657 lat = 31.636355 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km We can check what the cell height and width are at the center of the image, they should both be close to 1km according to the SEVIRI documentation LineDirGridStep gives the grid step size in km SSP in the line direction. Default value is 3km for VIS and IR, and 1km for HRV. The on-ground grid step size of 3 km at the SSP represents an instrument scan step of 251.53 microrad divided by 3. - EUMETSAT round_m_to_km = lambda m : round ( m / 1000 , 2 ) UTM_35N_epsg = 32632 # should be relatively accurate and is in meters src_x = np . median ( scene [ 'HRV' ] . x . values ) src_y = np . median ( scene [ 'HRV' ] . y . values ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , UTM_35N_epsg ) round_m_to_km ( src_x_width ), round_m_to_km ( src_y_height ) (1.03, 1.36) Comparing Reprojection Libraries \u00b6 In the last section we used pyresample to carry out the data reprojection, here we'll explore pyinterp . Before we start we'll quickly extract the xarrays for the original and reprojected coordinates. def extract_formatted_scene ( scene , variable = 'HRV' , x_coords_name = 'x' , y_coords_name = 'y' , x_units = 'metre' , y_units = 'metre' ): da = ( scene [ variable ] . copy () . rename ({ 'x' : x_coords_name , 'y' : y_coords_name }) ) da [ x_coords_name ] . attrs [ 'units' ] = x_units da [ y_coords_name ] . attrs [ 'units' ] = y_units return da da = extract_formatted_scene ( scene ) da_resampled = extract_formatted_scene ( resampled_scene ) da_resampled /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'my_index-29d4abca897f6a873de1759d39a81a3b' (y: 1831, x: 1870)> dask.array<copy, shape=(1831, 1870), dtype=float32, chunksize=(1831, 1870), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unknown ba... * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 -3.08e+06 ... 4.384e+06 4.388e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9683646614038233 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2021-01-21 20:45:11.814324 end_time: 2021-01-21 20:50:10.471270 area: Area ID: TM\\nDescription: Transve... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'my_index-29d4abca897f6a873de1759d39a81a3b' y : 1831 x : 1870 dask.array<chunksize=(1831, 1870), meta=np.ndarray> Array Chunk Bytes 13.70 MB 13.70 MB Shape (1831, 1870) (1831, 1870) Count 360 Tasks 1 Chunks Type float32 numpy.ndarray 1870 1831 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Transverse Mercator Datum: Unknown based on WGS84 ellipsoid - Ellipsoid: WGS 84 - Prime Meridian: Greenwich , dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 units : metre array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 units : metre array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9683646614038233 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2021-01-21 20:45:11.814324 end_time : 2021-01-21 20:50:10.471270 area : Area ID: TM Description: Transverse Mercator Projection ID: TM Projection: {'ellps': 'WGS84', 'k': '1', 'lat_0': '0', 'lon_0': '0', 'no_defs': 'None', 'proj': 'tmerc', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 1870 Number of rows: 1831 Area extent: (-3090000, 1690000, 4390000, 9014000) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We'll now save the coordinates of the grid we're using in the new projection new_grid_4km_TM = { 'x_coords' : list ( da_resampled . x . values ), 'y_coords' : list ( da_resampled . y . values ) } save_data = True if save_data == True : with open ( '../data/intermediate/new_grid_4km_TM.json' , 'w' ) as fp : json . dump ( new_grid_4km_TM , fp ) JSON ( new_grid_4km_TM ) <IPython.core.display.JSON object> As well as calculate the locations of those points in the original CRS %% time def chunks ( list_ , n ): \"\"\" Yield successive n-sized chunks from `list_`. \"\"\" for i in range ( 0 , len ( list_ ), n ): yield list_ [ i : i + n ] def reproject_geometries ( da , old_crs , new_crs , chunk_size = 5000 ): xx , yy = np . meshgrid ( da . x . values , da . y . values , indexing = 'ij' ) geometry = gpd . points_from_xy ( xx . flatten (), yy . flatten ()) new_coords_samples = [] for geometry_sample in chunks ( geometry , chunk_size ): df_new_coords_sample = ( gpd . GeoSeries ( geometry_sample , crs = old_crs ) . to_crs ( new_crs ) . apply ( lambda x : list ( x . coords [ 0 ])) . apply ( pd . Series ) . rename ( columns = { 0 : 'x' , 1 : 'y' }) ) new_coords_samples += [ df_new_coords_sample ] df_new_coords = pd . concat ( new_coords_samples , ignore_index = True ) return df_new_coords if not os . path . exists ( intermediate_data_dir ): os . makedirs ( intermediate_data_dir ) if calculate_reproj_coords == True : df_new_coords = reproject_geometries ( da_resampled , '+proj=tmerc' , seviri_crs . proj4_init ) df_new_coords . to_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' , index = False ) elif 'reproj_coords_TM_4km.csv' not in os . listdir ( intermediate_data_dir ): df_new_coords = pd . read_csv ( 'https://storage.googleapis.com/reprojection_cache/reproj_coords_TM_4km.csv' ) else : df_new_coords = pd . read_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' ) df_new_coords . head () Wall time: 1.94 s x y 0 inf inf 1 inf inf 2 inf inf 3 inf inf 4 inf inf We can layer these on top of each other to get an alternative view of the transform operation %% time old_x_positions , old_y_positions = [ elem . flatten () for elem in np . meshgrid ( da . x . values [:: 100 ], da . y . values [:: 100 ], indexing = 'ij' )] new_x_positions , new_y_positions = df_new_coords [ 'x' ][:: 100 ], df_new_coords [ 'y' ][:: 100 ] # Plotting fig , ax = plt . subplots ( dpi = 150 ) ax . scatter ( old_x_positions , old_y_positions , s = 0.1 ) ax . scatter ( new_x_positions , new_y_positions , s = 0.1 ) hlp . hide_spines ( ax ) Wall time: 51 ms We'll now use pyinterp to take these and use them to carry out the resampling. We'll also create a wrapper for converting the result back into an Xarray object. #exports def reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ): x_axis = pyinterp . Axis ( da . x . values ) y_axis = pyinterp . Axis ( da . y . values ) grid = pyinterp . Grid2D ( x_axis , y_axis , da . data . T ) reproj_data = ( pyinterp . bivariate ( grid , x_coords , y_coords ) . reshape (( len ( new_grid [ 'x_coords' ]), len ( new_grid [ 'y_coords' ]))) ) return reproj_data def reproj_to_xarray ( da , x_coords , y_coords , new_grid ): # We'll reproject the data reproj_data = reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ) # Then put it in an XArray DataArray da_reproj = xr . DataArray ( np . flip ( reproj_data . T , axis = ( 0 , 1 )), dims = ( 'y' , 'x' ), coords = { 'x' : new_grid [ 'x_coords' ][:: - 1 ], 'y' : new_grid [ 'y_coords' ][:: - 1 ] }, attrs = da . attrs ) return da_reproj We'll load the grid back in with open ( '../data/intermediate/new_grid_4km_TM.json' , 'r' ) as fp : new_grid = json . load ( fp ) JSON ( new_grid ) <IPython.core.display.JSON object> Confirm that the size of the grid definition arrays match the number of coordinates we have df_new_coords [ 'y' ] . size == len ( new_grid [ 'x_coords' ]) * len ( new_grid [ 'y_coords' ]) True And finally carry out the reprojection %% timeit # if pyinterp not present try : da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) except : pass 860 ms \u00c2\u00b1 53.7 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) Most importantly we'll carry out a visual check that the reprojection was carried out properly. # if pyinterp not present try : da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_reproj . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) except : pass <ipython-input-37-1ffad43e210d>:7: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) Reprojection Wrappers \u00b6 We'll now wrap the individual steps of our resampling approaches within some standalone functions #exports def full_scene_pyresample ( native_fp ): # Loading scene scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) # Constructing target area definition tm_area_def = construct_TM_area_def ( scene ) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da = scene [ dataset_name ] . sortby ( 'y' , ascending = False ) . sortby ( 'x' ) num_y_pixels , num_x_pixels = da . shape seviri_area_def = get_seviri_area_def ( native_fp , num_x_pixels = num_x_pixels , num_y_pixels = num_y_pixels ) resampler = satpy . resample . KDTreeResampler ( seviri_area_def , tm_area_def ) da_reproj = resampler . resample ( da ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = ( xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) . drop ( labels = 'crs' ) ) return ds_reproj def full_scene_pyinterp ( native_fp , new_x_coords , new_y_coords , new_grid_fp ): # Loading data scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) with open ( new_grid_fp , 'r' ) as fp : new_grid = json . load ( fp ) # Correcting x coordinates seviri_area_def = get_seviri_area_def ( native_fp ) area_extent = seviri_area_def . area_extent x_offset = calculate_x_offset ( native_fp ) width = scene [ 'HRV' ] . x . size corrected_x_coords = np . linspace ( area_extent [ 2 ], area_extent [ 0 ], width ) scene [ 'HRV' ] = scene [ 'HRV' ] . assign_coords ({ 'x' : corrected_x_coords }) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da_reproj = reproj_to_xarray ( scene [ dataset_name ], new_x_coords , new_y_coords , new_grid ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) return ds_reproj We'll then create a new Reprojector class which allows us to easily switch between the two and also stores the cached coordinates required for the pyinterp approach #exports class Reprojector : def __init__ ( self , new_coords_fp = None , new_grid_fp = None ): if new_coords_fp is None and new_grid_fp is None : return df_new_coords = pd . read_csv ( new_coords_fp ) self . new_x_coords = df_new_coords [ 'x' ] self . new_y_coords = df_new_coords [ 'y' ] self . new_grid_fp = new_grid_fp return def reproject ( self , native_fp , reproj_library = 'pyresample' ): if reproj_library == 'pyinterp' : ds_reproj = full_scene_pyinterp ( native_fp , self . new_x_coords , self . new_y_coords , self . new_grid_fp ) elif reproj_library == 'pyresample' : ds_reproj = full_scene_pyresample ( native_fp ) else : raise ValueError ( f '`reproj_library` must be one of: pyresample, pyinterp. { reproj_library } can not be passed.' ) return ds_reproj new_coords_fp = f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = Reprojector ( new_coords_fp , new_grid_fp ) reprojector <__main__.Reprojector at 0x1c280222940> We'll quickly compare the speeds between the pyinterp ... %% capture -- no - stdout %% timeit # in case pyinterp is not available: try : ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) except : pass 8.65 s \u00c2\u00b1 908 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) ... and the pyresample methods %% capture -- no - stdout %% timeit reprojector = Reprojector () ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) 6.75 s \u00c2\u00b1 665 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) We'll also visualise one of the reprojections to double-check that everything is working as expected fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-44-7b583bd69917>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x1c298416430>","title":"Data Transformation"},{"location":"02_reprojection/#data-transformation","text":"#exports import json import pandas as pd import xarray as xr import numpy as np import numpy.ma as ma import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import colors import seaborn as sns import os import time from itertools import product from collections import OrderedDict from datetime import datetime from ipypb import track import FEAutils as hlp import satpy from satpy import Scene from satpy.readers import seviri_l1b_native import pyresample from pyresample.geometry import AreaDefinition # pyinterp fails to import on some machines for unknown reasons - leave it optional try : import pyinterp import pyinterp.backends.xarray except : pass We'll separately install libraries that wont be needed for the satip module import rasterio from rasterio import Affine as A from rasterio.warp import reproject , Resampling , calculate_default_transform , transform from rasterio.control import GroundControlPoint from rasterio.transform import xy import geopandas as gpd from shapely.geometry import Point import cartopy.crs as ccrs from IPython.display import JSON","title":"Data Transformation"},{"location":"02_reprojection/#user-input","text":"data_dir = '../data/raw' intermediate_data_dir = '../data/intermediate' calculate_reproj_coords = False","title":"User Input"},{"location":"02_reprojection/#exploratory-data-analysis","text":"We'll start by identifying the available files native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fps [ 0 ] '../data/raw/MSG3-SEVI-MSG15-0100-NA-20210121204918.196000000Z-NA.nat' Then load one of them in as a SatPy scene native_fp = native_fps [ 0 ] scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) scene <satpy.scene.Scene at 0x1c2a2940eb0> We can get a list of the available datasets (bands) scene . all_dataset_names () ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] Each band contains an XArray DataArray scene . load ([ 'HRV' ]) scene [ 'HRV' ] C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'reshape-d4e0a459824b09e38634d18c1de710b4' (y: 4176, x: 5568)> dask.array<mul, shape=(4176, 5568), dtype=float32, chunksize=(1392, 5568), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unknown\",E... * y (y) float64 1.395e+06 1.396e+06 1.397e+06 ... 5.57e+06 5.571e+06 * x (x) float64 2.83e+06 2.829e+06 2.828e+06 ... -2.736e+06 -2.737e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9683646614038233 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2021-01-21 20:45:11.814324 end_time: 2021-01-21 20:50:10.471270 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'reshape-d4e0a459824b09e38634d18c1de710b4' y : 4176 x : 5568 dask.array<chunksize=(1392, 5568), meta=np.ndarray> Array Chunk Bytes 93.01 MB 31.00 MB Shape (4176, 5568) (1392, 5568) Count 214 Tasks 3 Chunks Type float32 numpy.ndarray 5568 4176 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Geostationary Satellite (Sweep Y) Datum: unknown - Ellipsoid: unknown - Prime Meridian: Greenwich , dtype=object) y (y) float64 1.395e+06 1.396e+06 ... 5.571e+06 units : meter array([1395187.416673, 1396187.551022, 1397187.68537 , ..., 5568748.054504, 5569748.188853, 5570748.323202]) x (x) float64 2.83e+06 2.829e+06 ... -2.737e+06 units : meter array([ 2830380.2073 , 2829380.072951, 2828379.938602, ..., -2735367.444158, -2736367.578506, -2737367.712855]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9683646614038233 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2021-01-21 20:45:11.814324 end_time : 2021-01-21 20:50:10.471270 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2830880.2745, 5571248.3904, -2737867.78, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We can see that the DataArray contains a crs, however we'll make our own custom area definition that's more accurate. First we'll create a helper function that will create our area definitions. #exports def calculate_x_offset ( native_fp ): handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) lower_east_column_planned = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] x_offset = 32500 + (( 2733 - lower_east_column_planned ) * 1000 ) return x_offset def get_seviri_area_def ( native_fp , num_x_pixels = 5568 , num_y_pixels = 4176 ) -> AreaDefinition : \"\"\" The HRV channel on Meteosat Second Generation satellites doesn't scan the full number of columns. The east boundary of the HRV channel changes (e.g. to maximise the amount of the image which is illuminated by sunlight. Parameters: native_fp: Data filepath \"\"\" x_offset = calculate_x_offset ( native_fp ) # The EUMETSAT docs say \"The distance between spacecraft and centre of earth is 42,164 km. The idealized earth # is a perfect ellipsoid with an equator radius of 6378.1690 km and a polar radius of 6356.5838 km.\" # The projection used by SatPy expresses height as height above the Earth's surface (not distance # to the centre of the Earth). projection = { 'proj' : 'geos' , 'lon_0' : 9.5 , 'a' : 6378169.0 , 'b' : 6356583.8 , 'h' : 35785831.00 , 'units' : 'm' } seviri = AreaDefinition ( area_id = 'seviri' , description = 'SEVIRI RSS HRV' , proj_id = 'seviri' , projection = projection , width = num_x_pixels , height = num_y_pixels , area_extent = [ - 2768872.0236 + x_offset , # left 1394687.3495 , # bottom (from scene['HRV'].area) 2799876.1893 + x_offset , # right 5570248.4773 ] # top (from scene['HRV'].area) ) return seviri Then we'll use it to construct the relevant one for Seviri seviri = get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () seviri_crs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2021-03-26T14:44:22.150408 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +a=6378169.0 +rf=295.488065897001 +h=35785831.0 +lon_0=9.5 +no_defs=True +proj=geos +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We'll create a loader function that will extract the relevant data for lower_east_column_planned automatically #exports def load_scene ( native_fp ): # Reading scene and loading HRV scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) # Identifying and recording lower_east_column_planned handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) scene . attrs [ 'lower_east_column_planned' ] = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] return scene We'll see how quickly this loads %% time scene = load_scene ( native_fp ) scene . load ([ 'HRV' ]) Wall time: 779 ms C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() We can visualise what a specific band looks like fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x1c2af21bb20> One of the benefits of having access to the underlying XArray object is that we can more easily start to do some analysis with the data, for example defining a reflectance threshold reflectance_threshold = 35 cmap = colors . ListedColormap ([ ( 0 , 0 , 0 , 0 ), # transparent ( 251 / 255 , 242 / 255 , 180 / 255 , 1 ) # yellow # (0.533, 0.808, 0.922, 1) # grey-like blue ]) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , vmin = 0 , vmax = 50 , cmap = 'magma' , add_colorbar = False ) ( scene [ 'HRV' ] > reflectance_threshold ) . plot . imshow ( ax = ax , cmap = cmap , add_colorbar = False ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x1c2a4d10ee0> We'll extract the values from the XArray object, then mask all NaN values to enable us to carry out statistical analysis HRV = scene [ \"HRV\" ] . values HRV_masked = ma . masked_array ( HRV , mask = xr . ufuncs . isnan ( scene [ \"HRV\" ]) . values ) np . mean ( HRV_masked ) 0.03837633008116254 We can also visualise the full distribution. N.b. to reduce the time it takes to calculate the best KDE fit we'll take only a sample of the data. HRV_sample = np . random . choice ( HRV_masked . flatten (), 1_000_000 ) # Plotting fig , ax = plt . subplots ( dpi = 250 ) sns . kdeplot ( HRV_sample , ax = ax , fill = True ) ax . set_yticks ([]) ax . set_ylabel ( '' ) ax . set_xlabel ( 'HRV Reflectance' ) hlp . hide_spines ( ax , positions = [ 'top' , 'left' , 'right' ])","title":"Exploratory Data Analysis"},{"location":"02_reprojection/#evaluating-reprojection-to-tranverse-mercator","text":"Before we can resample we need to define the area we're resampling to, we'll write a constructor to help us do this #exports def construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , pixel_size = None ): # If None then will use same number of x and y points # HRV's resolution will be more like 4km for Europe if pixel_size is not None : width = int (( east - west ) / pixel_size ) height = int (( north - south ) / pixel_size ) else : width = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . x . values . shape [ 0 ] height = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . y . values . shape [ 0 ] area_extent = ( west , south , east , north ) area_def = AreaDefinition ( area_id , description , proj_id , projection , width , height , area_extent ) return area_def def construct_TM_area_def ( scene ): meters_per_pixel = 4000 west , south , east , north = ( - 3090000 , 1690000 , 4390000 , 9014000 ) area_id = 'TM' description = 'Transverse Mercator' proj_id = 'TM' projection = { 'ellps' : 'WGS84' , 'proj' : 'tmerc' , # Transverse Mercator 'units' : 'm' # meters } tm_area_def = construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , meters_per_pixel ) return tm_area_def tm_area_def = construct_TM_area_def ( scene ) tm_area_def . to_cartopy_crs () C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2021-03-26T14:44:44.261206 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +k=1.0 +lat_0=0.0 +lon_0=0.0 +no_defs=True +proj=tmerc +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We can now carry out the resampling using the pyresample library %% time resampled_scene = scene . resample ( tm_area_def , resampler = 'nearest' ) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:123: RuntimeWarning: invalid value encountered in true_divide self.cart /= np.sqrt(np.einsum('...i, ...i', self.cart, self.cart)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:178: RuntimeWarning: invalid value encountered in double_scalars return (val + mod) % (2 * mod) - mod C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() Wall time: 4.81 s We'll quickly check that the reprojection looks ok fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-20-ec0e500c536a>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x1c2b58957f0> We want to gain a deeper understanding of the reprojection that's being carried out, to do this we'll manually reproject a sample of the original gridded coordinates %% time orig_x_values = scene [ 'HRV' ] . x . values [:: 50 ] orig_y_values = scene [ 'HRV' ] . y . values [:: 50 ] XX , YY = np . meshgrid ( orig_x_values , orig_y_values ) df_proj_points = ( gpd . GeoSeries ([ Point ( x , y ) for x , y in np . stack ([ XX . flatten (), YY . flatten ()], axis = 1 ) ]) . set_crs ( crs = scene [ 'HRV' ] . area . crs_wkt ) . to_crs ( crs = resampled_scene [ 'HRV' ] . area . crs_wkt ) . apply ( lambda point : pd . Series ( list ( point . coords )[ 0 ])) . rename ( columns = { 0 : 'x_reproj' , 1 : 'y_reproj' }) . replace ( np . inf , np . nan ) . pipe ( lambda df : df . assign ( x_orig = XX . flatten ())) . pipe ( lambda df : df . assign ( y_orig = YY . flatten ())) ) df_proj_points . head () Wall time: 8.13 s x_reproj y_reproj x_orig y_orig 0 4.3395e+06 1.80726e+06 2.83038e+06 1.39519e+06 1 4.26554e+06 1.79291e+06 2.78037e+06 1.39519e+06 2 4.19261e+06 1.77906e+06 2.73037e+06 1.39519e+06 3 4.12066e+06 1.76567e+06 2.68036e+06 1.39519e+06 4 4.04965e+06 1.75274e+06 2.63035e+06 1.39519e+06 We can then visualise the reprojection of the original grid against the regridded reprojection %% time fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) ax . scatter ( df_proj_points [ 'x_reproj' ][:: 10 ], df_proj_points [ 'y_reproj' ][:: 10 ], s = 2 , color = 'red' ) <timed exec>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) Wall time: 20.8 s <matplotlib.collections.PathCollection at 0x1c2af1a3400> This is useful for quick visual inspection, for example we can see that the y axis gets stretched further the nearer to the pole. However, we want to get a better understanding of how the local cell resolution is changing for any given point, we'll begin by looking at this change for Greenwich. def lon_lat_to_new_crs ( lon , lat , crs ): x , y = list ( gpd . GeoSeries ([ Point ( lon , lat )]) . set_crs ( 4326 ) . to_crs ( crs ) . iloc [ 0 ] . coords )[ 0 ] return x , y def calc_res_change ( src_x , src_y , src_da , dst_da , src_dx = 10 , src_dy = 10 ): src_crs = src_da . area . crs_wkt dst_crs = dst_da . area . crs_wkt src_x_width = np . abs ( np . diff ( src_da . x . values )[ 0 ]) src_y_width = np . abs ( np . diff ( src_da . y . values )[ 0 ]) dst_x_width = np . abs ( np . diff ( dst_da . x . values )[ 0 ]) dst_y_width = np . abs ( np . diff ( dst_da . y . values )[ 0 ]) s_points = ( gpd . GeoSeries ([ Point ( src_x , src_y ), Point ( src_x + src_dx , src_y ), Point ( src_x , src_y + src_dy ) ]) . set_crs ( src_crs ) . to_crs ( dst_crs ) ) dst_dx = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) dst_dy = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) x_ratio_change = ( dst_dx / dst_x_width ) / ( src_dx / src_x_width ) y_ratio_change = ( dst_dy / dst_y_width ) / ( src_dy / src_y_width ) return x_ratio_change , y_ratio_change lon = 0 lat = 51.4934 src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) x_ratio_change , y_ratio_change = calc_res_change ( src_x , src_y , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) x_ratio_change , y_ratio_change (0.27381567467569573, 0.528776076616483) We'll double check this by calculating it through a different method, in this case by locating the nearest cell for each scene and comparing their sizes in a common coordinate system def get_da_nearest_cell_width_height ( da , x , y , units_crs ): nearest_loc = da . sel ( x = x , y = y , method = 'nearest' ) nearest_x = nearest_loc . x . values nearest_y = nearest_loc . y . values next_nearest_x = da . x . values [ list ( da . x . values ) . index ( nearest_x ) + 1 ] next_nearest_y = da . y . values [ list ( da . y . values ) . index ( nearest_y ) + 1 ] s_points = ( gpd . GeoSeries ([ Point ( nearest_x , nearest_y ), Point ( next_nearest_x , nearest_y ), Point ( nearest_x , next_nearest_y ) ]) . set_crs ( da . area . crs_wkt ) . to_crs ( units_crs ) ) x_width = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) y_height = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) return x_width , y_height src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , resampled_scene [ 'HRV' ] . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( resampled_scene [ 'HRV' ], dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) The width has changed from 1.09 km to 4.0 km The height has changed from 2.12 km to 4.0 km This can easily be converted into a x and y pixel size ratio change which almost exactly matches our previous calculation. The first calculation is more accurate as the dx and dy can approach 0 and get closer to the true ratio change, however the get_da_nearest_cell_width_height function is still useful as it allows us to determine the cell width and height in more interpretable units x_ratio_change , y_ratio_change = src_x_width / dst_x_width , src_y_height / dst_y_height x_ratio_change , y_ratio_change (0.2738180115545141, 0.5290020702784486) Iceland is stretched further still def print_pixel_change ( lon , lat , da_src , da_dst ): src_x , src_y = lon_lat_to_new_crs ( lon , lat , da_src . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , da_dst . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( da_src , src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( da_dst , dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) return lon = - 18.779208 lat = 64.887370 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.52 km to 3.99 km The height has changed from 4.75 km to 3.99 km And contrasts with Marrakesh which is stretched less than Greenwich in the y axis lon = - 8.005657 lat = 31.636355 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km We can check what the cell height and width are at the center of the image, they should both be close to 1km according to the SEVIRI documentation LineDirGridStep gives the grid step size in km SSP in the line direction. Default value is 3km for VIS and IR, and 1km for HRV. The on-ground grid step size of 3 km at the SSP represents an instrument scan step of 251.53 microrad divided by 3. - EUMETSAT round_m_to_km = lambda m : round ( m / 1000 , 2 ) UTM_35N_epsg = 32632 # should be relatively accurate and is in meters src_x = np . median ( scene [ 'HRV' ] . x . values ) src_y = np . median ( scene [ 'HRV' ] . y . values ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , UTM_35N_epsg ) round_m_to_km ( src_x_width ), round_m_to_km ( src_y_height ) (1.03, 1.36)","title":"Evaluating Reprojection to Tranverse Mercator"},{"location":"02_reprojection/#comparing-reprojection-libraries","text":"In the last section we used pyresample to carry out the data reprojection, here we'll explore pyinterp . Before we start we'll quickly extract the xarrays for the original and reprojected coordinates. def extract_formatted_scene ( scene , variable = 'HRV' , x_coords_name = 'x' , y_coords_name = 'y' , x_units = 'metre' , y_units = 'metre' ): da = ( scene [ variable ] . copy () . rename ({ 'x' : x_coords_name , 'y' : y_coords_name }) ) da [ x_coords_name ] . attrs [ 'units' ] = x_units da [ y_coords_name ] . attrs [ 'units' ] = y_units return da da = extract_formatted_scene ( scene ) da_resampled = extract_formatted_scene ( resampled_scene ) da_resampled /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'my_index-29d4abca897f6a873de1759d39a81a3b' (y: 1831, x: 1870)> dask.array<copy, shape=(1831, 1870), dtype=float32, chunksize=(1831, 1870), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unknown ba... * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 -3.08e+06 ... 4.384e+06 4.388e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9683646614038233 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2021-01-21 20:45:11.814324 end_time: 2021-01-21 20:50:10.471270 area: Area ID: TM\\nDescription: Transve... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'my_index-29d4abca897f6a873de1759d39a81a3b' y : 1831 x : 1870 dask.array<chunksize=(1831, 1870), meta=np.ndarray> Array Chunk Bytes 13.70 MB 13.70 MB Shape (1831, 1870) (1831, 1870) Count 360 Tasks 1 Chunks Type float32 numpy.ndarray 1870 1831 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Transverse Mercator Datum: Unknown based on WGS84 ellipsoid - Ellipsoid: WGS 84 - Prime Meridian: Greenwich , dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 units : metre array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 units : metre array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9683646614038233 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2021-01-21 20:45:11.814324 end_time : 2021-01-21 20:50:10.471270 area : Area ID: TM Description: Transverse Mercator Projection ID: TM Projection: {'ellps': 'WGS84', 'k': '1', 'lat_0': '0', 'lon_0': '0', 'no_defs': 'None', 'proj': 'tmerc', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 1870 Number of rows: 1831 Area extent: (-3090000, 1690000, 4390000, 9014000) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We'll now save the coordinates of the grid we're using in the new projection new_grid_4km_TM = { 'x_coords' : list ( da_resampled . x . values ), 'y_coords' : list ( da_resampled . y . values ) } save_data = True if save_data == True : with open ( '../data/intermediate/new_grid_4km_TM.json' , 'w' ) as fp : json . dump ( new_grid_4km_TM , fp ) JSON ( new_grid_4km_TM ) <IPython.core.display.JSON object> As well as calculate the locations of those points in the original CRS %% time def chunks ( list_ , n ): \"\"\" Yield successive n-sized chunks from `list_`. \"\"\" for i in range ( 0 , len ( list_ ), n ): yield list_ [ i : i + n ] def reproject_geometries ( da , old_crs , new_crs , chunk_size = 5000 ): xx , yy = np . meshgrid ( da . x . values , da . y . values , indexing = 'ij' ) geometry = gpd . points_from_xy ( xx . flatten (), yy . flatten ()) new_coords_samples = [] for geometry_sample in chunks ( geometry , chunk_size ): df_new_coords_sample = ( gpd . GeoSeries ( geometry_sample , crs = old_crs ) . to_crs ( new_crs ) . apply ( lambda x : list ( x . coords [ 0 ])) . apply ( pd . Series ) . rename ( columns = { 0 : 'x' , 1 : 'y' }) ) new_coords_samples += [ df_new_coords_sample ] df_new_coords = pd . concat ( new_coords_samples , ignore_index = True ) return df_new_coords if not os . path . exists ( intermediate_data_dir ): os . makedirs ( intermediate_data_dir ) if calculate_reproj_coords == True : df_new_coords = reproject_geometries ( da_resampled , '+proj=tmerc' , seviri_crs . proj4_init ) df_new_coords . to_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' , index = False ) elif 'reproj_coords_TM_4km.csv' not in os . listdir ( intermediate_data_dir ): df_new_coords = pd . read_csv ( 'https://storage.googleapis.com/reprojection_cache/reproj_coords_TM_4km.csv' ) else : df_new_coords = pd . read_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' ) df_new_coords . head () Wall time: 1.94 s x y 0 inf inf 1 inf inf 2 inf inf 3 inf inf 4 inf inf We can layer these on top of each other to get an alternative view of the transform operation %% time old_x_positions , old_y_positions = [ elem . flatten () for elem in np . meshgrid ( da . x . values [:: 100 ], da . y . values [:: 100 ], indexing = 'ij' )] new_x_positions , new_y_positions = df_new_coords [ 'x' ][:: 100 ], df_new_coords [ 'y' ][:: 100 ] # Plotting fig , ax = plt . subplots ( dpi = 150 ) ax . scatter ( old_x_positions , old_y_positions , s = 0.1 ) ax . scatter ( new_x_positions , new_y_positions , s = 0.1 ) hlp . hide_spines ( ax ) Wall time: 51 ms We'll now use pyinterp to take these and use them to carry out the resampling. We'll also create a wrapper for converting the result back into an Xarray object. #exports def reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ): x_axis = pyinterp . Axis ( da . x . values ) y_axis = pyinterp . Axis ( da . y . values ) grid = pyinterp . Grid2D ( x_axis , y_axis , da . data . T ) reproj_data = ( pyinterp . bivariate ( grid , x_coords , y_coords ) . reshape (( len ( new_grid [ 'x_coords' ]), len ( new_grid [ 'y_coords' ]))) ) return reproj_data def reproj_to_xarray ( da , x_coords , y_coords , new_grid ): # We'll reproject the data reproj_data = reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ) # Then put it in an XArray DataArray da_reproj = xr . DataArray ( np . flip ( reproj_data . T , axis = ( 0 , 1 )), dims = ( 'y' , 'x' ), coords = { 'x' : new_grid [ 'x_coords' ][:: - 1 ], 'y' : new_grid [ 'y_coords' ][:: - 1 ] }, attrs = da . attrs ) return da_reproj We'll load the grid back in with open ( '../data/intermediate/new_grid_4km_TM.json' , 'r' ) as fp : new_grid = json . load ( fp ) JSON ( new_grid ) <IPython.core.display.JSON object> Confirm that the size of the grid definition arrays match the number of coordinates we have df_new_coords [ 'y' ] . size == len ( new_grid [ 'x_coords' ]) * len ( new_grid [ 'y_coords' ]) True And finally carry out the reprojection %% timeit # if pyinterp not present try : da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) except : pass 860 ms \u00c2\u00b1 53.7 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) Most importantly we'll carry out a visual check that the reprojection was carried out properly. # if pyinterp not present try : da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_reproj . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) except : pass <ipython-input-37-1ffad43e210d>:7: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator())","title":"Comparing Reprojection Libraries"},{"location":"02_reprojection/#reprojection-wrappers","text":"We'll now wrap the individual steps of our resampling approaches within some standalone functions #exports def full_scene_pyresample ( native_fp ): # Loading scene scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) # Constructing target area definition tm_area_def = construct_TM_area_def ( scene ) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da = scene [ dataset_name ] . sortby ( 'y' , ascending = False ) . sortby ( 'x' ) num_y_pixels , num_x_pixels = da . shape seviri_area_def = get_seviri_area_def ( native_fp , num_x_pixels = num_x_pixels , num_y_pixels = num_y_pixels ) resampler = satpy . resample . KDTreeResampler ( seviri_area_def , tm_area_def ) da_reproj = resampler . resample ( da ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = ( xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) . drop ( labels = 'crs' ) ) return ds_reproj def full_scene_pyinterp ( native_fp , new_x_coords , new_y_coords , new_grid_fp ): # Loading data scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) with open ( new_grid_fp , 'r' ) as fp : new_grid = json . load ( fp ) # Correcting x coordinates seviri_area_def = get_seviri_area_def ( native_fp ) area_extent = seviri_area_def . area_extent x_offset = calculate_x_offset ( native_fp ) width = scene [ 'HRV' ] . x . size corrected_x_coords = np . linspace ( area_extent [ 2 ], area_extent [ 0 ], width ) scene [ 'HRV' ] = scene [ 'HRV' ] . assign_coords ({ 'x' : corrected_x_coords }) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da_reproj = reproj_to_xarray ( scene [ dataset_name ], new_x_coords , new_y_coords , new_grid ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) return ds_reproj We'll then create a new Reprojector class which allows us to easily switch between the two and also stores the cached coordinates required for the pyinterp approach #exports class Reprojector : def __init__ ( self , new_coords_fp = None , new_grid_fp = None ): if new_coords_fp is None and new_grid_fp is None : return df_new_coords = pd . read_csv ( new_coords_fp ) self . new_x_coords = df_new_coords [ 'x' ] self . new_y_coords = df_new_coords [ 'y' ] self . new_grid_fp = new_grid_fp return def reproject ( self , native_fp , reproj_library = 'pyresample' ): if reproj_library == 'pyinterp' : ds_reproj = full_scene_pyinterp ( native_fp , self . new_x_coords , self . new_y_coords , self . new_grid_fp ) elif reproj_library == 'pyresample' : ds_reproj = full_scene_pyresample ( native_fp ) else : raise ValueError ( f '`reproj_library` must be one of: pyresample, pyinterp. { reproj_library } can not be passed.' ) return ds_reproj new_coords_fp = f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = Reprojector ( new_coords_fp , new_grid_fp ) reprojector <__main__.Reprojector at 0x1c280222940> We'll quickly compare the speeds between the pyinterp ... %% capture -- no - stdout %% timeit # in case pyinterp is not available: try : ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) except : pass 8.65 s \u00c2\u00b1 908 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) ... and the pyresample methods %% capture -- no - stdout %% timeit reprojector = Reprojector () ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) 6.75 s \u00c2\u00b1 665 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) We'll also visualise one of the reprojections to double-check that everything is working as expected fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-44-7b583bd69917>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x1c298416430>","title":"Reprojection Wrappers"},{"location":"03_zarr/","text":"Zarr \u00b6 Imports \u00b6 C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.28rows/s] import os import dotenv import matplotlib.pyplot as plt import cartopy.crs as ccrs from IPython.display import JSON User Inputs \u00b6 data_dir = '../data/raw' metadata_db_fp = '../data/EUMETSAT_metadata.db' debug_fp = '../logs/EUMETSAT_download.txt' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' new_coords_fp = '../data/intermediate/reproj_coords_TM_4km.csv' in_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr' out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16' Loading Environment Variables \u00b6 dotenv . load_dotenv ( '../.env' ) user_key = os . environ . get ( 'USER_KEY' ) user_secret = os . environ . get ( 'USER_SECRET' ) slack_id = os . environ . get ( 'SLACK_ID' ) slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ) Preparing Data to Save to Zarr \u00b6 We'll start by loading in one of the datasets we've just downloaded, in this instance we'll take the most recent one by identifying it from the metadata db. dm = eumetsat . DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp ) df_metadata = dm . get_df_metadata () df_metadata . tail () 2021-03-19 13:36:06,283 - INFO - ********** Download Manager Initialised ************** ('Unnamed: 0_level_0', 'id') ('start_date', 'Unnamed: 1_level_1') ('end_date', 'Unnamed: 2_level_1') ('result_time', 'Unnamed: 3_level_1') ('platform_short_name', 'Unnamed: 4_level_1') ('platform_orbit_type', 'Unnamed: 5_level_1') ('instrument_name', 'Unnamed: 6_level_1') ('sensor_op_mode', 'Unnamed: 7_level_1') ('center_srs_name', 'Unnamed: 8_level_1') ('center_position', 'Unnamed: 9_level_1') ('file_name', 'Unnamed: 10_level_1') ('file_size', 'Unnamed: 11_level_1') ('missing_pct', 'Unnamed: 12_level_1') ('downloaded', 'Unnamed: 13_level_1') 22 2021-03-19 13:00:09.714 2021-03-19 13:04:16.088 2021-03-19 13:04:16.088 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319130416.0880000... 99819 59 2021-03-19 13:32:31.390670 23 2021-03-19 13:05:09.569 2021-03-19 13:09:15.943 2021-03-19 13:09:15.943 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319130915.9430000... 99819 0 2021-03-19 13:32:36.178702 24 2021-03-19 13:10:09.423 2021-03-19 13:14:15.798 2021-03-19 13:14:15.798 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319131415.7980000... 99819 0 2021-03-19 13:32:40.347753 25 2021-03-19 13:15:09.278 2021-03-19 13:19:15.652 2021-03-19 13:19:15.652 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319131915.6520000... 99819 62 2021-03-19 13:32:44.720295 26 2021-03-19 13:20:10.335 2021-03-19 13:24:16.708 2021-03-19 13:24:16.708 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319132416.7080000... 99819 0 2021-03-19 13:32:48.922629 We'll then load in the file filename = df_metadata . loc [ df_metadata . index [ - 2 ], 'file_name' ] native_fp = f ' { data_dir } / { filename } .nat' severi_area_def = reproj . get_seviri_area_def ( native_fp ) seviri_crs = severi_area_def . to_cartopy_crs () scene = reproj . load_scene ( native_fp ) scene . load ([ 'HRV' ]) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/pyproj/crs/crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/pyproj/crs/crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() And visualise it to test that everything is working fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fc2c8619880> We now need to reproject it %% capture -- no - stdout %% time reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) CPU times: user 2.23 s, sys: 104 ms, total: 2.33 s Wall time: 2.38 s Which again we'll check through visualisation fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-10-53f177b0781d>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fc2c86dd9a0> ds_reproj [ 'stacked_eumetsat_data' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (variable: 12, y: 1831, x: 1870)> dask.array<concatenate, shape=(12, 1831, 1870), dtype=float32, chunksize=(1, 1831, 1870), chunktype=numpy.ndarray> Coordinates: * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * variable (variable) object 'HRV' 'IR_016' 'IR_039' ... 'WV_062' 'WV_073' Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9911189780118609 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2021-03-19 13:15:09.278906 end_time: 2021-03-19 13:20:10.330158 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'stacked_eumetsat_data' variable : 12 y : 1831 x : 1870 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9911189780118609 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2021-03-19 13:15:09.278906 end_time : 2021-03-19 13:20:10.330158 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Compressing \u00b6 We'll now develop our compressor class that will reduce the size of the datasets that we save to Zarr, in this instance we'll normalize the data and transform it to Int16. This has been found to reduce the size by ~50%. #exports def add_constant_coord_to_da ( da , coord_name , coord_val ): \"\"\" Adds a new coordinate with a constant value to the DataArray Parameters ---------- da : xr.DataArray DataArrray which will have the new coords added to it coord_name : str Name for the new coordinate dimensions coord_val Value that will be assigned to the new coordinates Returns ------- da : xr.DataArray DataArrray with the new coords added to it \"\"\" da = ( da . assign_coords ({ coord_name : coord_val }) . expand_dims ( coord_name ) ) return da class Compressor : def __init__ ( self , bits_per_pixel = 10 , mins = np . array ([ - 1.2278595 , - 2.5118103 , - 64.83977 , 63.404694 , 2.844452 , 199.10002 , - 17.254883 , - 26.29155 , - 1.1009827 , - 2.4184198 , 199.57048 , 198.95093 ]), maxs = np . array ([ 103.90016 , 69.60857 , 339.15588 , 340.26526 , 317.86752 , 313.2767 , 315.99194 , 274.82297 , 93.786545 , 101.34922 , 249.91806 , 286.96323 ]), variable_order = [ 'HRV' , 'IR_016' , 'IR_039' , 'IR_087' , 'IR_097' , 'IR_108' , 'IR_120' , 'IR_134' , 'VIS006' , 'VIS008' , 'WV_062' , 'WV_073' ] ): locals_ = locals () attrs_to_add = [ 'bits_per_pixel' , 'mins' , 'maxs' , 'variable_order' ] for attr in attrs_to_add : setattr ( self , attr , locals_ [ attr ]) return def fit ( self , da , dims = [ 'time' , 'y' , 'x' ]): self . mins = da . min ( dims ) . compute () self . maxs = da . max ( dims ) . compute () self . variable_order = da . coords [ 'variable' ] . values print ( f 'The mins are: { self . mins } ' ) print ( f 'The maxs are: { self . maxs } ' ) print ( f 'The variable order is: { self . variable_order } ' ) return def compress ( self , da ): da_meta = da . attrs for attr in [ 'mins' , 'maxs' ]: assert getattr ( self , attr ) is not None , f ' { attr } must be set in initialisation or through `fit`' if 'time' not in da . dims : time = pd . to_datetime ( da_meta [ 'end_time' ]) da = add_constant_coord_to_da ( da , 'time' , time ) da = ( da . reindex ({ 'variable' : self . variable_order }) . transpose ( 'time' , 'y' , 'x' , 'variable' ) ) upper_bound = ( 2 ** self . bits_per_pixel ) - 1 new_max = self . maxs - self . mins da -= self . mins da /= new_max da *= upper_bound da = ( da . clip ( 0 , upper_bound ) . fillna ( - 1 ) . round () . astype ( np . int16 ) ) da . attrs = { 'meta' : str ( da_meta )} # Must be serialisable return da %% time compressor = Compressor () da_compressed = compressor . compress ( ds_reproj [ 'stacked_eumetsat_data' ]) CPU times: user 10.7 ms, sys: 1.96 ms, total: 12.7 ms Wall time: 12.6 ms Saving to Zarr \u00b6 We'll now create a helper function for saving the data-array to a zarr database # exports get_time_as_unix = lambda da : pd . Series (( pd . to_datetime ( da . time . values ) - pd . Timestamp ( '1970-01-01' )) . total_seconds ()) . astype ( int ) . values def save_da_to_zarr ( da , zarr_bucket , dim_order = [ 'time' , 'x' , 'y' , 'variable' ], zarr_mode = 'a' ): da = da . transpose ( * dim_order ) da [ 'time' ] = get_time_as_unix ( da ) _ , y_size , x_size , _ = da . shape out_store = gcsfs . GCSMap ( root = zarr_bucket , gcs = gcsfs . GCSFileSystem ()) chunks = ( 36 , y_size , x_size , 1 ) ds = xr . Dataset ({ 'stacked_eumetsat_data' : da . chunk ( chunks )}) zarr_mode_to_extra_kwargs = { 'a' : { 'append_dim' : 'time' }, 'w' : { 'encoding' : { 'stacked_eumetsat_data' : { 'compressor' : numcodecs . Blosc ( cname = 'zstd' , clevel = 5 ), 'chunks' : chunks } } } } assert zarr_mode in [ 'a' , 'w' ], '`zarr_mode` must be one of: `a`, `w`' extra_kwargs = zarr_mode_to_extra_kwargs [ zarr_mode ] ds . to_zarr ( out_store , mode = zarr_mode , consolidated = True , ** extra_kwargs ) print ( 'Saved file to zarr bucket' ) return ds da_compressed /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 1, y: 1831, x: 1870, variable: 12)> dask.array<astype, shape=(1, 1831, 1870, 12), dtype=int16, chunksize=(1, 1831, 1870, 1), chunktype=numpy.ndarray> Coordinates: * variable (variable) object 'HRV' 'IR_016' 'IR_039' ... 'WV_062' 'WV_073' * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * time (time) datetime64[ns] 2021-03-19T13:20:10.330158 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 1 y : 1831 x : 1870 variable : 12 dask.array<chunksize=(1, 1831, 1870, 1), meta=np.ndarray> Array Chunk Bytes 82.18 MB 6.85 MB Shape (1, 1831, 1870, 12) (1, 1831, 1870, 1) Count 1505 Tasks 12 Chunks Type int16 numpy.ndarray 1 1 12 1870 1831 Coordinates: (4) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) time (time) datetime64[ns] 2021-03-19T13:20:10.330158 array(['2021-03-19T13:20:10.330158000'], dtype='datetime64[ns]') Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Now we can save it! save_data = False if save_data == True : out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' ds = save_da_to_zarr ( da_compressed , out_zarr_bucket , zarr_mode = 'w' ) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: divide by zero encountered in true_divide return func(*(_execute_task(a, cache) for a in args)) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) Saved file to zarr bucket Loading Zarr Data \u00b6 We'll start by defining a loading function and a replacement for the standard gcsfs.utils is_retriable function #exports def is_retriable ( exception ): \"\"\"Returns True if this exception is retriable.\"\"\" errors = list ( range ( 500 , 505 )) + [ 400 , # Jack's addition. Google Cloud occasionally throws Bad Requests for no apparent reason. 408 , # Request Timeout 429 , # Too Many Requests ] errors += [ str ( e ) for e in errors ] if isinstance ( exception , gcsfs . utils . HttpError ): return exception . code in errors return isinstance ( exception , gcsfs . utils . RETRIABLE_EXCEPTIONS ) gcsfs . utils . is_retriable = is_retriable get_unix_as_time = lambda da : pd . to_datetime ( da . time . values , unit = 's' ) def load_from_zarr_bucket ( zarr_bucket ): gcs = gcsfs . GCSFileSystem () store = gcsfs . GCSMap ( root = zarr_bucket , gcs = gcs ) ds = xr . open_zarr ( store , consolidated = True ) ds [ 'time' ] = get_unix_as_time ( ds ) return ds We'll now read it in %% time out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' ds_zarr = load_from_zarr_bucket ( out_zarr_bucket ) ds_zarr . time . compute () CPU times: user 4.14 s, sys: 1.7 s, total: 5.84 s Wall time: 21.3 s /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'time' (time: 5816)> array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-03-14T23:49:18.000000000', '2020-03-14T23:54:17.000000000', '2020-03-14T23:59:15.000000000'], dtype='datetime64[ns]') Coordinates: * time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-03-14T23:59:15 xarray.DataArray 'time' time : 5816 2021-03-19T13:20:10 2021-03-19T13:24:16 ... 2020-03-14T23:59:15 array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-03-14T23:49:18.000000000', '2020-03-14T23:54:17.000000000', '2020-03-14T23:59:15.000000000'], dtype='datetime64[ns]') Coordinates: (1) time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-03-... array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-03-14T23:49:18.000000000', '2020-03-14T23:54:17.000000000', '2020-03-14T23:59:15.000000000'], dtype='datetime64[ns]') Attributes: (0) Let's inspect the current datetime coverage in the database #exports def plot_zarr_data ( loaded_xarray ): df = loaded_xarray . time . to_dataframe () df [ 'time' ] = 1 df = df . resample ( 'D' ) . sum () # rather than messing with formatter, set index to a readable date format of Year-Month df = df . set_index ( df . index . map ( lambda s : s . strftime ( '%Y-%m' ))) # plot fig , ax = plt . subplots ( figsize = ( 6 , 6 ), dpi = 150 ) sns . heatmap ( df , ax = ax , cmap = 'Blues' , xticklabels = False ) ax . set ( title = \"Count of timesteps by day in Zarr datastore\" ) # reduce tick counts plt . locator_params ( axis = 'y' , nbins = 10 ) plot_zarr_data ( loaded_xarray ) We'll also plot the a sample of the loaded array fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) loaded_xarray [ 'stacked_eumetsat_data' ] . isel ( variable = 0 , time = 0 ) . T . plot ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-26-f7e189d5f897>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fc2df31c0a0> We can also identify missing datasets which will be useful for filling them in later #exports def identifying_missing_datasets ( start_date , end_date , eumetsat_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' ): # constructing the monthly split month_split = pd . date_range ( start_date , end_date , freq = \"MS\" ) # handling date range less than a month if len ( month_split ) <= 1 : month_split = [ start_date , end_date ] # identifying missing datasets in each split missing_datasets = [] warn ( f 'Earliest { start_date } , latest { end_date } ' ) for i in range ( len ( month_split ) - 1 ): # Identifying all potential datasets over specified date range datasets = eumetsat . identify_available_datasets ( month_split [ i ], month_split [ i + 1 ]) # Extracting the datetime each dataset was finished end_dates = [ dataset [ 'properties' ][ 'date' ] . split ( '/' )[ - 1 ] for dataset in datasets ] try : cleaned_end_dates = pd . to_datetime ( end_dates ) . floor ( freq = 's' ) . tz_localize ( 'UTC' ) . tz_convert ( None ) except : cleaned_end_dates = pd . to_datetime ( end_dates ) . floor ( freq = 's' ) . tz_convert ( None ) # Identifying missing datasets from the Zarr DB ds_eumetsat = load_from_zarr_bucket ( eumetsat_zarr_bucket ) end_dates_to_datasets = dict ( zip ( cleaned_end_dates , datasets )) missing_dates = set ( cleaned_end_dates ) - set ( pd . to_datetime ( ds_eumetsat . time . values )) missing_datasets . append ([ data for date , data in end_dates_to_datasets . items () if date in missing_dates ]) flat_list = [ item for sublist in missing_datasets for item in sublist ] return flat_list missing_datasets = identifying_missing_datasets ( \"2020-01-01T00:00:00\" , \"2020-01-01T01:00:00\" ) JSON ( missing_datasets ) Earliest 2020-01-01T00:00:00, latest 2020-01-01T01:00:00 100% 1/1 [00:04 < 00:04, 3.91s/it] identify_available_datasets: found 12 results from API <IPython.core.display.JSON object>","title":"Saving with Zarr"},{"location":"03_zarr/#zarr","text":"","title":"Zarr"},{"location":"03_zarr/#imports","text":"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.28rows/s] import os import dotenv import matplotlib.pyplot as plt import cartopy.crs as ccrs from IPython.display import JSON","title":"Imports"},{"location":"03_zarr/#user-inputs","text":"data_dir = '../data/raw' metadata_db_fp = '../data/EUMETSAT_metadata.db' debug_fp = '../logs/EUMETSAT_download.txt' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' new_coords_fp = '../data/intermediate/reproj_coords_TM_4km.csv' in_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr' out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16'","title":"User Inputs"},{"location":"03_zarr/#loading-environment-variables","text":"dotenv . load_dotenv ( '../.env' ) user_key = os . environ . get ( 'USER_KEY' ) user_secret = os . environ . get ( 'USER_SECRET' ) slack_id = os . environ . get ( 'SLACK_ID' ) slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' )","title":"Loading Environment Variables"},{"location":"03_zarr/#preparing-data-to-save-to-zarr","text":"We'll start by loading in one of the datasets we've just downloaded, in this instance we'll take the most recent one by identifying it from the metadata db. dm = eumetsat . DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp ) df_metadata = dm . get_df_metadata () df_metadata . tail () 2021-03-19 13:36:06,283 - INFO - ********** Download Manager Initialised ************** ('Unnamed: 0_level_0', 'id') ('start_date', 'Unnamed: 1_level_1') ('end_date', 'Unnamed: 2_level_1') ('result_time', 'Unnamed: 3_level_1') ('platform_short_name', 'Unnamed: 4_level_1') ('platform_orbit_type', 'Unnamed: 5_level_1') ('instrument_name', 'Unnamed: 6_level_1') ('sensor_op_mode', 'Unnamed: 7_level_1') ('center_srs_name', 'Unnamed: 8_level_1') ('center_position', 'Unnamed: 9_level_1') ('file_name', 'Unnamed: 10_level_1') ('file_size', 'Unnamed: 11_level_1') ('missing_pct', 'Unnamed: 12_level_1') ('downloaded', 'Unnamed: 13_level_1') 22 2021-03-19 13:00:09.714 2021-03-19 13:04:16.088 2021-03-19 13:04:16.088 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319130416.0880000... 99819 59 2021-03-19 13:32:31.390670 23 2021-03-19 13:05:09.569 2021-03-19 13:09:15.943 2021-03-19 13:09:15.943 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319130915.9430000... 99819 0 2021-03-19 13:32:36.178702 24 2021-03-19 13:10:09.423 2021-03-19 13:14:15.798 2021-03-19 13:14:15.798 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319131415.7980000... 99819 0 2021-03-19 13:32:40.347753 25 2021-03-19 13:15:09.278 2021-03-19 13:19:15.652 2021-03-19 13:19:15.652 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319131915.6520000... 99819 62 2021-03-19 13:32:44.720295 26 2021-03-19 13:20:10.335 2021-03-19 13:24:16.708 2021-03-19 13:24:16.708 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210319132416.7080000... 99819 0 2021-03-19 13:32:48.922629 We'll then load in the file filename = df_metadata . loc [ df_metadata . index [ - 2 ], 'file_name' ] native_fp = f ' { data_dir } / { filename } .nat' severi_area_def = reproj . get_seviri_area_def ( native_fp ) seviri_crs = severi_area_def . to_cartopy_crs () scene = reproj . load_scene ( native_fp ) scene . load ([ 'HRV' ]) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/pyproj/crs/crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/pyproj/crs/crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() And visualise it to test that everything is working fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fc2c8619880> We now need to reproject it %% capture -- no - stdout %% time reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) CPU times: user 2.23 s, sys: 104 ms, total: 2.33 s Wall time: 2.38 s Which again we'll check through visualisation fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-10-53f177b0781d>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fc2c86dd9a0> ds_reproj [ 'stacked_eumetsat_data' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (variable: 12, y: 1831, x: 1870)> dask.array<concatenate, shape=(12, 1831, 1870), dtype=float32, chunksize=(1, 1831, 1870), chunktype=numpy.ndarray> Coordinates: * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * variable (variable) object 'HRV' 'IR_016' 'IR_039' ... 'WV_062' 'WV_073' Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9911189780118609 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2021-03-19 13:15:09.278906 end_time: 2021-03-19 13:20:10.330158 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'stacked_eumetsat_data' variable : 12 y : 1831 x : 1870 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9911189780118609 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2021-03-19 13:15:09.278906 end_time : 2021-03-19 13:20:10.330158 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : []","title":"Preparing Data to Save to Zarr"},{"location":"03_zarr/#compressing","text":"We'll now develop our compressor class that will reduce the size of the datasets that we save to Zarr, in this instance we'll normalize the data and transform it to Int16. This has been found to reduce the size by ~50%. #exports def add_constant_coord_to_da ( da , coord_name , coord_val ): \"\"\" Adds a new coordinate with a constant value to the DataArray Parameters ---------- da : xr.DataArray DataArrray which will have the new coords added to it coord_name : str Name for the new coordinate dimensions coord_val Value that will be assigned to the new coordinates Returns ------- da : xr.DataArray DataArrray with the new coords added to it \"\"\" da = ( da . assign_coords ({ coord_name : coord_val }) . expand_dims ( coord_name ) ) return da class Compressor : def __init__ ( self , bits_per_pixel = 10 , mins = np . array ([ - 1.2278595 , - 2.5118103 , - 64.83977 , 63.404694 , 2.844452 , 199.10002 , - 17.254883 , - 26.29155 , - 1.1009827 , - 2.4184198 , 199.57048 , 198.95093 ]), maxs = np . array ([ 103.90016 , 69.60857 , 339.15588 , 340.26526 , 317.86752 , 313.2767 , 315.99194 , 274.82297 , 93.786545 , 101.34922 , 249.91806 , 286.96323 ]), variable_order = [ 'HRV' , 'IR_016' , 'IR_039' , 'IR_087' , 'IR_097' , 'IR_108' , 'IR_120' , 'IR_134' , 'VIS006' , 'VIS008' , 'WV_062' , 'WV_073' ] ): locals_ = locals () attrs_to_add = [ 'bits_per_pixel' , 'mins' , 'maxs' , 'variable_order' ] for attr in attrs_to_add : setattr ( self , attr , locals_ [ attr ]) return def fit ( self , da , dims = [ 'time' , 'y' , 'x' ]): self . mins = da . min ( dims ) . compute () self . maxs = da . max ( dims ) . compute () self . variable_order = da . coords [ 'variable' ] . values print ( f 'The mins are: { self . mins } ' ) print ( f 'The maxs are: { self . maxs } ' ) print ( f 'The variable order is: { self . variable_order } ' ) return def compress ( self , da ): da_meta = da . attrs for attr in [ 'mins' , 'maxs' ]: assert getattr ( self , attr ) is not None , f ' { attr } must be set in initialisation or through `fit`' if 'time' not in da . dims : time = pd . to_datetime ( da_meta [ 'end_time' ]) da = add_constant_coord_to_da ( da , 'time' , time ) da = ( da . reindex ({ 'variable' : self . variable_order }) . transpose ( 'time' , 'y' , 'x' , 'variable' ) ) upper_bound = ( 2 ** self . bits_per_pixel ) - 1 new_max = self . maxs - self . mins da -= self . mins da /= new_max da *= upper_bound da = ( da . clip ( 0 , upper_bound ) . fillna ( - 1 ) . round () . astype ( np . int16 ) ) da . attrs = { 'meta' : str ( da_meta )} # Must be serialisable return da %% time compressor = Compressor () da_compressed = compressor . compress ( ds_reproj [ 'stacked_eumetsat_data' ]) CPU times: user 10.7 ms, sys: 1.96 ms, total: 12.7 ms Wall time: 12.6 ms","title":"Compressing"},{"location":"03_zarr/#saving-to-zarr","text":"We'll now create a helper function for saving the data-array to a zarr database # exports get_time_as_unix = lambda da : pd . Series (( pd . to_datetime ( da . time . values ) - pd . Timestamp ( '1970-01-01' )) . total_seconds ()) . astype ( int ) . values def save_da_to_zarr ( da , zarr_bucket , dim_order = [ 'time' , 'x' , 'y' , 'variable' ], zarr_mode = 'a' ): da = da . transpose ( * dim_order ) da [ 'time' ] = get_time_as_unix ( da ) _ , y_size , x_size , _ = da . shape out_store = gcsfs . GCSMap ( root = zarr_bucket , gcs = gcsfs . GCSFileSystem ()) chunks = ( 36 , y_size , x_size , 1 ) ds = xr . Dataset ({ 'stacked_eumetsat_data' : da . chunk ( chunks )}) zarr_mode_to_extra_kwargs = { 'a' : { 'append_dim' : 'time' }, 'w' : { 'encoding' : { 'stacked_eumetsat_data' : { 'compressor' : numcodecs . Blosc ( cname = 'zstd' , clevel = 5 ), 'chunks' : chunks } } } } assert zarr_mode in [ 'a' , 'w' ], '`zarr_mode` must be one of: `a`, `w`' extra_kwargs = zarr_mode_to_extra_kwargs [ zarr_mode ] ds . to_zarr ( out_store , mode = zarr_mode , consolidated = True , ** extra_kwargs ) print ( 'Saved file to zarr bucket' ) return ds da_compressed /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 1, y: 1831, x: 1870, variable: 12)> dask.array<astype, shape=(1, 1831, 1870, 12), dtype=int16, chunksize=(1, 1831, 1870, 1), chunktype=numpy.ndarray> Coordinates: * variable (variable) object 'HRV' 'IR_016' 'IR_039' ... 'WV_062' 'WV_073' * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * time (time) datetime64[ns] 2021-03-19T13:20:10.330158 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 1 y : 1831 x : 1870 variable : 12 dask.array<chunksize=(1, 1831, 1870, 1), meta=np.ndarray> Array Chunk Bytes 82.18 MB 6.85 MB Shape (1, 1831, 1870, 12) (1, 1831, 1870, 1) Count 1505 Tasks 12 Chunks Type int16 numpy.ndarray 1 1 12 1870 1831 Coordinates: (4) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) time (time) datetime64[ns] 2021-03-19T13:20:10.330158 array(['2021-03-19T13:20:10.330158000'], dtype='datetime64[ns]') Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Now we can save it! save_data = False if save_data == True : out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' ds = save_da_to_zarr ( da_compressed , out_zarr_bucket , zarr_mode = 'w' ) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: divide by zero encountered in true_divide return func(*(_execute_task(a, cache) for a in args)) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) /Users/laurence/conda/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) Saved file to zarr bucket","title":"Saving to Zarr"},{"location":"03_zarr/#loading-zarr-data","text":"We'll start by defining a loading function and a replacement for the standard gcsfs.utils is_retriable function #exports def is_retriable ( exception ): \"\"\"Returns True if this exception is retriable.\"\"\" errors = list ( range ( 500 , 505 )) + [ 400 , # Jack's addition. Google Cloud occasionally throws Bad Requests for no apparent reason. 408 , # Request Timeout 429 , # Too Many Requests ] errors += [ str ( e ) for e in errors ] if isinstance ( exception , gcsfs . utils . HttpError ): return exception . code in errors return isinstance ( exception , gcsfs . utils . RETRIABLE_EXCEPTIONS ) gcsfs . utils . is_retriable = is_retriable get_unix_as_time = lambda da : pd . to_datetime ( da . time . values , unit = 's' ) def load_from_zarr_bucket ( zarr_bucket ): gcs = gcsfs . GCSFileSystem () store = gcsfs . GCSMap ( root = zarr_bucket , gcs = gcs ) ds = xr . open_zarr ( store , consolidated = True ) ds [ 'time' ] = get_unix_as_time ( ds ) return ds We'll now read it in %% time out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' ds_zarr = load_from_zarr_bucket ( out_zarr_bucket ) ds_zarr . time . compute () CPU times: user 4.14 s, sys: 1.7 s, total: 5.84 s Wall time: 21.3 s /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'time' (time: 5816)> array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-03-14T23:49:18.000000000', '2020-03-14T23:54:17.000000000', '2020-03-14T23:59:15.000000000'], dtype='datetime64[ns]') Coordinates: * time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-03-14T23:59:15 xarray.DataArray 'time' time : 5816 2021-03-19T13:20:10 2021-03-19T13:24:16 ... 2020-03-14T23:59:15 array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-03-14T23:49:18.000000000', '2020-03-14T23:54:17.000000000', '2020-03-14T23:59:15.000000000'], dtype='datetime64[ns]') Coordinates: (1) time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-03-... array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-03-14T23:49:18.000000000', '2020-03-14T23:54:17.000000000', '2020-03-14T23:59:15.000000000'], dtype='datetime64[ns]') Attributes: (0) Let's inspect the current datetime coverage in the database #exports def plot_zarr_data ( loaded_xarray ): df = loaded_xarray . time . to_dataframe () df [ 'time' ] = 1 df = df . resample ( 'D' ) . sum () # rather than messing with formatter, set index to a readable date format of Year-Month df = df . set_index ( df . index . map ( lambda s : s . strftime ( '%Y-%m' ))) # plot fig , ax = plt . subplots ( figsize = ( 6 , 6 ), dpi = 150 ) sns . heatmap ( df , ax = ax , cmap = 'Blues' , xticklabels = False ) ax . set ( title = \"Count of timesteps by day in Zarr datastore\" ) # reduce tick counts plt . locator_params ( axis = 'y' , nbins = 10 ) plot_zarr_data ( loaded_xarray ) We'll also plot the a sample of the loaded array fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) loaded_xarray [ 'stacked_eumetsat_data' ] . isel ( variable = 0 , time = 0 ) . T . plot ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-26-f7e189d5f897>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fc2df31c0a0> We can also identify missing datasets which will be useful for filling them in later #exports def identifying_missing_datasets ( start_date , end_date , eumetsat_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' ): # constructing the monthly split month_split = pd . date_range ( start_date , end_date , freq = \"MS\" ) # handling date range less than a month if len ( month_split ) <= 1 : month_split = [ start_date , end_date ] # identifying missing datasets in each split missing_datasets = [] warn ( f 'Earliest { start_date } , latest { end_date } ' ) for i in range ( len ( month_split ) - 1 ): # Identifying all potential datasets over specified date range datasets = eumetsat . identify_available_datasets ( month_split [ i ], month_split [ i + 1 ]) # Extracting the datetime each dataset was finished end_dates = [ dataset [ 'properties' ][ 'date' ] . split ( '/' )[ - 1 ] for dataset in datasets ] try : cleaned_end_dates = pd . to_datetime ( end_dates ) . floor ( freq = 's' ) . tz_localize ( 'UTC' ) . tz_convert ( None ) except : cleaned_end_dates = pd . to_datetime ( end_dates ) . floor ( freq = 's' ) . tz_convert ( None ) # Identifying missing datasets from the Zarr DB ds_eumetsat = load_from_zarr_bucket ( eumetsat_zarr_bucket ) end_dates_to_datasets = dict ( zip ( cleaned_end_dates , datasets )) missing_dates = set ( cleaned_end_dates ) - set ( pd . to_datetime ( ds_eumetsat . time . values )) missing_datasets . append ([ data for date , data in end_dates_to_datasets . items () if date in missing_dates ]) flat_list = [ item for sublist in missing_datasets for item in sublist ] return flat_list missing_datasets = identifying_missing_datasets ( \"2020-01-01T00:00:00\" , \"2020-01-01T01:00:00\" ) JSON ( missing_datasets ) Earliest 2020-01-01T00:00:00, latest 2020-01-01T01:00:00 100% 1/1 [00:04 < 00:04, 3.91s/it] identify_available_datasets: found 12 results from API <IPython.core.display.JSON object>","title":"Loading Zarr Data"},{"location":"04_gcp/","text":"EUMETSAT and Google Cloud Platform (GCP) \u00b6 The intention is to run a DAG using Airflow that: Uses the EUMETSAT DownloadManager will check for available files over a time period. Compares with already downloaded files in a GCP bucket Downloads any files not already downloaded, compressed using pbzip2 Run on europe-west4 (Netherlands) by preference. Our bucket and an example folder prefix is defined below. The data is stored in the format gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/<year>/<month>/<day>/<hour>/<minute>/ as per the existing files. Setup \u00b6 #exports from google.cloud import storage import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import os import re import dotenv import pandas_gbq GCP Helpers \u00b6 First need a couple of helper functions to work with Google Cloud Platform. Ideally the principles will transfer easily to other cloud providers if necessary. First we want to be able to list files ('blobs') in a Google Cloud storage bucket, and get the metadata for a specific file ('blob'). # You may need to run the following to create locally stored account credentials # https://googleapis.dev/python/google-api-core/latest/auth.html # !gcloud auth application-default login #exports def list_blobs_with_prefix ( bucket_name , prefix , delimiter = None ): \"\"\"Lists all the blobs in the bucket that begin with the prefix. This can be used to list all blobs in a \"folder\", e.g. \"public/\". The delimiter argument can be used to restrict the results to only the \"files\" in the given \"folder\". Without the delimiter, the entire tree under the prefix is returned. For example, given these blobs: a/1.txt a/b/2.txt If you just specify prefix = 'a', you'll get back: a/1.txt a/b/2.txt However, if you specify prefix='a' and delimiter='/', you'll get back: a/1.txt Additionally, the same request will return blobs.prefixes populated with: a/b/ \"\"\" storage_client = storage . Client () # Note: Client.list_blobs requires at least package version 1.17.0. blobs = storage_client . list_blobs ( bucket_name , prefix = prefix , delimiter = delimiter ) names = [] for blob in blobs : names . append ( blob . name ) return names def blob_metadata ( bucket_name , blob_name ): \"\"\"Prints out a blob's metadata.\"\"\" # bucket_name = 'your-bucket-name' # blob_name = 'your-object-name' storage_client = storage . Client () bucket = storage_client . bucket ( bucket_name ) blob = bucket . get_blob ( blob_name ) print ( \"Blob: {} \" . format ( blob . name )) print ( \"Bucket: {} \" . format ( blob . bucket . name )) print ( \"Storage class: {} \" . format ( blob . storage_class )) print ( \"ID: {} \" . format ( blob . id )) print ( \"Size: {} bytes\" . format ( blob . size )) print ( \"Updated: {} \" . format ( blob . updated )) print ( \"Generation: {} \" . format ( blob . generation )) print ( \"Metageneration: {} \" . format ( blob . metageneration )) print ( \"Etag: {} \" . format ( blob . etag )) print ( \"Owner: {} \" . format ( blob . owner )) print ( \"Component count: {} \" . format ( blob . component_count )) print ( \"Crc32c: {} \" . format ( blob . crc32c )) print ( \"md5_hash: {} \" . format ( blob . md5_hash )) print ( \"Cache-control: {} \" . format ( blob . cache_control )) print ( \"Content-type: {} \" . format ( blob . content_type )) print ( \"Content-disposition: {} \" . format ( blob . content_disposition )) print ( \"Content-encoding: {} \" . format ( blob . content_encoding )) print ( \"Content-language: {} \" . format ( blob . content_language )) print ( \"Metadata: {} \" . format ( blob . metadata )) We also want to be able to upload a file ('blob') to a storage bucket in an efficient way. #exports def upload_blob ( bucket_name , source_file_name , destination_blob_name , prefix = None , log = None ): \"\"\"Uploads a file to the bucket.\"\"\" # bucket_name = \"your-bucket-name\" # source_file_name = \"local/path/to/file\" # destination_blob_name = \"storage-object-name\" if prefix : destination_blob_name = prefix + destination_blob_name storage_client = storage . Client () bucket = storage_client . bucket ( bucket_name ) blob = bucket . blob ( destination_blob_name ) # For slow upload speed storage . blob . _DEFAULT_CHUNKSIZE = 2097152 # 1024 * 1024 B * 2 = 2 MB storage . blob . _MAX_MULTIPART_SIZE = 2097152 # 2 MB blob . upload_from_filename ( source_file_name ) print ( \"File {} uploaded to {} .\" . format ( source_file_name , destination_blob_name ) ) if log : log . info ( \"File {} uploaded to {} .\" . format ( source_file_name , destination_blob_name ) ) Checking existing saved data in Google Cloud Storage \u00b6 Finding out how much data has been downloaded for different years in the OCF native data bucket. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2019/01/01\" blobs = list_blobs_with_prefix ( BUCKET_NAME , prefix = PREFIX ) print ( f 'There are { len ( blobs ) } files' ) There are 277 files Lets see how large the data for the whole of 2018 is - this may take a few minutes to run. storage_client = storage . Client () PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2021/\" # Note: Client.list_blobs requires at least package version 1.17.0. blobs_ = storage_client . list_blobs ( BUCKET_NAME , prefix = PREFIX ) sizes = [] for blob in blobs_ : sizes . append ( blob . size ) sum ( sizes ) / 1e9 226.886050375 2018 contains 2.4TB of data Note that using the storage client to return blobs returns an iterable of blob metadata objects. From those we've extracted the names. We can go backwards from the names to interact with the blobs. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2021\" blobs = list_blobs_with_prefix ( BUCKET_NAME , prefix = PREFIX ) df = pd . DataFrame ( blobs , columns = [ 'blobs' ]) df = df [ df [ 'blobs' ] . str . endswith ( '.nat.bz2' )] # only compressed data files df [ 'datetime' ] = pd . to_datetime ( df [ 'blobs' ] . str . slice ( start = 37 , stop = 53 ), format = \"%Y/%m/ %d /%H/%M\" ) It is helpful to see by month how many data files already exist as compressed .nat files. Note that this is not looking at files reprojected and stored in the Zarr database. months_in_order = [ 'January' , 'February' , 'March' , 'April' , 'May' , 'June' , 'July' , 'August' , 'September' , 'October' , 'November' , 'December' ] blobs_by_month = df \\ . assign ( year = lambda x : x [ 'datetime' ] . dt . year ) \\ . assign ( month = lambda x : x [ 'datetime' ] . dt . month_name ()) \\ . groupby ([ 'month' , 'year' ]) . count ()[ 'blobs' ] . to_frame () \\ . reset_index () \\ . pivot ( index = 'month' , columns = 'year' , values = 'blobs' ) \\ . reindex ( months_in_order ) blobs_by_month ('year', 'month') ('2021', 'Unnamed: 1_level_1') January 6695 February 289 March nan April nan May nan June nan July nan August nan September nan October nan November nan December nan And lets plot this # credit: https://dfrieds.com/data-visualizations/visualize-historical-time-comparisons.html figure , axes = plt . subplots ( figsize = ( 10 , 11 )) sns . heatmap ( blobs_by_month , annot = True , linewidths =. 5 , ax = axes , cmap = \"Greys\" ) axes . axes . set_title ( \"Count of .nat.bz files in Storage by Month and Year\" , fontsize = 20 , y = 1.01 ) axes . axes . set_ylabel ( \"month\" , labelpad = 50 , rotation = 0 ) axes . axes . set_xlabel ( \"year\" , labelpad = 16 ); plt . yticks ( rotation = 0 ); Sometimes we'll want all of the original (uncompressed) filenames - for example to compare with the results of the EUMETSAT API so we can work out whether we should request a file or not. We'll make a function to get original filenames from compressed or uncompressed files stored as blobs on GCP. filenames = df [ 'blobs' ] . str . split ( '/' ) . str [ - 1 ] . str . replace ( '.bz2' , '' ) #exports def get_eumetsat_filenames ( bucket_name , prefix , delimiter = None ): \"\"\"Lists all the blobs in the bucket that begin with the prefix. This can be used to list all blobs in a \"folder\", e.g. \"public/\". The delimiter argument can be used to restrict the results to only the \"files\" in the given \"folder\". Without the delimiter, the entire tree under the prefix is returned. For example, given these blobs: \"\"\" storage_client = storage . Client () # Note: Client.list_blobs requires at least package version 1.17.0. blobs = storage_client . list_blobs ( bucket_name , prefix = prefix , delimiter = delimiter ) names = [] for blob in blobs : if blob . name . endswith ( '.nat.bz2' ): filename = blob . name . split ( '/' )[ - 1 ] . replace ( '.bz2' , '' ) names . append ( filename ) return names PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2019/10/01\" filenames = get_eumetsat_filenames ( BUCKET_NAME , prefix = PREFIX ) len ( filenames ) 288 Write metadata to bigquery \u00b6 For cloud storage functions, storing metadata in a RDBS seems useful. BigQuery is a low hassle way to achieve this and can scale to lots of data with ease. Downsides are rather inflexible migrations and updates. # exports def write_metadata_to_gcp ( df , table_id , project_id , credentials = None , append = True ): if append : if_exists = \"append\" else : if_exists = \"fail\" if credentials : pandas_gbq . to_gbq ( df , table_id , project_id = project_id , credentials = credentials , if_exists = if_exists , ) else : pandas_gbq . to_gbq ( df , table_id , project_id = project_id , if_exists = if_exists , ) print ( f \" { len ( df ) } rows written to BQ { table_id } , append= { append } \" ) write_metadata_now = False if write_metadata_now == True : write_metadata_to_gcp ( df , 'test' , 'solar-pv-nowcasting' ) As well as writing to BigQuery, we also want to query it. We'll write a small wrapper that allows us to send any SQL query and get results as a pandas DataFrame. Naturally we need to know the GCP project id, and the BigQuery table name. #exports def query ( sql_query , project_id ): \"\"\"Wrapper around BigQuery for a given Google project Returns: pandas.DataFrame of the query results \"\"\" df = pandas_gbq . read_gbq ( sql_query , project_id = project_id ) return df sql_query = 'select * from eumetsat.metadata where result_time = (select max(result_time) from eumetsat.metadata)' project_id = 'solar-pv-nowcasting' query ( sql_query , project_id )[ 'result_time' ] . iloc [ 0 ] . strftime ( '%Y-%m- %d %H:%M' ) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.09rows/s] '2021-02-02 08:44'","title":"GCP Analytics"},{"location":"04_gcp/#eumetsat-and-google-cloud-platform-gcp","text":"The intention is to run a DAG using Airflow that: Uses the EUMETSAT DownloadManager will check for available files over a time period. Compares with already downloaded files in a GCP bucket Downloads any files not already downloaded, compressed using pbzip2 Run on europe-west4 (Netherlands) by preference. Our bucket and an example folder prefix is defined below. The data is stored in the format gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/<year>/<month>/<day>/<hour>/<minute>/ as per the existing files.","title":"EUMETSAT and Google Cloud Platform (GCP)"},{"location":"04_gcp/#setup","text":"#exports from google.cloud import storage import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import os import re import dotenv import pandas_gbq","title":"Setup"},{"location":"04_gcp/#gcp-helpers","text":"First need a couple of helper functions to work with Google Cloud Platform. Ideally the principles will transfer easily to other cloud providers if necessary. First we want to be able to list files ('blobs') in a Google Cloud storage bucket, and get the metadata for a specific file ('blob'). # You may need to run the following to create locally stored account credentials # https://googleapis.dev/python/google-api-core/latest/auth.html # !gcloud auth application-default login #exports def list_blobs_with_prefix ( bucket_name , prefix , delimiter = None ): \"\"\"Lists all the blobs in the bucket that begin with the prefix. This can be used to list all blobs in a \"folder\", e.g. \"public/\". The delimiter argument can be used to restrict the results to only the \"files\" in the given \"folder\". Without the delimiter, the entire tree under the prefix is returned. For example, given these blobs: a/1.txt a/b/2.txt If you just specify prefix = 'a', you'll get back: a/1.txt a/b/2.txt However, if you specify prefix='a' and delimiter='/', you'll get back: a/1.txt Additionally, the same request will return blobs.prefixes populated with: a/b/ \"\"\" storage_client = storage . Client () # Note: Client.list_blobs requires at least package version 1.17.0. blobs = storage_client . list_blobs ( bucket_name , prefix = prefix , delimiter = delimiter ) names = [] for blob in blobs : names . append ( blob . name ) return names def blob_metadata ( bucket_name , blob_name ): \"\"\"Prints out a blob's metadata.\"\"\" # bucket_name = 'your-bucket-name' # blob_name = 'your-object-name' storage_client = storage . Client () bucket = storage_client . bucket ( bucket_name ) blob = bucket . get_blob ( blob_name ) print ( \"Blob: {} \" . format ( blob . name )) print ( \"Bucket: {} \" . format ( blob . bucket . name )) print ( \"Storage class: {} \" . format ( blob . storage_class )) print ( \"ID: {} \" . format ( blob . id )) print ( \"Size: {} bytes\" . format ( blob . size )) print ( \"Updated: {} \" . format ( blob . updated )) print ( \"Generation: {} \" . format ( blob . generation )) print ( \"Metageneration: {} \" . format ( blob . metageneration )) print ( \"Etag: {} \" . format ( blob . etag )) print ( \"Owner: {} \" . format ( blob . owner )) print ( \"Component count: {} \" . format ( blob . component_count )) print ( \"Crc32c: {} \" . format ( blob . crc32c )) print ( \"md5_hash: {} \" . format ( blob . md5_hash )) print ( \"Cache-control: {} \" . format ( blob . cache_control )) print ( \"Content-type: {} \" . format ( blob . content_type )) print ( \"Content-disposition: {} \" . format ( blob . content_disposition )) print ( \"Content-encoding: {} \" . format ( blob . content_encoding )) print ( \"Content-language: {} \" . format ( blob . content_language )) print ( \"Metadata: {} \" . format ( blob . metadata )) We also want to be able to upload a file ('blob') to a storage bucket in an efficient way. #exports def upload_blob ( bucket_name , source_file_name , destination_blob_name , prefix = None , log = None ): \"\"\"Uploads a file to the bucket.\"\"\" # bucket_name = \"your-bucket-name\" # source_file_name = \"local/path/to/file\" # destination_blob_name = \"storage-object-name\" if prefix : destination_blob_name = prefix + destination_blob_name storage_client = storage . Client () bucket = storage_client . bucket ( bucket_name ) blob = bucket . blob ( destination_blob_name ) # For slow upload speed storage . blob . _DEFAULT_CHUNKSIZE = 2097152 # 1024 * 1024 B * 2 = 2 MB storage . blob . _MAX_MULTIPART_SIZE = 2097152 # 2 MB blob . upload_from_filename ( source_file_name ) print ( \"File {} uploaded to {} .\" . format ( source_file_name , destination_blob_name ) ) if log : log . info ( \"File {} uploaded to {} .\" . format ( source_file_name , destination_blob_name ) )","title":"GCP Helpers"},{"location":"04_gcp/#checking-existing-saved-data-in-google-cloud-storage","text":"Finding out how much data has been downloaded for different years in the OCF native data bucket. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2019/01/01\" blobs = list_blobs_with_prefix ( BUCKET_NAME , prefix = PREFIX ) print ( f 'There are { len ( blobs ) } files' ) There are 277 files Lets see how large the data for the whole of 2018 is - this may take a few minutes to run. storage_client = storage . Client () PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2021/\" # Note: Client.list_blobs requires at least package version 1.17.0. blobs_ = storage_client . list_blobs ( BUCKET_NAME , prefix = PREFIX ) sizes = [] for blob in blobs_ : sizes . append ( blob . size ) sum ( sizes ) / 1e9 226.886050375 2018 contains 2.4TB of data Note that using the storage client to return blobs returns an iterable of blob metadata objects. From those we've extracted the names. We can go backwards from the names to interact with the blobs. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2021\" blobs = list_blobs_with_prefix ( BUCKET_NAME , prefix = PREFIX ) df = pd . DataFrame ( blobs , columns = [ 'blobs' ]) df = df [ df [ 'blobs' ] . str . endswith ( '.nat.bz2' )] # only compressed data files df [ 'datetime' ] = pd . to_datetime ( df [ 'blobs' ] . str . slice ( start = 37 , stop = 53 ), format = \"%Y/%m/ %d /%H/%M\" ) It is helpful to see by month how many data files already exist as compressed .nat files. Note that this is not looking at files reprojected and stored in the Zarr database. months_in_order = [ 'January' , 'February' , 'March' , 'April' , 'May' , 'June' , 'July' , 'August' , 'September' , 'October' , 'November' , 'December' ] blobs_by_month = df \\ . assign ( year = lambda x : x [ 'datetime' ] . dt . year ) \\ . assign ( month = lambda x : x [ 'datetime' ] . dt . month_name ()) \\ . groupby ([ 'month' , 'year' ]) . count ()[ 'blobs' ] . to_frame () \\ . reset_index () \\ . pivot ( index = 'month' , columns = 'year' , values = 'blobs' ) \\ . reindex ( months_in_order ) blobs_by_month ('year', 'month') ('2021', 'Unnamed: 1_level_1') January 6695 February 289 March nan April nan May nan June nan July nan August nan September nan October nan November nan December nan And lets plot this # credit: https://dfrieds.com/data-visualizations/visualize-historical-time-comparisons.html figure , axes = plt . subplots ( figsize = ( 10 , 11 )) sns . heatmap ( blobs_by_month , annot = True , linewidths =. 5 , ax = axes , cmap = \"Greys\" ) axes . axes . set_title ( \"Count of .nat.bz files in Storage by Month and Year\" , fontsize = 20 , y = 1.01 ) axes . axes . set_ylabel ( \"month\" , labelpad = 50 , rotation = 0 ) axes . axes . set_xlabel ( \"year\" , labelpad = 16 ); plt . yticks ( rotation = 0 ); Sometimes we'll want all of the original (uncompressed) filenames - for example to compare with the results of the EUMETSAT API so we can work out whether we should request a file or not. We'll make a function to get original filenames from compressed or uncompressed files stored as blobs on GCP. filenames = df [ 'blobs' ] . str . split ( '/' ) . str [ - 1 ] . str . replace ( '.bz2' , '' ) #exports def get_eumetsat_filenames ( bucket_name , prefix , delimiter = None ): \"\"\"Lists all the blobs in the bucket that begin with the prefix. This can be used to list all blobs in a \"folder\", e.g. \"public/\". The delimiter argument can be used to restrict the results to only the \"files\" in the given \"folder\". Without the delimiter, the entire tree under the prefix is returned. For example, given these blobs: \"\"\" storage_client = storage . Client () # Note: Client.list_blobs requires at least package version 1.17.0. blobs = storage_client . list_blobs ( bucket_name , prefix = prefix , delimiter = delimiter ) names = [] for blob in blobs : if blob . name . endswith ( '.nat.bz2' ): filename = blob . name . split ( '/' )[ - 1 ] . replace ( '.bz2' , '' ) names . append ( filename ) return names PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2019/10/01\" filenames = get_eumetsat_filenames ( BUCKET_NAME , prefix = PREFIX ) len ( filenames ) 288","title":"Checking existing saved data in Google Cloud Storage"},{"location":"04_gcp/#write-metadata-to-bigquery","text":"For cloud storage functions, storing metadata in a RDBS seems useful. BigQuery is a low hassle way to achieve this and can scale to lots of data with ease. Downsides are rather inflexible migrations and updates. # exports def write_metadata_to_gcp ( df , table_id , project_id , credentials = None , append = True ): if append : if_exists = \"append\" else : if_exists = \"fail\" if credentials : pandas_gbq . to_gbq ( df , table_id , project_id = project_id , credentials = credentials , if_exists = if_exists , ) else : pandas_gbq . to_gbq ( df , table_id , project_id = project_id , if_exists = if_exists , ) print ( f \" { len ( df ) } rows written to BQ { table_id } , append= { append } \" ) write_metadata_now = False if write_metadata_now == True : write_metadata_to_gcp ( df , 'test' , 'solar-pv-nowcasting' ) As well as writing to BigQuery, we also want to query it. We'll write a small wrapper that allows us to send any SQL query and get results as a pandas DataFrame. Naturally we need to know the GCP project id, and the BigQuery table name. #exports def query ( sql_query , project_id ): \"\"\"Wrapper around BigQuery for a given Google project Returns: pandas.DataFrame of the query results \"\"\" df = pandas_gbq . read_gbq ( sql_query , project_id = project_id ) return df sql_query = 'select * from eumetsat.metadata where result_time = (select max(result_time) from eumetsat.metadata)' project_id = 'solar-pv-nowcasting' query ( sql_query , project_id )[ 'result_time' ] . iloc [ 0 ] . strftime ( '%Y-%m- %d %H:%M' ) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.09rows/s] '2021-02-02 08:44'","title":"Write metadata to bigquery"},{"location":"05_pipeline/","text":"End-to-End Pipeline \u00b6 Imports \u00b6 #exports import pandas as pd import xarray as xr from satip import eumetsat, reproj, io, gcp_helpers from dagster import execute_pipeline, pipeline, solid, Field import os import glob import dotenv import warnings import shutil Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.32rows/s] Log Cleaning \u00b6 We'll suppress some errors/warnings to make the logs easier to parse #exports warnings.filterwarnings('ignore', message='divide by zero encountered in true_divide') warnings.filterwarnings('ignore', message='invalid value encountered in sin') warnings.filterwarnings('ignore', message='invalid value encountered in cos') warnings.filterwarnings('ignore', message='invalid value encountered in subtract') warnings.filterwarnings('ignore', message='You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems') Dagster Pipeline \u00b6 We're now going to combine these steps into a pipeline using dagster , first we'll create the individual components. #exports @solid() def download_eumetsat_files(context, env_vars_fp: str, data_dir: str, metadata_db_fp: str, debug_fp: str, table_id: str, project_id: str, start_date: str='', end_date: str='', max_mins: int=60): _ = dotenv.load_dotenv(env_vars_fp) if start_date == '': sql_query = f'select * from {table_id} where result_time = (select max(result_time) from {table_id})' latest_saved_date = gcp_helpers.query(sql_query, project_id)['result_time'].iloc[0].tz_localize(None) earliest_start_date = pd.Timestamp.now() - pd.Timedelta(max_mins, unit='minutes') start_date = max(earliest_start_date, latest_saved_date).strftime('%Y-%m-%d %H:%M') if end_date == '': end_date = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M') context.log.info(f'Querying data between {start_date} - {end_date}') dm = eumetsat.DownloadManager(os.environ.get('USER_KEY'), os.environ.get('USER_SECRET'), data_dir, metadata_db_fp, debug_fp, slack_webhook_url=os.environ.get('SLACK_WEBHOOK_URL'), slack_id=os.environ.get('SLACK_ID')) df_new_metadata = dm.download_date_range(start_date, end_date) if df_new_metadata is None: df_new_metadata = pd.DataFrame(columns=['result_time', 'file_name']) else: df_new_metadata = df_new_metadata.iloc[1:] # the first entry is the last one we downloaded return df_new_metadata @solid() def df_metadata_to_dt_to_fp_map(_, df_new_metadata, data_dir: str) -> dict: \"\"\" Here we'll then identify downloaded files in the metadata dataframe and return a mapping between datetimes and filenames \"\"\" datetime_to_filename = (df_new_metadata .set_index('result_time') ['file_name'] .drop_duplicates() .to_dict() ) datetime_to_filepath = { datetime: f\"{data_dir}/{filename}.nat\" for datetime, filename in datetime_to_filename.items() if filename != {} } return datetime_to_filepath @solid() def reproject_datasets(_, datetime_to_filepath: dict, new_coords_fp: str, new_grid_fp: str): reprojector = reproj.Reprojector(new_coords_fp, new_grid_fp) reprojected_dss = [ (reprojector .reproject(filepath, reproj_library='pyresample') .pipe(io.add_constant_coord_to_da, 'time', pd.to_datetime(datetime)) ) for datetime, filepath in datetime_to_filepath.items() ] if len(reprojected_dss) > 0: ds_combined_reproj = xr.concat(reprojected_dss, 'time', coords='all', data_vars='all') return ds_combined_reproj else: return xr.Dataset() @solid() def compress_and_save_datasets(_, ds_combined_reproj, zarr_bucket: str, var_name: str='stacked_eumetsat_data'): # Handle case where no new data exists if len(ds_combined_reproj.dims) == 0: print(\"compress_and_save_datasets: No new data to save to zarr\") return # Compressing the datasets compressor = io.Compressor() var_name = var_name da_compressed = compressor.compress(ds_combined_reproj[var_name]) # Saving to Zarr ds_compressed = io.save_da_to_zarr(da_compressed, zarr_bucket) return ds_compressed @solid() def save_metadata(context, ds_combined_compressed, df_new_metadata, table_id: str, project_id: str): if ds_combined_compressed is not None: if df_new_metadata.shape[0] > 0: gcp_helpers.write_metadata_to_gcp(df_new_metadata, table_id, project_id, append=True) context.log.info(f'{df_new_metadata.shape[0]} new metadata entries were added') else: context.log.info('No metadata was available to be added') return True @solid() def compress_export_then_delete_raw(context, ds_combined_compressed, data_dir: str, compressed_dir: str, BUCKET_NAME: str='solar-pv-nowcasting-data', PREFIX: str='satellite/EUMETSAT/SEVIRI_RSS/native/', ready_to_delete: bool=True): if ready_to_delete == True: eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) eumetsat.upload_compressed_files(compressed_dir, BUCKET_NAME=BUCKET_NAME, PREFIX=PREFIX, log=None) for dir_ in [data_dir, compressed_dir]: context.log.info(f'Removing directory {dir_}') shutil.rmtree(dir_) os.mkdir(dir_) # recreate empty folder Then we'll combine them in a pipeline #exports @pipeline def download_latest_data_pipeline(): df_new_metadata = download_eumetsat_files() datetime_to_filepath = df_metadata_to_dt_to_fp_map(df_new_metadata) ds_combined_reproj = reproject_datasets(datetime_to_filepath) ds_combined_compressed = compress_and_save_datasets(ds_combined_reproj) ready_to_delete = save_metadata(ds_combined_compressed, df_new_metadata) compress_export_then_delete_raw(ready_to_delete) Which we'll now run a test with run_config = { 'solids': { 'download_eumetsat_files': { 'inputs': { 'env_vars_fp': \"../.env\", 'data_dir': \"../data/raw\", 'metadata_db_fp': \"../data/EUMETSAT_metadata.db\", 'debug_fp': \"../logs/EUMETSAT_download.txt\", 'table_id': \"eumetsat.metadata\", 'project_id': \"solar-pv-nowcasting\", 'start_date': \"\", 'end_date': \"\" }, }, 'df_metadata_to_dt_to_fp_map': { 'inputs': { 'data_dir': \"../data/raw\" } }, 'reproject_datasets': { 'inputs': { 'new_coords_fp': \"../data/intermediate/reproj_coords_TM_4km.csv\", 'new_grid_fp': \"../data/intermediate/new_grid_4km_TM.json\" } }, 'compress_and_save_datasets': { 'inputs': { 'zarr_bucket': \"solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16\", 'var_name': \"stacked_eumetsat_data\" } }, 'save_metadata': { 'inputs': { 'table_id': \"eumetsat.metadata\", 'project_id': \"solar-pv-nowcasting\" }, }, 'compress_export_then_delete_raw': { 'inputs': { 'data_dir': \"../data/raw\", 'compressed_dir': \"../data/compressed\", 'BUCKET_NAME': \"solar-pv-nowcasting-data\", 'PREFIX': \"satellite/EUMETSAT/SEVIRI_RSS/native/\", 'ready_to_delete': True }, } } } execute_pipeline(download_latest_data_pipeline, run_config=run_config) 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Starting initialization of resources [asset_store]. 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Finished initialization of resources [asset_store]. 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - PIPELINE_START - Started execution of pipeline \"download_latest_data_pipeline\". 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Executing steps in process (pid: 28895) 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_START - Started execution of step \"download_eumetsat_files.compute\". 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"env_vars_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"metadata_db_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"debug_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"start_date\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"end_date\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"max_mins\" of type \"Int\". (Type check passed). Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.29rows/s] 2021-02-25 18:11:11 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - download_eumetsat_files.compute - Querying data between 2021-02-25 17:11 - 2021-02-25 18:11 2021-02-25 18:11:11,425 - INFO - ********** Download Manager Initialised ************** 2021-02-25 18:11:11,888 - INFO - 0 files queried, 0 found in ../data/raw, 0 to download. 2021-02-25 18:11:11,890 - INFO - No files will be downloaded. Set DownloadManager bucket_name argument for local download 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_SUCCESS - Finished execution of step \"download_eumetsat_files.compute\" in 2.21s. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_START - Started execution of step \"df_metadata_to_dt_to_fp_map.compute\". 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_OUTPUT - Yielded output \"result\" of type \"dict\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_SUCCESS - Finished execution of step \"df_metadata_to_dt_to_fp_map.compute\" in 5.63ms. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_START - Started execution of step \"reproject_datasets.compute\". 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input datetime_to_filepath in memory object store using pickle. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"datetime_to_filepath\" of type \"dict\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"new_coords_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"new_grid_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_SUCCESS - Finished execution of step \"reproject_datasets.compute\" in 962ms. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_START - Started execution of step \"compress_and_save_datasets.compute\". 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_reproj in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"ds_combined_reproj\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"zarr_bucket\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"var_name\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_SUCCESS - Finished execution of step \"compress_and_save_datasets.compute\" in 1.3ms. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_START - Started execution of step \"save_metadata.compute\". 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_SUCCESS - Finished execution of step \"save_metadata.compute\" in 1.23ms. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_START - Started execution of step \"compress_export_then_delete_raw.compute\". 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"compressed_dir\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"BUCKET_NAME\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"PREFIX\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ready_to_delete\" of type \"Bool\". (Type check passed). 2021-02-25 18:11:12 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - compress_export_then_delete_raw.compute - Found 0 native files. Found 0 native files. Moved and compressed 0 files to ../data/compressed File /Users/laurence/code/Satip/nbs/../data/compressed/2020/10/01/12/04/MSG3-SEVI-MSG15-0100-NA-20201001120415.953000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/10/01/12/04/MSG3-SEVI-MSG15-0100-NA-20201001120415.953000000Z-NA.nat.bz2. File /Users/laurence/code/Satip/nbs/../data/compressed/2020/10/01/12/09/MSG3-SEVI-MSG15-0100-NA-20201001120915.775000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/10/01/12/09/MSG3-SEVI-MSG15-0100-NA-20201001120915.775000000Z-NA.nat.bz2. File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/04/MSG3-SEVI-MSG15-0100-NA-20200101000414.102000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/04/MSG3-SEVI-MSG15-0100-NA-20200101000414.102000000Z-NA.nat.bz2. File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/09/MSG3-SEVI-MSG15-0100-NA-20200101000915.215000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/09/MSG3-SEVI-MSG15-0100-NA-20200101000915.215000000Z-NA.nat.bz2. 2021-02-25 18:11:58 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - compress_export_then_delete_raw.compute - File path ../data/compressed/2020 was not removed. 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_SUCCESS - Finished execution of step \"compress_export_then_delete_raw.compute\" in 45.46s. 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Finished steps in process (pid: 28895) in 48.68s 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - PIPELINE_SUCCESS - Finished execution of pipeline \"download_latest_data_pipeline\". File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/14/MSG3-SEVI-MSG15-0100-NA-20200101001416.328000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/14/MSG3-SEVI-MSG15-0100-NA-20200101001416.328000000Z-NA.nat.bz2. <dagster.core.execution.results.PipelineExecutionResult at 0x7fc94e591df0>","title":"Pipelines"},{"location":"05_pipeline/#end-to-end-pipeline","text":"","title":"End-to-End Pipeline"},{"location":"05_pipeline/#imports","text":"#exports import pandas as pd import xarray as xr from satip import eumetsat, reproj, io, gcp_helpers from dagster import execute_pipeline, pipeline, solid, Field import os import glob import dotenv import warnings import shutil Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.32rows/s]","title":"Imports"},{"location":"05_pipeline/#log-cleaning","text":"We'll suppress some errors/warnings to make the logs easier to parse #exports warnings.filterwarnings('ignore', message='divide by zero encountered in true_divide') warnings.filterwarnings('ignore', message='invalid value encountered in sin') warnings.filterwarnings('ignore', message='invalid value encountered in cos') warnings.filterwarnings('ignore', message='invalid value encountered in subtract') warnings.filterwarnings('ignore', message='You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems')","title":"Log Cleaning"},{"location":"05_pipeline/#dagster-pipeline","text":"We're now going to combine these steps into a pipeline using dagster , first we'll create the individual components. #exports @solid() def download_eumetsat_files(context, env_vars_fp: str, data_dir: str, metadata_db_fp: str, debug_fp: str, table_id: str, project_id: str, start_date: str='', end_date: str='', max_mins: int=60): _ = dotenv.load_dotenv(env_vars_fp) if start_date == '': sql_query = f'select * from {table_id} where result_time = (select max(result_time) from {table_id})' latest_saved_date = gcp_helpers.query(sql_query, project_id)['result_time'].iloc[0].tz_localize(None) earliest_start_date = pd.Timestamp.now() - pd.Timedelta(max_mins, unit='minutes') start_date = max(earliest_start_date, latest_saved_date).strftime('%Y-%m-%d %H:%M') if end_date == '': end_date = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M') context.log.info(f'Querying data between {start_date} - {end_date}') dm = eumetsat.DownloadManager(os.environ.get('USER_KEY'), os.environ.get('USER_SECRET'), data_dir, metadata_db_fp, debug_fp, slack_webhook_url=os.environ.get('SLACK_WEBHOOK_URL'), slack_id=os.environ.get('SLACK_ID')) df_new_metadata = dm.download_date_range(start_date, end_date) if df_new_metadata is None: df_new_metadata = pd.DataFrame(columns=['result_time', 'file_name']) else: df_new_metadata = df_new_metadata.iloc[1:] # the first entry is the last one we downloaded return df_new_metadata @solid() def df_metadata_to_dt_to_fp_map(_, df_new_metadata, data_dir: str) -> dict: \"\"\" Here we'll then identify downloaded files in the metadata dataframe and return a mapping between datetimes and filenames \"\"\" datetime_to_filename = (df_new_metadata .set_index('result_time') ['file_name'] .drop_duplicates() .to_dict() ) datetime_to_filepath = { datetime: f\"{data_dir}/{filename}.nat\" for datetime, filename in datetime_to_filename.items() if filename != {} } return datetime_to_filepath @solid() def reproject_datasets(_, datetime_to_filepath: dict, new_coords_fp: str, new_grid_fp: str): reprojector = reproj.Reprojector(new_coords_fp, new_grid_fp) reprojected_dss = [ (reprojector .reproject(filepath, reproj_library='pyresample') .pipe(io.add_constant_coord_to_da, 'time', pd.to_datetime(datetime)) ) for datetime, filepath in datetime_to_filepath.items() ] if len(reprojected_dss) > 0: ds_combined_reproj = xr.concat(reprojected_dss, 'time', coords='all', data_vars='all') return ds_combined_reproj else: return xr.Dataset() @solid() def compress_and_save_datasets(_, ds_combined_reproj, zarr_bucket: str, var_name: str='stacked_eumetsat_data'): # Handle case where no new data exists if len(ds_combined_reproj.dims) == 0: print(\"compress_and_save_datasets: No new data to save to zarr\") return # Compressing the datasets compressor = io.Compressor() var_name = var_name da_compressed = compressor.compress(ds_combined_reproj[var_name]) # Saving to Zarr ds_compressed = io.save_da_to_zarr(da_compressed, zarr_bucket) return ds_compressed @solid() def save_metadata(context, ds_combined_compressed, df_new_metadata, table_id: str, project_id: str): if ds_combined_compressed is not None: if df_new_metadata.shape[0] > 0: gcp_helpers.write_metadata_to_gcp(df_new_metadata, table_id, project_id, append=True) context.log.info(f'{df_new_metadata.shape[0]} new metadata entries were added') else: context.log.info('No metadata was available to be added') return True @solid() def compress_export_then_delete_raw(context, ds_combined_compressed, data_dir: str, compressed_dir: str, BUCKET_NAME: str='solar-pv-nowcasting-data', PREFIX: str='satellite/EUMETSAT/SEVIRI_RSS/native/', ready_to_delete: bool=True): if ready_to_delete == True: eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) eumetsat.upload_compressed_files(compressed_dir, BUCKET_NAME=BUCKET_NAME, PREFIX=PREFIX, log=None) for dir_ in [data_dir, compressed_dir]: context.log.info(f'Removing directory {dir_}') shutil.rmtree(dir_) os.mkdir(dir_) # recreate empty folder Then we'll combine them in a pipeline #exports @pipeline def download_latest_data_pipeline(): df_new_metadata = download_eumetsat_files() datetime_to_filepath = df_metadata_to_dt_to_fp_map(df_new_metadata) ds_combined_reproj = reproject_datasets(datetime_to_filepath) ds_combined_compressed = compress_and_save_datasets(ds_combined_reproj) ready_to_delete = save_metadata(ds_combined_compressed, df_new_metadata) compress_export_then_delete_raw(ready_to_delete) Which we'll now run a test with run_config = { 'solids': { 'download_eumetsat_files': { 'inputs': { 'env_vars_fp': \"../.env\", 'data_dir': \"../data/raw\", 'metadata_db_fp': \"../data/EUMETSAT_metadata.db\", 'debug_fp': \"../logs/EUMETSAT_download.txt\", 'table_id': \"eumetsat.metadata\", 'project_id': \"solar-pv-nowcasting\", 'start_date': \"\", 'end_date': \"\" }, }, 'df_metadata_to_dt_to_fp_map': { 'inputs': { 'data_dir': \"../data/raw\" } }, 'reproject_datasets': { 'inputs': { 'new_coords_fp': \"../data/intermediate/reproj_coords_TM_4km.csv\", 'new_grid_fp': \"../data/intermediate/new_grid_4km_TM.json\" } }, 'compress_and_save_datasets': { 'inputs': { 'zarr_bucket': \"solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16\", 'var_name': \"stacked_eumetsat_data\" } }, 'save_metadata': { 'inputs': { 'table_id': \"eumetsat.metadata\", 'project_id': \"solar-pv-nowcasting\" }, }, 'compress_export_then_delete_raw': { 'inputs': { 'data_dir': \"../data/raw\", 'compressed_dir': \"../data/compressed\", 'BUCKET_NAME': \"solar-pv-nowcasting-data\", 'PREFIX': \"satellite/EUMETSAT/SEVIRI_RSS/native/\", 'ready_to_delete': True }, } } } execute_pipeline(download_latest_data_pipeline, run_config=run_config) 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Starting initialization of resources [asset_store]. 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Finished initialization of resources [asset_store]. 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - PIPELINE_START - Started execution of pipeline \"download_latest_data_pipeline\". 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Executing steps in process (pid: 28895) 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_START - Started execution of step \"download_eumetsat_files.compute\". 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"env_vars_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"metadata_db_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"debug_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"start_date\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"end_date\" of type \"String\". (Type check passed). 2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"max_mins\" of type \"Int\". (Type check passed). Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.29rows/s] 2021-02-25 18:11:11 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - download_eumetsat_files.compute - Querying data between 2021-02-25 17:11 - 2021-02-25 18:11 2021-02-25 18:11:11,425 - INFO - ********** Download Manager Initialised ************** 2021-02-25 18:11:11,888 - INFO - 0 files queried, 0 found in ../data/raw, 0 to download. 2021-02-25 18:11:11,890 - INFO - No files will be downloaded. Set DownloadManager bucket_name argument for local download 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_SUCCESS - Finished execution of step \"download_eumetsat_files.compute\" in 2.21s. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_START - Started execution of step \"df_metadata_to_dt_to_fp_map.compute\". 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_OUTPUT - Yielded output \"result\" of type \"dict\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_SUCCESS - Finished execution of step \"df_metadata_to_dt_to_fp_map.compute\" in 5.63ms. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_START - Started execution of step \"reproject_datasets.compute\". 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input datetime_to_filepath in memory object store using pickle. 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"datetime_to_filepath\" of type \"dict\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"new_coords_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"new_grid_fp\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_SUCCESS - Finished execution of step \"reproject_datasets.compute\" in 962ms. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_START - Started execution of step \"compress_and_save_datasets.compute\". 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_reproj in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"ds_combined_reproj\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"zarr_bucket\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"var_name\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_SUCCESS - Finished execution of step \"compress_and_save_datasets.compute\" in 1.3ms. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_START - Started execution of step \"save_metadata.compute\". 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_SUCCESS - Finished execution of step \"save_metadata.compute\" in 1.23ms. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_START - Started execution of step \"compress_export_then_delete_raw.compute\". 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle. 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"compressed_dir\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"BUCKET_NAME\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"PREFIX\" of type \"String\". (Type check passed). 2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ready_to_delete\" of type \"Bool\". (Type check passed). 2021-02-25 18:11:12 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - compress_export_then_delete_raw.compute - Found 0 native files. Found 0 native files. Moved and compressed 0 files to ../data/compressed File /Users/laurence/code/Satip/nbs/../data/compressed/2020/10/01/12/04/MSG3-SEVI-MSG15-0100-NA-20201001120415.953000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/10/01/12/04/MSG3-SEVI-MSG15-0100-NA-20201001120415.953000000Z-NA.nat.bz2. File /Users/laurence/code/Satip/nbs/../data/compressed/2020/10/01/12/09/MSG3-SEVI-MSG15-0100-NA-20201001120915.775000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/10/01/12/09/MSG3-SEVI-MSG15-0100-NA-20201001120915.775000000Z-NA.nat.bz2. File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/04/MSG3-SEVI-MSG15-0100-NA-20200101000414.102000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/04/MSG3-SEVI-MSG15-0100-NA-20200101000414.102000000Z-NA.nat.bz2. File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/09/MSG3-SEVI-MSG15-0100-NA-20200101000915.215000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/09/MSG3-SEVI-MSG15-0100-NA-20200101000915.215000000Z-NA.nat.bz2. 2021-02-25 18:11:58 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - compress_export_then_delete_raw.compute - File path ../data/compressed/2020 was not removed. 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_SUCCESS - Finished execution of step \"compress_export_then_delete_raw.compute\" in 45.46s. 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Finished steps in process (pid: 28895) in 48.68s 2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - PIPELINE_SUCCESS - Finished execution of pipeline \"download_latest_data_pipeline\". File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/14/MSG3-SEVI-MSG15-0100-NA-20200101001416.328000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/14/MSG3-SEVI-MSG15-0100-NA-20200101001416.328000000Z-NA.nat.bz2. <dagster.core.execution.results.PipelineExecutionResult at 0x7fc94e591df0>","title":"Dagster Pipeline"},{"location":"05a_pipeline_batch/","text":"Pipeline for backfilling / batching \u00b6 Dagster can only run one pipeline per module, and 05_pipeline.ipynb ie mario.py already has one pipeline defined for continuous linear retrieval where the steps take place one after the other. Imports \u00b6 #exports import pandas as pd import xarray as xr import os import glob import dotenv import warnings from dagster import execute_pipeline , pipeline , solid , Field , OutputDefinition , DagsterType , Output from itertools import islice import shutil from IPython.display import JSON from satip import eumetsat , reproj , io , gcp_helpers from satip.mario import ( df_metadata_to_dt_to_fp_map , reproject_datasets , save_metadata , compress_and_save_datasets , compress_export_then_delete_raw ) # Filter some warnings #exports warnings . filterwarnings ( 'ignore' , message = 'divide by zero encountered in true_divide' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in sin' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in cos' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in subtract' ) warnings . filterwarnings ( 'ignore' , message = 'You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems' ) eumetsat_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' missing_datasets = io . identifying_missing_datasets ( \"2020-01-01 00:00\" , \"2020-01-01 01:00\" , eumetsat_zarr_bucket = eumetsat_zarr_bucket ) JSON ( missing_datasets ) Earliest 2020-01-01 00:00, latest 2020-01-01 01:00 100% 1/1 [00:01 < 00:01, 1.38s/it] identify_available_datasets: found 12 results from API <IPython.core.display.JSON object> #exports def chunks ( data , SIZE = 10000 ): \"\"\"Turn dict into iterator of length SIZE chunks\"\"\" it = iter ( data ) for i in range ( 0 , len ( data ), SIZE ): yield { k : data [ k ] for k in islice ( it , SIZE )} #exports # create pandas DataFrame type definition for Dagster DataFrame = DagsterType ( name = \"DataFrame\" , type_check_fn = lambda _ , x : isinstance ( x , pd . DataFrame ), ) @solid ( output_defs = [ OutputDefinition ( name = 'df_new_metadata' , dagster_type = DataFrame , is_required = False )]) def download_missing_eumetsat_files ( context , env_vars_fp : str , data_dir : str , metadata_db_fp : str , debug_fp : str , table_id : str , project_id : str , start_date : str = '' , end_date : str = '' ): _ = dotenv . load_dotenv ( env_vars_fp ) dm = eumetsat . DownloadManager ( os . environ . get ( 'USER_KEY' ), os . environ . get ( 'USER_SECRET' ), data_dir , metadata_db_fp , debug_fp , slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ), slack_id = os . environ . get ( 'SLACK_ID' )) missing_datasets = io . identifying_missing_datasets ( start_date , end_date ) context . log . info ( f \"Missing data: { len ( missing_datasets ) } \" ) df_new_metadata = dm . download_datasets ( missing_datasets ) # if df_new_metadata is None, pipeline will skip subsequent solids if df_new_metadata is None : context . log . info ( \"*******************\" ) context . log . info ( \"Files already in zarr. Exiting.\" ) context . log . info ( \"*******************\" ) return yield Output ( df_new_metadata , 'df_new_metadata' ) #exports @solid () def reproject_compress_save_datasets_batch ( _ , datetime_to_filepath : dict , new_coords_fp : str , new_grid_fp : str , zarr_bucket : str , var_name : str = 'stacked_eumetsat_data' ): \"\"\"Batch up the reprojection and saving to zarr steps xAarray concat or some other processing step gives memory crashes beyond around 1hr of time range which is around 12 file items \"\"\" # datetime_to_filepath -> batches batch_size = 10 batches = [ i for i in chunks ( datetime_to_filepath , batch_size )] for batch in batches : reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) reprojected_dss = [ ( reprojector . reproject ( filepath , reproj_library = 'pyresample' ) . pipe ( io . add_constant_coord_to_da , 'time' , pd . to_datetime ( datetime )) ) for datetime , filepath in batch . items () ] if len ( reprojected_dss ) > 0 : ds_combined_reproj = xr . concat ( reprojected_dss , 'time' , coords = 'all' , data_vars = 'all' ) else : print ( \"compress_and_save_datasets: No new data to save to zarr\" ) return # Compressing the datasets compressor = io . Compressor () var_name = var_name da_compressed = compressor . compress ( ds_combined_reproj [ var_name ]) # Saving to Zarr ds_compressed = io . save_da_to_zarr ( da_compressed , zarr_bucket ) # fine to just return last one, we are just checking it exists return ds_compressed @solid () def save_metadata_batch ( context , ds_combined_compressed , df_new_metadata , table_id : str , project_id : str ): if ds_combined_compressed is not None : if df_new_metadata . shape [ 0 ] > 0 : gcp_helpers . write_metadata_to_gcp ( df_new_metadata , table_id , project_id , append = True ) context . log . info ( f ' { df_new_metadata . shape [ 0 ] } new metadata entries were added' ) else : context . log . info ( 'No metadata was available to be added' ) return True @solid () def compress_export_then_delete_raw_batch ( context , ready_to_delete , data_dir : str , compressed_dir : str , BUCKET_NAME : str = 'solar-pv-nowcasting-data' , PREFIX : str = 'satellite/EUMETSAT/SEVIRI_RSS/native/' ): if ready_to_delete == True : eumetsat . compress_downloaded_files ( data_dir = data_dir , compressed_dir = compressed_dir , log = context . log ) eumetsat . upload_compressed_files ( compressed_dir , BUCKET_NAME = BUCKET_NAME , PREFIX = PREFIX , log = None ) for dir_ in [ data_dir , compressed_dir ]: context . log . info ( f 'Removing directory { dir_ } ' ) shutil . rmtree ( dir_ ) os . mkdir ( dir_ ) # recreate empty folder #exports @pipeline def download_missing_data_pipeline (): # Retrieving data, reprojecting, compressing, and saving to GCP df_new_metadata = download_missing_eumetsat_files () datetime_to_filepath = df_metadata_to_dt_to_fp_map ( df_new_metadata ) last_batch_compressed = reproject_compress_save_datasets_batch ( datetime_to_filepath ) ready_to_delete = save_metadata_batch ( last_batch_compressed , df_new_metadata ) compress_export_then_delete_raw_batch ( ready_to_delete ) datetime_to_filepath is a dict, looking like: {Timestamp(): str # e.g # {Timestamp('2019-04-01 00:04:19.045000+0000', tz='UTC'): '../data/raw_bfill/MSG3-SEVI-MSG15-0100-NA-20190401000419.045000000Z-NA.nat'} Test the configuration and execute the pipeline:","title":"Pipeline for backfilling / batching"},{"location":"05a_pipeline_batch/#pipeline-for-backfilling-batching","text":"Dagster can only run one pipeline per module, and 05_pipeline.ipynb ie mario.py already has one pipeline defined for continuous linear retrieval where the steps take place one after the other.","title":"Pipeline for backfilling / batching"},{"location":"05a_pipeline_batch/#imports","text":"#exports import pandas as pd import xarray as xr import os import glob import dotenv import warnings from dagster import execute_pipeline , pipeline , solid , Field , OutputDefinition , DagsterType , Output from itertools import islice import shutil from IPython.display import JSON from satip import eumetsat , reproj , io , gcp_helpers from satip.mario import ( df_metadata_to_dt_to_fp_map , reproject_datasets , save_metadata , compress_and_save_datasets , compress_export_then_delete_raw ) # Filter some warnings #exports warnings . filterwarnings ( 'ignore' , message = 'divide by zero encountered in true_divide' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in sin' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in cos' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in subtract' ) warnings . filterwarnings ( 'ignore' , message = 'You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems' ) eumetsat_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' missing_datasets = io . identifying_missing_datasets ( \"2020-01-01 00:00\" , \"2020-01-01 01:00\" , eumetsat_zarr_bucket = eumetsat_zarr_bucket ) JSON ( missing_datasets ) Earliest 2020-01-01 00:00, latest 2020-01-01 01:00 100% 1/1 [00:01 < 00:01, 1.38s/it] identify_available_datasets: found 12 results from API <IPython.core.display.JSON object> #exports def chunks ( data , SIZE = 10000 ): \"\"\"Turn dict into iterator of length SIZE chunks\"\"\" it = iter ( data ) for i in range ( 0 , len ( data ), SIZE ): yield { k : data [ k ] for k in islice ( it , SIZE )} #exports # create pandas DataFrame type definition for Dagster DataFrame = DagsterType ( name = \"DataFrame\" , type_check_fn = lambda _ , x : isinstance ( x , pd . DataFrame ), ) @solid ( output_defs = [ OutputDefinition ( name = 'df_new_metadata' , dagster_type = DataFrame , is_required = False )]) def download_missing_eumetsat_files ( context , env_vars_fp : str , data_dir : str , metadata_db_fp : str , debug_fp : str , table_id : str , project_id : str , start_date : str = '' , end_date : str = '' ): _ = dotenv . load_dotenv ( env_vars_fp ) dm = eumetsat . DownloadManager ( os . environ . get ( 'USER_KEY' ), os . environ . get ( 'USER_SECRET' ), data_dir , metadata_db_fp , debug_fp , slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ), slack_id = os . environ . get ( 'SLACK_ID' )) missing_datasets = io . identifying_missing_datasets ( start_date , end_date ) context . log . info ( f \"Missing data: { len ( missing_datasets ) } \" ) df_new_metadata = dm . download_datasets ( missing_datasets ) # if df_new_metadata is None, pipeline will skip subsequent solids if df_new_metadata is None : context . log . info ( \"*******************\" ) context . log . info ( \"Files already in zarr. Exiting.\" ) context . log . info ( \"*******************\" ) return yield Output ( df_new_metadata , 'df_new_metadata' ) #exports @solid () def reproject_compress_save_datasets_batch ( _ , datetime_to_filepath : dict , new_coords_fp : str , new_grid_fp : str , zarr_bucket : str , var_name : str = 'stacked_eumetsat_data' ): \"\"\"Batch up the reprojection and saving to zarr steps xAarray concat or some other processing step gives memory crashes beyond around 1hr of time range which is around 12 file items \"\"\" # datetime_to_filepath -> batches batch_size = 10 batches = [ i for i in chunks ( datetime_to_filepath , batch_size )] for batch in batches : reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) reprojected_dss = [ ( reprojector . reproject ( filepath , reproj_library = 'pyresample' ) . pipe ( io . add_constant_coord_to_da , 'time' , pd . to_datetime ( datetime )) ) for datetime , filepath in batch . items () ] if len ( reprojected_dss ) > 0 : ds_combined_reproj = xr . concat ( reprojected_dss , 'time' , coords = 'all' , data_vars = 'all' ) else : print ( \"compress_and_save_datasets: No new data to save to zarr\" ) return # Compressing the datasets compressor = io . Compressor () var_name = var_name da_compressed = compressor . compress ( ds_combined_reproj [ var_name ]) # Saving to Zarr ds_compressed = io . save_da_to_zarr ( da_compressed , zarr_bucket ) # fine to just return last one, we are just checking it exists return ds_compressed @solid () def save_metadata_batch ( context , ds_combined_compressed , df_new_metadata , table_id : str , project_id : str ): if ds_combined_compressed is not None : if df_new_metadata . shape [ 0 ] > 0 : gcp_helpers . write_metadata_to_gcp ( df_new_metadata , table_id , project_id , append = True ) context . log . info ( f ' { df_new_metadata . shape [ 0 ] } new metadata entries were added' ) else : context . log . info ( 'No metadata was available to be added' ) return True @solid () def compress_export_then_delete_raw_batch ( context , ready_to_delete , data_dir : str , compressed_dir : str , BUCKET_NAME : str = 'solar-pv-nowcasting-data' , PREFIX : str = 'satellite/EUMETSAT/SEVIRI_RSS/native/' ): if ready_to_delete == True : eumetsat . compress_downloaded_files ( data_dir = data_dir , compressed_dir = compressed_dir , log = context . log ) eumetsat . upload_compressed_files ( compressed_dir , BUCKET_NAME = BUCKET_NAME , PREFIX = PREFIX , log = None ) for dir_ in [ data_dir , compressed_dir ]: context . log . info ( f 'Removing directory { dir_ } ' ) shutil . rmtree ( dir_ ) os . mkdir ( dir_ ) # recreate empty folder #exports @pipeline def download_missing_data_pipeline (): # Retrieving data, reprojecting, compressing, and saving to GCP df_new_metadata = download_missing_eumetsat_files () datetime_to_filepath = df_metadata_to_dt_to_fp_map ( df_new_metadata ) last_batch_compressed = reproject_compress_save_datasets_batch ( datetime_to_filepath ) ready_to_delete = save_metadata_batch ( last_batch_compressed , df_new_metadata ) compress_export_then_delete_raw_batch ( ready_to_delete ) datetime_to_filepath is a dict, looking like: {Timestamp(): str # e.g # {Timestamp('2019-04-01 00:04:19.045000+0000', tz='UTC'): '../data/raw_bfill/MSG3-SEVI-MSG15-0100-NA-20190401000419.045000000Z-NA.nat'} Test the configuration and execute the pipeline:","title":"Imports"},{"location":"06-ci-cd/","text":"CI/CD \u00b6 #exports import os import re import typer import logging from warnings import warn from configparser import ConfigParser Initialising CLI \u00b6 #exports app = typer.Typer() Incrementing the Package Version \u00b6 We'll start by retrieving the current package version specified in settings.ini #exports @app.command() def get_current_package_version(settings_fp: str='settings.ini'): config = ConfigParser(delimiters=['=']) config.read(settings_fp) version = config.get('DEFAULT', 'version') return version settings_fp = '../settings.ini' original_version = get_current_package_version(settings_fp) original_version '1.0.2' We'll now increment the package version #exports @app.command() def increment_package_version(old_version: str, increment_level: str='micro'): increment = lambda rev: str(int(rev)+1) major, minor, micro = old_version.split('.') # naming from - https://the-hitchhikers-guide-to-packaging.readthedocs.io/en/latest/specification.html#sequence-based-scheme if increment_level == 'major': major = increment(major) elif increment_level == 'minor': minor = increment(minor) elif increment_level == 'micro': micro = increment(micro) new_version = '.'.join([major, minor, micro]) return new_version increment_package_version(original_version) '1.0.3' But what about if we've made large changes to the code-base and wish to express the size of these revisions in the version? For that we can specify the increment_level . increment_package_version(original_version, increment_level='major') '2.0.2' And finally we can set the version #exports @app.command() def set_current_package_version(version: str, settings_fp: str='settings.ini'): version = version.replace('v', '') config = ConfigParser(delimiters=['=']) config.read(settings_fp) config.set('DEFAULT', 'version', version) with open(settings_fp, 'w') as configfile: config.write(configfile) logger = logging.getLogger('package_release') logger.setLevel('INFO') logger.info(f'The package version has to be updated to {version}') return set_current_package_version('9.9.9', settings_fp) get_current_package_version(settings_fp) '9.9.9' Before we move on we'll change the version on file back to the original set_current_package_version(original_version, settings_fp) get_current_package_version(settings_fp) '1.0.2' Finally we need to ensure the CLI app is available when the module is loaded. N.b. we've included the condition '__file__' in globals() to make sure this isn't when inside the notebook #exports if __name__ == '__main__' and '__file__' in globals(): app()","title":"CI/CD"},{"location":"06-ci-cd/#cicd","text":"#exports import os import re import typer import logging from warnings import warn from configparser import ConfigParser","title":"CI/CD"},{"location":"06-ci-cd/#initialising-cli","text":"#exports app = typer.Typer()","title":"Initialising CLI"},{"location":"06-ci-cd/#incrementing-the-package-version","text":"We'll start by retrieving the current package version specified in settings.ini #exports @app.command() def get_current_package_version(settings_fp: str='settings.ini'): config = ConfigParser(delimiters=['=']) config.read(settings_fp) version = config.get('DEFAULT', 'version') return version settings_fp = '../settings.ini' original_version = get_current_package_version(settings_fp) original_version '1.0.2' We'll now increment the package version #exports @app.command() def increment_package_version(old_version: str, increment_level: str='micro'): increment = lambda rev: str(int(rev)+1) major, minor, micro = old_version.split('.') # naming from - https://the-hitchhikers-guide-to-packaging.readthedocs.io/en/latest/specification.html#sequence-based-scheme if increment_level == 'major': major = increment(major) elif increment_level == 'minor': minor = increment(minor) elif increment_level == 'micro': micro = increment(micro) new_version = '.'.join([major, minor, micro]) return new_version increment_package_version(original_version) '1.0.3' But what about if we've made large changes to the code-base and wish to express the size of these revisions in the version? For that we can specify the increment_level . increment_package_version(original_version, increment_level='major') '2.0.2' And finally we can set the version #exports @app.command() def set_current_package_version(version: str, settings_fp: str='settings.ini'): version = version.replace('v', '') config = ConfigParser(delimiters=['=']) config.read(settings_fp) config.set('DEFAULT', 'version', version) with open(settings_fp, 'w') as configfile: config.write(configfile) logger = logging.getLogger('package_release') logger.setLevel('INFO') logger.info(f'The package version has to be updated to {version}') return set_current_package_version('9.9.9', settings_fp) get_current_package_version(settings_fp) '9.9.9' Before we move on we'll change the version on file back to the original set_current_package_version(original_version, settings_fp) get_current_package_version(settings_fp) '1.0.2' Finally we need to ensure the CLI app is available when the module is loaded. N.b. we've included the condition '__file__' in globals() to make sure this isn't when inside the notebook #exports if __name__ == '__main__' and '__file__' in globals(): app()","title":"Incrementing the Package Version"},{"location":"101_downloading/","text":"Downloading Data From EUMETSAT \u00b6 from satip import eumetsat import matplotlib.pyplot as plt import cartopy.crs as ccrs import os import dotenv C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.40rows/s] User Inputs \u00b6 We have to specify the directory where the data native filepaths are located data_dir = '../data/raw' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' Using the Download Manager \u00b6 First we'll load the the environment variables dotenv.load_dotenv(env_vars_fp) user_key = os.environ.get('USER_KEY') user_secret = os.environ.get('USER_SECRET') slack_id = os.environ.get('SLACK_ID') slack_webhook_url = os.environ.get('SLACK_WEBHOOK_URL') Then we'll use the download manager to retrieve a single dataset dm = eumetsat.DownloadManager(user_key, user_secret, data_dir, metadata_db_fp, debug_fp, slack_webhook_url=slack_webhook_url, slack_id=slack_id) start_date = '2020-01-01 00:00' end_date = '2020-01-01 00:05' dm.download_date_range(start_date, end_date) 2020-12-17 00:21:11,192 - INFO - ********** Download Manager Initialised ************** 2020-12-17 00:21:11,777 - INFO - 1 files queried, 0 found in ../data/raw, 1 to download. 100% 1/1 [00:07 < 00:07, 6.59s/it] start_date end_date result_time platform_short_name platform_orbit_type instrument_name sensor_op_mode center_srs_name center_position file_name file_size missing_pct downloaded 0 2020-01-01 00:00:07.683000+00:00 2020-01-01 00:04:14.102000+00:00 2020-01-01 00:04:14.102000+00:00 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101000414.1020000... 99819 0 2020-12-17 00:21:18.312026 Once the files have been downloaded they will be automatically detected and skipped if downloading is attempted again _ = dm.download_date_range(start_date, end_date) 2020-12-17 00:21:31,507 - INFO - 1 files queried, 1 found in ../data/raw, 0 to download. 2020-12-17 00:21:31,512 - INFO - No files will be downloaded. Set DownloadManager bucket_name argument for local download We can retrieve the metadata for all historical downloads by calling the get_df_metadata method df_metadata = dm.get_df_metadata() df_metadata.head()","title":"Downloading from EUMETSAT"},{"location":"101_downloading/#downloading-data-from-eumetsat","text":"from satip import eumetsat import matplotlib.pyplot as plt import cartopy.crs as ccrs import os import dotenv C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.40rows/s]","title":"Downloading Data From EUMETSAT"},{"location":"101_downloading/#user-inputs","text":"We have to specify the directory where the data native filepaths are located data_dir = '../data/raw' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db'","title":"User Inputs"},{"location":"101_downloading/#using-the-download-manager","text":"First we'll load the the environment variables dotenv.load_dotenv(env_vars_fp) user_key = os.environ.get('USER_KEY') user_secret = os.environ.get('USER_SECRET') slack_id = os.environ.get('SLACK_ID') slack_webhook_url = os.environ.get('SLACK_WEBHOOK_URL') Then we'll use the download manager to retrieve a single dataset dm = eumetsat.DownloadManager(user_key, user_secret, data_dir, metadata_db_fp, debug_fp, slack_webhook_url=slack_webhook_url, slack_id=slack_id) start_date = '2020-01-01 00:00' end_date = '2020-01-01 00:05' dm.download_date_range(start_date, end_date) 2020-12-17 00:21:11,192 - INFO - ********** Download Manager Initialised ************** 2020-12-17 00:21:11,777 - INFO - 1 files queried, 0 found in ../data/raw, 1 to download. 100% 1/1 [00:07 < 00:07, 6.59s/it] start_date end_date result_time platform_short_name platform_orbit_type instrument_name sensor_op_mode center_srs_name center_position file_name file_size missing_pct downloaded 0 2020-01-01 00:00:07.683000+00:00 2020-01-01 00:04:14.102000+00:00 2020-01-01 00:04:14.102000+00:00 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101000414.1020000... 99819 0 2020-12-17 00:21:18.312026 Once the files have been downloaded they will be automatically detected and skipped if downloading is attempted again _ = dm.download_date_range(start_date, end_date) 2020-12-17 00:21:31,507 - INFO - 1 files queried, 1 found in ../data/raw, 0 to download. 2020-12-17 00:21:31,512 - INFO - No files will be downloaded. Set DownloadManager bucket_name argument for local download We can retrieve the metadata for all historical downloads by calling the get_df_metadata method df_metadata = dm.get_df_metadata() df_metadata.head()","title":"Using the Download Manager"},{"location":"102_reprojecting/","text":"Reprojecting \u00b6 from satip import reproj import matplotlib.pyplot as plt import cartopy.crs as ccrs import os User Inputs \u00b6 We have to specify the directory where the data native filepaths are located data_dir = '../data/raw' Loading the Scene \u00b6 We'll then load the file using the reproj library native_fps = sorted([f'{data_dir}/{f}' for f in os.listdir(data_dir) if '.nat' in f]) native_fp = native_fps[0] scene = reproj.load_scene(native_fp) scene.load(['HRV']) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() Next we'll visualise the data in the HRV layer. In this particular image it looks like we've caught a period where the satellite is slightly off-kilter. Fortunately the area definition we create accounts for periods when this occurs. seviri = reproj.get_seviri_area_def(native_fp) seviri_crs = seviri.to_cartopy_crs() # Plotting fig = plt.figure(dpi=250, figsize=(10, 10)) ax = plt.axes(projection=seviri_crs) scene['HRV'].plot.imshow(ax=ax, add_colorbar=False, cmap='magma', vmin=0, vmax=50) ax.set_title('') ax.coastlines(resolution='50m', alpha=0.8, color='white') C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() <cartopy.mpl.feature_artist.FeatureArtist at 0x28f1fdd6970> Reprojection \u00b6 The main way to carry out a reprojection is with the Reprojector class reprojector = reproj.Reprojector() reprojector <satip.reproj.Reprojector at 0x28f14995100> From which the reproject method can be called, the default method that will be used is through pyresample %%capture --no-stdout %%time ds_reproj = reprojector.reproject(native_fp) Wall time: 5.58 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Attributes: (0) It's also possible to use the functional api, e.g. for our task we could have used full_scene_pyresample to achieve the same results. %%capture --no-stdout %%time ds_reproj = reproj.full_scene_pyresample(native_fp) Wall time: 4.98 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Attributes: (0) Alongside pyresample its also possible to use pyinterp which can be faster when the dataset has fewer layers. When using pyinterp we have to provide the coordinates of the new grid as well as the coordinates that grid has in the original CRS. %%capture --no-stdout %%time new_coords_fp = f'../data/intermediate/reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = reproj.Reprojector(new_coords_fp, new_grid_fp) ds_reproj = reprojector.reproject(native_fp, reproj_library='pyinterp') Wall time: 16.5 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * x (x) float64 4.388e+06 4.384e+06 ... -3.088e+06 * y (y) float64 1.692e+06 1.696e+06 ... 9.012e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float64 nan nan nan ... nan nan nan xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) x (x) float64 4.388e+06 4.384e+06 ... -3.088e+06 array([ 4388000., 4384000., 4380000., ..., -3080000., -3084000., -3088000.]) y (y) float64 1.692e+06 1.696e+06 ... 9.012e+06 array([1692000., 1696000., 1700000., ..., 9004000., 9008000., 9012000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float64 nan nan nan nan ... nan nan nan nan orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] array([[[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., ... ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]]]) Attributes: (0)","title":"Reprojecting"},{"location":"102_reprojecting/#reprojecting","text":"from satip import reproj import matplotlib.pyplot as plt import cartopy.crs as ccrs import os","title":"Reprojecting"},{"location":"102_reprojecting/#user-inputs","text":"We have to specify the directory where the data native filepaths are located data_dir = '../data/raw'","title":"User Inputs"},{"location":"102_reprojecting/#loading-the-scene","text":"We'll then load the file using the reproj library native_fps = sorted([f'{data_dir}/{f}' for f in os.listdir(data_dir) if '.nat' in f]) native_fp = native_fps[0] scene = reproj.load_scene(native_fp) scene.load(['HRV']) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() Next we'll visualise the data in the HRV layer. In this particular image it looks like we've caught a period where the satellite is slightly off-kilter. Fortunately the area definition we create accounts for periods when this occurs. seviri = reproj.get_seviri_area_def(native_fp) seviri_crs = seviri.to_cartopy_crs() # Plotting fig = plt.figure(dpi=250, figsize=(10, 10)) ax = plt.axes(projection=seviri_crs) scene['HRV'].plot.imshow(ax=ax, add_colorbar=False, cmap='magma', vmin=0, vmax=50) ax.set_title('') ax.coastlines(resolution='50m', alpha=0.8, color='white') C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() <cartopy.mpl.feature_artist.FeatureArtist at 0x28f1fdd6970>","title":"Loading the Scene"},{"location":"102_reprojecting/#reprojection","text":"The main way to carry out a reprojection is with the Reprojector class reprojector = reproj.Reprojector() reprojector <satip.reproj.Reprojector at 0x28f14995100> From which the reproject method can be called, the default method that will be used is through pyresample %%capture --no-stdout %%time ds_reproj = reprojector.reproject(native_fp) Wall time: 5.58 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Attributes: (0) It's also possible to use the functional api, e.g. for our task we could have used full_scene_pyresample to achieve the same results. %%capture --no-stdout %%time ds_reproj = reproj.full_scene_pyresample(native_fp) Wall time: 4.98 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Attributes: (0) Alongside pyresample its also possible to use pyinterp which can be faster when the dataset has fewer layers. When using pyinterp we have to provide the coordinates of the new grid as well as the coordinates that grid has in the original CRS. %%capture --no-stdout %%time new_coords_fp = f'../data/intermediate/reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = reproj.Reprojector(new_coords_fp, new_grid_fp) ds_reproj = reprojector.reproject(native_fp, reproj_library='pyinterp') Wall time: 16.5 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * x (x) float64 4.388e+06 4.384e+06 ... -3.088e+06 * y (y) float64 1.692e+06 1.696e+06 ... 9.012e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float64 nan nan nan ... nan nan nan xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) x (x) float64 4.388e+06 4.384e+06 ... -3.088e+06 array([ 4388000., 4384000., 4380000., ..., -3080000., -3084000., -3088000.]) y (y) float64 1.692e+06 1.696e+06 ... 9.012e+06 array([1692000., 1696000., 1700000., ..., 9004000., 9008000., 9012000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float64 nan nan nan nan ... nan nan nan nan orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] array([[[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., ... ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]]]) Attributes: (0)","title":"Reprojection"},{"location":"103_loading/","text":"Loading from Zarr \u00b6 import numpy as np import pandas as pd from satip import io import seaborn as sns import matplotlib as mpl import matplotlib.pyplot as plt import cartopy.crs as ccrs import FEAutils as hlp from warnings import warn from ipypb import track User Inputs \u00b6 We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' Loading Data \u00b6 The satip wrapper for loading data will then generate an xarray Dataset when passed the path to the zarr bucket ds = io . load_from_zarr_bucket ( zarr_bucket ) ds [ 'stacked_eumetsat_data' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 11652, x: 1870, y: 1831, variable: 12)> dask.array<xarray-stacked_eumetsat_data, shape=(11652, 1870, 1831, 12), dtype=int16, chunksize=(36, 1870, 1831, 1), chunktype=numpy.ndarray> Coordinates: * time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-04T06:19:16 * variable (variable) object 'HRV' 'IR_016' 'IR_039' ... 'WV_062' 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 11652 x : 1870 y : 1831 variable : 12 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> Array Chunk Bytes 957.51 GB 246.53 MB Shape (11652, 1870, 1831, 12) (36, 1870, 1831, 1) Count 3889 Tasks 3888 Chunks Type int16 numpy.ndarray 11652 1 12 1831 1870 Coordinates: (4) time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-... array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-04-04T06:09:17.000000000', '2020-04-04T06:14:17.000000000', '2020-04-04T06:19:16.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} We can then index this as we would any other xarray object da_HRV_sample = ds [ 'stacked_eumetsat_data' ] . isel ( time = 0 ) . sel ( variable = 'HRV' ) da_HRV_sample /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (x: 1870, y: 1831)> dask.array<getitem, shape=(1870, 1831), dtype=int16, chunksize=(1870, 1831), chunktype=numpy.ndarray> Coordinates: time datetime64[ns] 2021-03-19T13:20:10 variable <U3 'HRV' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' x : 1870 y : 1831 dask.array<chunksize=(1870, 1831), meta=np.ndarray> Array Chunk Bytes 6.85 MB 6.85 MB Shape (1870, 1831) (1870, 1831) Count 3902 Tasks 1 Chunks Type int16 numpy.ndarray 1831 1870 Coordinates: (4) time () datetime64[ns] 2021-03-19T13:20:10 array('2021-03-19T13:20:10.000000000', dtype='datetime64[ns]') variable () <U3 'HRV' array('HRV', dtype='<U3') x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} As well as visualise it, here we'll use cartopy to plot the data with a coastline overlay. The darker area on the right hand side of the image are the areas where the sun has already set. fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_HRV_sample . T . plot . imshow ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-7-5badebb6746d>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x1cb9345ca30>","title":"Loading from Zarr"},{"location":"103_loading/#loading-from-zarr","text":"import numpy as np import pandas as pd from satip import io import seaborn as sns import matplotlib as mpl import matplotlib.pyplot as plt import cartopy.crs as ccrs import FEAutils as hlp from warnings import warn from ipypb import track","title":"Loading from Zarr"},{"location":"103_loading/#user-inputs","text":"We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16'","title":"User Inputs"},{"location":"103_loading/#loading-data","text":"The satip wrapper for loading data will then generate an xarray Dataset when passed the path to the zarr bucket ds = io . load_from_zarr_bucket ( zarr_bucket ) ds [ 'stacked_eumetsat_data' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 11652, x: 1870, y: 1831, variable: 12)> dask.array<xarray-stacked_eumetsat_data, shape=(11652, 1870, 1831, 12), dtype=int16, chunksize=(36, 1870, 1831, 1), chunktype=numpy.ndarray> Coordinates: * time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-04T06:19:16 * variable (variable) object 'HRV' 'IR_016' 'IR_039' ... 'WV_062' 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 11652 x : 1870 y : 1831 variable : 12 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> Array Chunk Bytes 957.51 GB 246.53 MB Shape (11652, 1870, 1831, 12) (36, 1870, 1831, 1) Count 3889 Tasks 3888 Chunks Type int16 numpy.ndarray 11652 1 12 1831 1870 Coordinates: (4) time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-... array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-04-04T06:09:17.000000000', '2020-04-04T06:14:17.000000000', '2020-04-04T06:19:16.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} We can then index this as we would any other xarray object da_HRV_sample = ds [ 'stacked_eumetsat_data' ] . isel ( time = 0 ) . sel ( variable = 'HRV' ) da_HRV_sample /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (x: 1870, y: 1831)> dask.array<getitem, shape=(1870, 1831), dtype=int16, chunksize=(1870, 1831), chunktype=numpy.ndarray> Coordinates: time datetime64[ns] 2021-03-19T13:20:10 variable <U3 'HRV' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' x : 1870 y : 1831 dask.array<chunksize=(1870, 1831), meta=np.ndarray> Array Chunk Bytes 6.85 MB 6.85 MB Shape (1870, 1831) (1870, 1831) Count 3902 Tasks 1 Chunks Type int16 numpy.ndarray 1831 1870 Coordinates: (4) time () datetime64[ns] 2021-03-19T13:20:10 array('2021-03-19T13:20:10.000000000', dtype='datetime64[ns]') variable () <U3 'HRV' array('HRV', dtype='<U3') x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} As well as visualise it, here we'll use cartopy to plot the data with a coastline overlay. The darker area on the right hand side of the image are the areas where the sun has already set. fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_HRV_sample . T . plot . imshow ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-7-5badebb6746d>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x1cb9345ca30>","title":"Loading Data"},{"location":"104_ts_analysis/","text":"Extracting Time-Series for Analysis \u00b6 from satip import io import shapely import geopandas as gpd import seaborn as sns import matplotlib.pyplot as plt import cartopy.crs as ccrs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 3.68rows/s] User Inputs \u00b6 We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' Loading Data \u00b6 Then the satip wrapper for loading data will generate an xarray Dataset ds = io . load_from_zarr_bucket ( zarr_bucket ) ds /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (time: 11662, variable: 12, x: 1870, y: 1831) Coordinates: * time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020... * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 Data variables: stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> xarray.Dataset Dimensions: time : 11662 variable : 12 x : 1870 y : 1831 Coordinates: (4) time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-... array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-04-01T00:39:20.000000000', '2020-04-01T00:44:20.000000000', '2020-04-01T00:49:20.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Data variables: (1) stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Array Chunk Bytes 958.33 GB 246.53 MB Shape (11662, 1870, 1831, 12) (36, 1870, 1831, 1) Count 3889 Tasks 3888 Chunks Type int16 numpy.ndarray 11662 1 12 1831 1870 Attributes: (0) We can then index this as we would any other xarray object da_HRV_sample = ds [ 'stacked_eumetsat_data' ] . isel ( time = slice ( 800 , 900 )) . sel ( variable = 'HRV' ) da_HRV_sample /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 100, x: 1870, y: 1831)> dask.array<getitem, shape=(100, 1870, 1831), dtype=int16, chunksize=(36, 1870, 1831), chunktype=numpy.ndarray> Coordinates: * time (time) datetime64[ns] 2020-01-03T12:49:15 ... 2020-01-03T21:04:16 variable <U3 'HRV' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 100 x : 1870 y : 1831 dask.array<chunksize=(28, 1870, 1831), meta=np.ndarray> Array Chunk Bytes 684.79 MB 246.53 MB Shape (100, 1870, 1831) (36, 1870, 1831) Count 3928 Tasks 3 Chunks Type int16 numpy.ndarray 1831 1870 100 Coordinates: (4) time (time) datetime64[ns] 2020-01-03T12:49:15 ... 2020-01-... array(['2020-01-03T12:49:15.000000000', '2020-01-03T12:54:16.000000000', '2020-01-03T12:59:16.000000000', '2020-01-03T13:04:16.000000000', '2020-01-03T13:09:16.000000000', '2020-01-03T13:14:16.000000000', '2020-01-03T13:19:16.000000000', '2020-01-03T13:24:16.000000000', '2020-01-03T13:29:16.000000000', '2020-01-03T13:34:15.000000000', '2020-01-03T13:39:15.000000000', '2020-01-03T13:44:15.000000000', '2020-01-03T13:49:15.000000000', '2020-01-03T13:54:15.000000000', '2020-01-03T13:59:15.000000000', '2020-01-03T14:04:15.000000000', '2020-01-03T14:09:15.000000000', '2020-01-03T14:14:15.000000000', '2020-01-03T14:19:15.000000000', '2020-01-03T14:24:16.000000000', '2020-01-03T14:29:17.000000000', '2020-01-03T14:34:18.000000000', '2020-01-03T14:39:18.000000000', '2020-01-03T14:44:18.000000000', '2020-01-03T14:49:18.000000000', '2020-01-03T14:54:16.000000000', '2020-01-03T14:59:16.000000000', '2020-01-03T15:04:16.000000000', '2020-01-03T15:09:16.000000000', '2020-01-03T15:14:16.000000000', '2020-01-03T15:19:16.000000000', '2020-01-03T15:24:16.000000000', '2020-01-03T15:29:16.000000000', '2020-01-03T15:34:16.000000000', '2020-01-03T15:39:16.000000000', '2020-01-03T15:44:16.000000000', '2020-01-03T15:49:15.000000000', '2020-01-03T15:54:15.000000000', '2020-01-03T15:59:15.000000000', '2020-01-03T16:04:15.000000000', '2020-01-03T16:09:15.000000000', '2020-01-03T16:14:15.000000000', '2020-01-03T16:19:15.000000000', '2020-01-03T16:24:16.000000000', '2020-01-03T16:29:17.000000000', '2020-01-03T16:34:18.000000000', '2020-01-03T16:39:18.000000000', '2020-01-03T16:44:18.000000000', '2020-01-03T16:49:18.000000000', '2020-01-03T16:54:17.000000000', '2020-01-03T16:59:17.000000000', '2020-01-03T17:04:17.000000000', '2020-01-03T17:09:16.000000000', '2020-01-03T17:14:16.000000000', '2020-01-03T17:19:16.000000000', '2020-01-03T17:24:16.000000000', '2020-01-03T17:29:16.000000000', '2020-01-03T17:34:16.000000000', '2020-01-03T17:39:16.000000000', '2020-01-03T17:44:16.000000000', '2020-01-03T17:49:16.000000000', '2020-01-03T17:54:16.000000000', '2020-01-03T17:59:16.000000000', '2020-01-03T18:04:15.000000000', '2020-01-03T18:09:15.000000000', '2020-01-03T18:14:15.000000000', '2020-01-03T18:19:15.000000000', '2020-01-03T18:24:15.000000000', '2020-01-03T18:29:15.000000000', '2020-01-03T18:34:15.000000000', '2020-01-03T18:39:15.000000000', '2020-01-03T18:44:15.000000000', '2020-01-03T18:49:15.000000000', '2020-01-03T18:54:16.000000000', '2020-01-03T18:59:16.000000000', '2020-01-03T19:04:16.000000000', '2020-01-03T19:09:16.000000000', '2020-01-03T19:14:15.000000000', '2020-01-03T19:19:15.000000000', '2020-01-03T19:24:15.000000000', '2020-01-03T19:29:15.000000000', '2020-01-03T19:34:15.000000000', '2020-01-03T19:39:15.000000000', '2020-01-03T19:44:15.000000000', '2020-01-03T19:49:15.000000000', '2020-01-03T19:54:16.000000000', '2020-01-03T19:59:16.000000000', '2020-01-03T20:04:16.000000000', '2020-01-03T20:09:16.000000000', '2020-01-03T20:14:16.000000000', '2020-01-03T20:19:15.000000000', '2020-01-03T20:24:15.000000000', '2020-01-03T20:29:15.000000000', '2020-01-03T20:34:15.000000000', '2020-01-03T20:39:15.000000000', '2020-01-03T20:44:15.000000000', '2020-01-03T20:49:15.000000000', '2020-01-03T20:54:16.000000000', '2020-01-03T20:59:16.000000000', '2020-01-03T21:04:16.000000000'], dtype='datetime64[ns]') variable () <U3 'HRV' array('HRV', dtype='<U3') x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Extracting Time-Series \u00b6 The coordinates are for a Transverse Mercator projection, we'll create a helper function that converts latitude and longitude into this coordinate system def convert_lon_lat_to_crs_coords ( lon = 0.1 , lat = 51.5 ): new_coords_point = ( gpd . GeoDataFrame ( geometry = [ shapely . geometry . Point ( lon , lat )], crs = 'EPSG:4326' ) . to_crs ( 'EPSG:3857' ) . loc [ 0 , 'geometry' ]) new_coords = ( new_coords_point . x , new_coords_point . y ) return new_coords x , y = convert_lon_lat_to_crs_coords ( lon = 1 , lat = 50 ) x , y (111319.49079327357, 6446275.841017158) We'll now interpolate the data at this location and extract a time-series of the HRV intensity s_HRV = da_HRV_sample . interp ( x = x , y = y ) . sortby ( 'time' ) . to_series () s_HRV . plot () C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\xarray\\core\\indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large chunk and silence this warning, set the option >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}): ... array[indexer] To avoid creating the large chunks, set the option >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}): ... array[indexer] return self.array[key] <AxesSubplot:xlabel='time'> We can also visualise the intensity distribution for this series sns . histplot ( s_HRV ) <AxesSubplot:xlabel='stacked_eumetsat_data', ylabel='Count'>","title":"Extracting Time-Series"},{"location":"104_ts_analysis/#extracting-time-series-for-analysis","text":"from satip import io import shapely import geopandas as gpd import seaborn as sns import matplotlib.pyplot as plt import cartopy.crs as ccrs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 3.68rows/s]","title":"Extracting Time-Series for Analysis"},{"location":"104_ts_analysis/#user-inputs","text":"We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16'","title":"User Inputs"},{"location":"104_ts_analysis/#loading-data","text":"Then the satip wrapper for loading data will generate an xarray Dataset ds = io . load_from_zarr_bucket ( zarr_bucket ) ds /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (time: 11662, variable: 12, x: 1870, y: 1831) Coordinates: * time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020... * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 Data variables: stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> xarray.Dataset Dimensions: time : 11662 variable : 12 x : 1870 y : 1831 Coordinates: (4) time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-... array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-04-01T00:39:20.000000000', '2020-04-01T00:44:20.000000000', '2020-04-01T00:49:20.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Data variables: (1) stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Array Chunk Bytes 958.33 GB 246.53 MB Shape (11662, 1870, 1831, 12) (36, 1870, 1831, 1) Count 3889 Tasks 3888 Chunks Type int16 numpy.ndarray 11662 1 12 1831 1870 Attributes: (0) We can then index this as we would any other xarray object da_HRV_sample = ds [ 'stacked_eumetsat_data' ] . isel ( time = slice ( 800 , 900 )) . sel ( variable = 'HRV' ) da_HRV_sample /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 100, x: 1870, y: 1831)> dask.array<getitem, shape=(100, 1870, 1831), dtype=int16, chunksize=(36, 1870, 1831), chunktype=numpy.ndarray> Coordinates: * time (time) datetime64[ns] 2020-01-03T12:49:15 ... 2020-01-03T21:04:16 variable <U3 'HRV' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 100 x : 1870 y : 1831 dask.array<chunksize=(28, 1870, 1831), meta=np.ndarray> Array Chunk Bytes 684.79 MB 246.53 MB Shape (100, 1870, 1831) (36, 1870, 1831) Count 3928 Tasks 3 Chunks Type int16 numpy.ndarray 1831 1870 100 Coordinates: (4) time (time) datetime64[ns] 2020-01-03T12:49:15 ... 2020-01-... array(['2020-01-03T12:49:15.000000000', '2020-01-03T12:54:16.000000000', '2020-01-03T12:59:16.000000000', '2020-01-03T13:04:16.000000000', '2020-01-03T13:09:16.000000000', '2020-01-03T13:14:16.000000000', '2020-01-03T13:19:16.000000000', '2020-01-03T13:24:16.000000000', '2020-01-03T13:29:16.000000000', '2020-01-03T13:34:15.000000000', '2020-01-03T13:39:15.000000000', '2020-01-03T13:44:15.000000000', '2020-01-03T13:49:15.000000000', '2020-01-03T13:54:15.000000000', '2020-01-03T13:59:15.000000000', '2020-01-03T14:04:15.000000000', '2020-01-03T14:09:15.000000000', '2020-01-03T14:14:15.000000000', '2020-01-03T14:19:15.000000000', '2020-01-03T14:24:16.000000000', '2020-01-03T14:29:17.000000000', '2020-01-03T14:34:18.000000000', '2020-01-03T14:39:18.000000000', '2020-01-03T14:44:18.000000000', '2020-01-03T14:49:18.000000000', '2020-01-03T14:54:16.000000000', '2020-01-03T14:59:16.000000000', '2020-01-03T15:04:16.000000000', '2020-01-03T15:09:16.000000000', '2020-01-03T15:14:16.000000000', '2020-01-03T15:19:16.000000000', '2020-01-03T15:24:16.000000000', '2020-01-03T15:29:16.000000000', '2020-01-03T15:34:16.000000000', '2020-01-03T15:39:16.000000000', '2020-01-03T15:44:16.000000000', '2020-01-03T15:49:15.000000000', '2020-01-03T15:54:15.000000000', '2020-01-03T15:59:15.000000000', '2020-01-03T16:04:15.000000000', '2020-01-03T16:09:15.000000000', '2020-01-03T16:14:15.000000000', '2020-01-03T16:19:15.000000000', '2020-01-03T16:24:16.000000000', '2020-01-03T16:29:17.000000000', '2020-01-03T16:34:18.000000000', '2020-01-03T16:39:18.000000000', '2020-01-03T16:44:18.000000000', '2020-01-03T16:49:18.000000000', '2020-01-03T16:54:17.000000000', '2020-01-03T16:59:17.000000000', '2020-01-03T17:04:17.000000000', '2020-01-03T17:09:16.000000000', '2020-01-03T17:14:16.000000000', '2020-01-03T17:19:16.000000000', '2020-01-03T17:24:16.000000000', '2020-01-03T17:29:16.000000000', '2020-01-03T17:34:16.000000000', '2020-01-03T17:39:16.000000000', '2020-01-03T17:44:16.000000000', '2020-01-03T17:49:16.000000000', '2020-01-03T17:54:16.000000000', '2020-01-03T17:59:16.000000000', '2020-01-03T18:04:15.000000000', '2020-01-03T18:09:15.000000000', '2020-01-03T18:14:15.000000000', '2020-01-03T18:19:15.000000000', '2020-01-03T18:24:15.000000000', '2020-01-03T18:29:15.000000000', '2020-01-03T18:34:15.000000000', '2020-01-03T18:39:15.000000000', '2020-01-03T18:44:15.000000000', '2020-01-03T18:49:15.000000000', '2020-01-03T18:54:16.000000000', '2020-01-03T18:59:16.000000000', '2020-01-03T19:04:16.000000000', '2020-01-03T19:09:16.000000000', '2020-01-03T19:14:15.000000000', '2020-01-03T19:19:15.000000000', '2020-01-03T19:24:15.000000000', '2020-01-03T19:29:15.000000000', '2020-01-03T19:34:15.000000000', '2020-01-03T19:39:15.000000000', '2020-01-03T19:44:15.000000000', '2020-01-03T19:49:15.000000000', '2020-01-03T19:54:16.000000000', '2020-01-03T19:59:16.000000000', '2020-01-03T20:04:16.000000000', '2020-01-03T20:09:16.000000000', '2020-01-03T20:14:16.000000000', '2020-01-03T20:19:15.000000000', '2020-01-03T20:24:15.000000000', '2020-01-03T20:29:15.000000000', '2020-01-03T20:34:15.000000000', '2020-01-03T20:39:15.000000000', '2020-01-03T20:44:15.000000000', '2020-01-03T20:49:15.000000000', '2020-01-03T20:54:16.000000000', '2020-01-03T20:59:16.000000000', '2020-01-03T21:04:16.000000000'], dtype='datetime64[ns]') variable () <U3 'HRV' array('HRV', dtype='<U3') x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []}","title":"Loading Data"},{"location":"104_ts_analysis/#extracting-time-series","text":"The coordinates are for a Transverse Mercator projection, we'll create a helper function that converts latitude and longitude into this coordinate system def convert_lon_lat_to_crs_coords ( lon = 0.1 , lat = 51.5 ): new_coords_point = ( gpd . GeoDataFrame ( geometry = [ shapely . geometry . Point ( lon , lat )], crs = 'EPSG:4326' ) . to_crs ( 'EPSG:3857' ) . loc [ 0 , 'geometry' ]) new_coords = ( new_coords_point . x , new_coords_point . y ) return new_coords x , y = convert_lon_lat_to_crs_coords ( lon = 1 , lat = 50 ) x , y (111319.49079327357, 6446275.841017158) We'll now interpolate the data at this location and extract a time-series of the HRV intensity s_HRV = da_HRV_sample . interp ( x = x , y = y ) . sortby ( 'time' ) . to_series () s_HRV . plot () C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\xarray\\core\\indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large chunk and silence this warning, set the option >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}): ... array[indexer] To avoid creating the large chunks, set the option >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}): ... array[indexer] return self.array[key] <AxesSubplot:xlabel='time'> We can also visualise the intensity distribution for this series sns . histplot ( s_HRV ) <AxesSubplot:xlabel='stacked_eumetsat_data', ylabel='Count'>","title":"Extracting Time-Series"},{"location":"105_summary/","text":"Zarr Database Summary & Validation \u00b6 import numpy as np import pandas as pd from satip import io import seaborn as sns import matplotlib as mpl import matplotlib.pyplot as plt import cartopy.crs as ccrs import FEAutils as hlp from warnings import warn from ipypb import track C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.23rows/s] User Inputs \u00b6 We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16' Data Loading & Coverage \u00b6 The satip wrapper for loading data will then generate an xarray Dataset when passed the path to the zarr bucket ds = io . load_from_zarr_bucket ( zarr_bucket ) ds [ 'stacked_eumetsat_data' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 11652, x: 1870, y: 1831, variable: 12)> dask.array<xarray-stacked_eumetsat_data, shape=(11652, 1870, 1831, 12), dtype=int16, chunksize=(36, 1870, 1831, 1), chunktype=numpy.ndarray> Coordinates: * time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-04T06:19:16 * variable (variable) object 'HRV' 'IR_016' 'IR_039' ... 'WV_062' 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 11652 x : 1870 y : 1831 variable : 12 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> Array Chunk Bytes 957.51 GB 246.53 MB Shape (11652, 1870, 1831, 12) (36, 1870, 1831, 1) Count 3889 Tasks 3888 Chunks Type int16 numpy.ndarray 11652 1 12 1831 1870 Coordinates: (4) time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-... array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-04-04T06:09:17.000000000', '2020-04-04T06:14:17.000000000', '2020-04-04T06:19:16.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} We'll quickly visualise the data coverage that's provided in the database. N.b. Here we've made the assumption that an image is generated every 5 minutes. round_dt_idx = lambda dt_idx : pd . to_datetime ((( dt_idx . astype ( np . int64 ) // ns5min + 1 ) * ns5min )) ns5min = 5 * 60 * 1000000000 zarr_db_dts = pd . to_datetime ( ds [ 'stacked_eumetsat_data' ] . time . values ) dt_rng_5m = round_dt_idx ( pd . date_range ( zarr_db_dts . min (), zarr_db_dts . max (), freq = '5T' )) s_db_coverage = pd . Series ( round_dt_idx ( zarr_db_dts )) . value_counts () . reindex ( dt_rng_5m ) current_db_coverage = 1 - s_db_coverage . isnull () . mean () print ( f 'The database coverage is currently at { 100 * current_db_coverage : .1f } %' ) # Plotting fig , ax = plt . subplots ( dpi = 150 ) s_db_coverage . resample ( 'D' ) . sum () . pipe ( lambda s : 100 * s / s . max ()) . plot . area ( ax = ax ) ax . set_ylim ( 0 , 100 ) ax . set_ylabel ( 'Database Coverage (%)' ) hlp . hide_spines ( ax ) The database coverage is currently at 5.0% We'll create a slightly modified version of this that doesn't show percentage coverage for each day but instead considers each 5 minute period and groups batches of data that were retrieved sequentially #exports def extract_dt_batch_sets ( zarr_db_dts ): dt_rng_split_idxs = ( pd . Series ( zarr_db_dts ) . diff ( 1 ) . dt . total_seconds () . abs () > ( 5 * 60 * 2 )) . replace ( False , np . nan ) . dropna () . index dt_batch_start_idxs = [ 0 ] + list ( dt_rng_split_idxs ) dt_batch_end_idxs = list ( dt_rng_split_idxs - 1 ) + [ len ( zarr_db_dts ) - 1 ] dt_batches = [] for dt_batch_start_idx , dt_batch_end_idx in zip ( dt_batch_start_idxs , dt_batch_end_idxs ): dt_batches += [( zarr_db_dts [ dt_batch_start_idx ], zarr_db_dts [ dt_batch_end_idx ])] return dt_batches dt_batches = extract_dt_batch_sets ( zarr_db_dts ) # Plotting fig , ax = plt . subplots ( dpi = 150 ) cmap = mpl . cm . get_cmap ( 'magma' ) total_dts_processed = 0 for batch_start_dt , batch_end_dt in track ( dt_batches ): if batch_start_dt == batch_end_dt : s_db_batch = pd . Series ([ 1 , 1 ], index = [ batch_start_dt , batch_start_dt + pd . Timedelta ( minutes = 5 )]) total_dts_processed += 1 batch_mid_pct_processed = total_dts_processed / zarr_db_dts . size else : s_db_batch = s_db_coverage [ batch_start_dt : batch_end_dt ] total_dts_processed += s_db_batch . size batch_mid_pct_processed = ( total_dts_processed - ( s_db_batch . size / 2 )) / zarr_db_dts . size color = cmap ( batch_mid_pct_processed ) s_db_batch . plot . area ( color = color , ax = ax ) ax . set_xlim ( zarr_db_dts . min (), zarr_db_dts . max ()) ax . set_ylim ( 0 , 1 ) hlp . hide_spines ( ax ) 100% 62/62 [06:28 < 00:10, 6.26s/it] Summary Statistics \u00b6 We'll start by calculating the average reflectance for a single month to check that no dodgy regions jump out. Interestly we can see mountainous regions such as the Alps jump out due to the high reflectance of snow. %% time # takes ca.18 mins da_HRV_mean = ( ds [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' , time = '2020-03' ) . mean ( dim = 'time' ) ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_HRV_mean . T . plot . imshow ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-16-455a547b74f1>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x20d83f79fd0> We'll also look at how the average reflectance changes with time of day %% time # if this fails take avg of x and y, then convert to df and process with pandas da_HRV_hourly_mean = ( ds [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' , time = '2020-03' ) . groupby ( 'time.dt.hour' ) . mean ( dim = [ 'x' , 'y' ]) . compute () ) da_HRV_hourly_mean . plot () We'll also get the minimum and maximum values present for each variable #exports def get_var_min_maxs ( ds ): mins = ds [ 'stacked_eumetsat_data' ] . sel ( time = '2020-03' ) . min ([ 'time' , 'x' , 'y' ]) . compute () maxs = ds [ 'stacked_eumetsat_data' ] . sel ( time = '2020-03' ) . max ([ 'time' , 'x' , 'y' ]) . compute () return mins , maxs mins , maxs = get_var_min_maxs ( ds ) mins , maxs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\xarray\\core\\indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large chunk and silence this warning, set the option >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}): ... array[indexer] To avoid creating the large chunks, set the option >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}): ... array[indexer] return self.array[key] Offline Validation \u00b6 We'll now do some quick data quality checks, including checking for duplicates and any null values. We'll start with the duplicates. #exports def check_for_duplicates ( ds ): ds_dts = pd . to_datetime ( ds . time . values ) num_dupes = ds_dts . duplicated () . sum () assert num_dupes == 0 , f 'There are { num_dupes } duplicate indexes in the database' return check_for_duplicates ( ds ) Then check for any nulls. #exports get_null_count = lambda ds : ( ds ==- 1 ) . sum () %% time get_null_count ( ds )","title":"Database Summary"},{"location":"105_summary/#zarr-database-summary-validation","text":"import numpy as np import pandas as pd from satip import io import seaborn as sns import matplotlib as mpl import matplotlib.pyplot as plt import cartopy.crs as ccrs import FEAutils as hlp from warnings import warn from ipypb import track C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.23rows/s]","title":"Zarr Database Summary &amp; Validation"},{"location":"105_summary/#user-inputs","text":"We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/zarr_full_extent_TM_int16'","title":"User Inputs"},{"location":"105_summary/#data-loading-coverage","text":"The satip wrapper for loading data will then generate an xarray Dataset when passed the path to the zarr bucket ds = io . load_from_zarr_bucket ( zarr_bucket ) ds [ 'stacked_eumetsat_data' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 11652, x: 1870, y: 1831, variable: 12)> dask.array<xarray-stacked_eumetsat_data, shape=(11652, 1870, 1831, 12), dtype=int16, chunksize=(36, 1870, 1831, 1), chunktype=numpy.ndarray> Coordinates: * time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-04T06:19:16 * variable (variable) object 'HRV' 'IR_016' 'IR_039' ... 'WV_062' 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 11652 x : 1870 y : 1831 variable : 12 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> Array Chunk Bytes 957.51 GB 246.53 MB Shape (11652, 1870, 1831, 12) (36, 1870, 1831, 1) Count 3889 Tasks 3888 Chunks Type int16 numpy.ndarray 11652 1 12 1831 1870 Coordinates: (4) time (time) datetime64[ns] 2021-03-19T13:20:10 ... 2020-04-... array(['2021-03-19T13:20:10.000000000', '2021-03-19T13:24:16.000000000', '2021-03-19T13:29:17.000000000', ..., '2020-04-04T06:09:17.000000000', '2020-04-04T06:14:17.000000000', '2020-04-04T06:19:16.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9911189780118609, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2021, 3, 19, 13, 15, 9, 278906), 'end_time': datetime.datetime(2021, 3, 19, 13, 20, 10, 330158), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2790874.9005, 5571248.3904, -2777873.154, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} We'll quickly visualise the data coverage that's provided in the database. N.b. Here we've made the assumption that an image is generated every 5 minutes. round_dt_idx = lambda dt_idx : pd . to_datetime ((( dt_idx . astype ( np . int64 ) // ns5min + 1 ) * ns5min )) ns5min = 5 * 60 * 1000000000 zarr_db_dts = pd . to_datetime ( ds [ 'stacked_eumetsat_data' ] . time . values ) dt_rng_5m = round_dt_idx ( pd . date_range ( zarr_db_dts . min (), zarr_db_dts . max (), freq = '5T' )) s_db_coverage = pd . Series ( round_dt_idx ( zarr_db_dts )) . value_counts () . reindex ( dt_rng_5m ) current_db_coverage = 1 - s_db_coverage . isnull () . mean () print ( f 'The database coverage is currently at { 100 * current_db_coverage : .1f } %' ) # Plotting fig , ax = plt . subplots ( dpi = 150 ) s_db_coverage . resample ( 'D' ) . sum () . pipe ( lambda s : 100 * s / s . max ()) . plot . area ( ax = ax ) ax . set_ylim ( 0 , 100 ) ax . set_ylabel ( 'Database Coverage (%)' ) hlp . hide_spines ( ax ) The database coverage is currently at 5.0% We'll create a slightly modified version of this that doesn't show percentage coverage for each day but instead considers each 5 minute period and groups batches of data that were retrieved sequentially #exports def extract_dt_batch_sets ( zarr_db_dts ): dt_rng_split_idxs = ( pd . Series ( zarr_db_dts ) . diff ( 1 ) . dt . total_seconds () . abs () > ( 5 * 60 * 2 )) . replace ( False , np . nan ) . dropna () . index dt_batch_start_idxs = [ 0 ] + list ( dt_rng_split_idxs ) dt_batch_end_idxs = list ( dt_rng_split_idxs - 1 ) + [ len ( zarr_db_dts ) - 1 ] dt_batches = [] for dt_batch_start_idx , dt_batch_end_idx in zip ( dt_batch_start_idxs , dt_batch_end_idxs ): dt_batches += [( zarr_db_dts [ dt_batch_start_idx ], zarr_db_dts [ dt_batch_end_idx ])] return dt_batches dt_batches = extract_dt_batch_sets ( zarr_db_dts ) # Plotting fig , ax = plt . subplots ( dpi = 150 ) cmap = mpl . cm . get_cmap ( 'magma' ) total_dts_processed = 0 for batch_start_dt , batch_end_dt in track ( dt_batches ): if batch_start_dt == batch_end_dt : s_db_batch = pd . Series ([ 1 , 1 ], index = [ batch_start_dt , batch_start_dt + pd . Timedelta ( minutes = 5 )]) total_dts_processed += 1 batch_mid_pct_processed = total_dts_processed / zarr_db_dts . size else : s_db_batch = s_db_coverage [ batch_start_dt : batch_end_dt ] total_dts_processed += s_db_batch . size batch_mid_pct_processed = ( total_dts_processed - ( s_db_batch . size / 2 )) / zarr_db_dts . size color = cmap ( batch_mid_pct_processed ) s_db_batch . plot . area ( color = color , ax = ax ) ax . set_xlim ( zarr_db_dts . min (), zarr_db_dts . max ()) ax . set_ylim ( 0 , 1 ) hlp . hide_spines ( ax ) 100% 62/62 [06:28 < 00:10, 6.26s/it]","title":"Data Loading &amp; Coverage"},{"location":"105_summary/#summary-statistics","text":"We'll start by calculating the average reflectance for a single month to check that no dodgy regions jump out. Interestly we can see mountainous regions such as the Alps jump out due to the high reflectance of snow. %% time # takes ca.18 mins da_HRV_mean = ( ds [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' , time = '2020-03' ) . mean ( dim = 'time' ) ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_HRV_mean . T . plot . imshow ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-16-455a547b74f1>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x20d83f79fd0> We'll also look at how the average reflectance changes with time of day %% time # if this fails take avg of x and y, then convert to df and process with pandas da_HRV_hourly_mean = ( ds [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' , time = '2020-03' ) . groupby ( 'time.dt.hour' ) . mean ( dim = [ 'x' , 'y' ]) . compute () ) da_HRV_hourly_mean . plot () We'll also get the minimum and maximum values present for each variable #exports def get_var_min_maxs ( ds ): mins = ds [ 'stacked_eumetsat_data' ] . sel ( time = '2020-03' ) . min ([ 'time' , 'x' , 'y' ]) . compute () maxs = ds [ 'stacked_eumetsat_data' ] . sel ( time = '2020-03' ) . max ([ 'time' , 'x' , 'y' ]) . compute () return mins , maxs mins , maxs = get_var_min_maxs ( ds ) mins , maxs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\xarray\\core\\indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large chunk and silence this warning, set the option >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}): ... array[indexer] To avoid creating the large chunks, set the option >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}): ... array[indexer] return self.array[key]","title":"Summary Statistics"},{"location":"105_summary/#offline-validation","text":"We'll now do some quick data quality checks, including checking for duplicates and any null values. We'll start with the duplicates. #exports def check_for_duplicates ( ds ): ds_dts = pd . to_datetime ( ds . time . values ) num_dupes = ds_dts . duplicated () . sum () assert num_dupes == 0 , f 'There are { num_dupes } duplicate indexes in the database' return check_for_duplicates ( ds ) Then check for any nulls. #exports get_null_count = lambda ds : ( ds ==- 1 ) . sum () %% time get_null_count ( ds )","title":"Offline Validation"},{"location":"API/01-parsers/","text":"Parsers \u00b6 ::: satip.parsers","title":"Parsers"},{"location":"API/01-parsers/#parsers","text":"::: satip.parsers","title":"Parsers"},{"location":"about/OCF/","text":"Open Climate Fix \u00b6 Open Climate Fix is a new non-profit research and development lab, totally focused on reducing greenhouse gas emissions as rapidly as possible. Every part of the organisation is designed to maximise climate impact, such as our open and collaborative approach, our rapid prototyping, and our attention on finding scalable & practical solutions. By using an open-source approach, we can draw upon a much larger pool of expertise than any individual company, so combining existing islands of knowledge and accelerating progress. Our approach will be to search for ML (Machine Learning) problems where, if we solve a well-defined ML task, then there is likely to be a large climate impact. Then, for each of these challenges, we will: Collate & release data , and write software tools to make it super-easy for people to consume this data. Run a collaborative \u201cglobal research project\u201d where everyone from 16-year-olds to PhD students to corporate research labs can help solve the ML task (and, over the last 6 weeks, we have received over 300 emails from people who\u2019d love to get involved). Help to put good solutions into production , once the community has developed them, so we can be reducing emissions ASAP. \u2709\ufe0f Sign up to our newsletter","title":"OCF"},{"location":"about/OCF/#open-climate-fix","text":"Open Climate Fix is a new non-profit research and development lab, totally focused on reducing greenhouse gas emissions as rapidly as possible. Every part of the organisation is designed to maximise climate impact, such as our open and collaborative approach, our rapid prototyping, and our attention on finding scalable & practical solutions. By using an open-source approach, we can draw upon a much larger pool of expertise than any individual company, so combining existing islands of knowledge and accelerating progress. Our approach will be to search for ML (Machine Learning) problems where, if we solve a well-defined ML task, then there is likely to be a large climate impact. Then, for each of these challenges, we will: Collate & release data , and write software tools to make it super-easy for people to consume this data. Run a collaborative \u201cglobal research project\u201d where everyone from 16-year-olds to PhD students to corporate research labs can help solve the ML task (and, over the last 6 weeks, we have received over 300 emails from people who\u2019d love to get involved). Help to put good solutions into production , once the community has developed them, so we can be reducing emissions ASAP. \u2709\ufe0f Sign up to our newsletter","title":"Open Climate Fix"},{"location":"about/Solar%20Forecasting/","text":"Solar Forecasting \u00b6 Forecasting solar photovoltaic (PV) power production is hard: As clouds move over PV panels, the power output moves up and down rapidly. To keep the energy grid in balance, operators need to have readily available power generation reserves which usually come from fossil fuel sources. If we have more accurate predictions of how much electricity a PV installation will produce over the next few hours then we can reduce the amount of fossil fuel reserve required. By making solar energy more predictable we will make it easier for the grid to absorb more PV generation and for investors to reduce the risk of solar investments. Supported by the European Space Agency and many other partners we are investigating how to use Machine Learning and satellite images to improve forecasts of PV power generation. The Satip module provides all of the functionality necessary for retrieving, transforming and storing the EUMETSAT data needed in the OCF solar forecasting project. You can find out more about the project here .","title":"Solar Forecasting"},{"location":"about/Solar%20Forecasting/#solar-forecasting","text":"Forecasting solar photovoltaic (PV) power production is hard: As clouds move over PV panels, the power output moves up and down rapidly. To keep the energy grid in balance, operators need to have readily available power generation reserves which usually come from fossil fuel sources. If we have more accurate predictions of how much electricity a PV installation will produce over the next few hours then we can reduce the amount of fossil fuel reserve required. By making solar energy more predictable we will make it easier for the grid to absorb more PV generation and for investors to reduce the risk of solar investments. Supported by the European Space Agency and many other partners we are investigating how to use Machine Learning and satellite images to improve forecasts of PV power generation. The Satip module provides all of the functionality necessary for retrieving, transforming and storing the EUMETSAT data needed in the OCF solar forecasting project. You can find out more about the project here .","title":"Solar Forecasting"}]}