{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Satip Documentation Site \u00b6 Satip is a library for sat ellite i mage p rocessing, and provides all of the functionality necessary for retrieving, transforming and storing EUMETSAT data This site provides user-guides, developer documentation and other information about the satip module Installation \u00b6 To install the satip library please run: pip install satip Development Set-Up \u00b6 To create a new environment you can follow the following code blocks or run the setup_env batch script located in the batch_scripts directory. git clone conda env create -f environment.yml conda activate sat_image_processing We'll also install Jupyter lab interactive plotting for matplotlib See the jupyter-matplotlib docs for more info . The short version is to run these commands from within the sat_image_processing env: jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter labextension install jupyter-matplotlib Publishing to PyPi \u00b6 To publish the satip module to PyPi simply run the following from the batch_scripts directory pypi_publish <anaconda_dir> Where <anaconda_dir> is the path to your anaconda directory - e.g. C:\\Users\\User\\anaconda3 When prompted you should enter your PyPi username and password After this you will be able to install the latest version of satip using pip install satip Pipeline \u00b6 To run the dagster pipeline for continuous data retrieval you can use: dagster pipeline execute -m satip.mario -c pipeline_inputs.yaml","title":"Home"},{"location":"#welcome-to-the-satip-documentation-site","text":"Satip is a library for sat ellite i mage p rocessing, and provides all of the functionality necessary for retrieving, transforming and storing EUMETSAT data This site provides user-guides, developer documentation and other information about the satip module","title":"Welcome to the Satip Documentation Site"},{"location":"#installation","text":"To install the satip library please run: pip install satip","title":"Installation"},{"location":"#development-set-up","text":"To create a new environment you can follow the following code blocks or run the setup_env batch script located in the batch_scripts directory. git clone conda env create -f environment.yml conda activate sat_image_processing We'll also install Jupyter lab interactive plotting for matplotlib See the jupyter-matplotlib docs for more info . The short version is to run these commands from within the sat_image_processing env: jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter labextension install jupyter-matplotlib","title":"Development Set-Up"},{"location":"#publishing-to-pypi","text":"To publish the satip module to PyPi simply run the following from the batch_scripts directory pypi_publish <anaconda_dir> Where <anaconda_dir> is the path to your anaconda directory - e.g. C:\\Users\\User\\anaconda3 When prompted you should enter your PyPi username and password After this you will be able to install the latest version of satip using pip install satip","title":"Publishing to PyPi"},{"location":"#pipeline","text":"To run the dagster pipeline for continuous data retrieval you can use: dagster pipeline execute -m satip.mario -c pipeline_inputs.yaml","title":"Pipeline"},{"location":"00_utils/","text":"Repository Helpers \u00b6 Loading Environment Variables \u00b6 First we'll load the the environment variables env_vars_fp = '../.env' dotenv . load_dotenv ( env_vars_fp ) slack_id = os . environ . get ( 'slack_id' ) slack_webhook_url = os . environ . get ( 'slack_webhook_url' ) Notebook Information \u00b6 We can now easily construct markdown tables notebook_info = { # development 'Utilities' : { 'Directory' : 'nbs' , 'Number' : '00' , 'Description' : 'Code for keeping the repository tidy' , 'Maintainer' : 'Ayrton Bourn' }, 'EUMETSAT' : { 'Directory' : 'nbs' , 'Number' : '01' , 'Description' : 'Development of the API wrapper for ems' , 'Maintainer' : 'Ayrton Bourn' }, 'Reprojection' : { 'Directory' : 'nbs' , 'Number' : '02' , 'Description' : 'Development of the reprojection operator' , 'Maintainer' : 'Ayrton Bourn' }, 'Zarr' : { 'Directory' : 'nbs' , 'Number' : '03' , 'Description' : 'Development of wrappers for loading/saving to Zarr' , 'Maintainer' : 'Ayrton Bourn' }, 'GCP' : { 'Directory' : 'nbs' , 'Number' : '04' , 'Description' : 'Development of GCP interface wrappers' , 'Maintainer' : 'Laurence Watson' }, 'Pipeline' : { 'Directory' : 'nbs' , 'Number' : '05' , 'Description' : 'Development of the pipeline processes' , 'Maintainer' : 'Ayrton Bourn' }, 'Downloading' : { 'Directory' : 'nbs' , 'Number' : '101' , 'Description' : 'Guidance for using the ems download manager' , 'Maintainer' : 'Ayrton Bourn' }, 'Reprojecting' : { 'Directory' : 'nbs' , 'Number' : '102' , 'Description' : 'Guidance for using the reprojection operator' , 'Maintainer' : 'Ayrton Bourn' }, 'Loading' : { 'Directory' : 'nbs' , 'Number' : '103' , 'Description' : 'Guidance for retrieving saved data from Zarr' , 'Maintainer' : 'Ayrton Bourn' }, 'Documentation' : { 'Directory' : 'docs' , 'Number' : '-' , 'Description' : 'Automated generation of docs from notebooks' , 'Maintainer' : 'Ayrton Bourn' }, } nb_table_str = create_markdown_table ( notebook_info ) print ( nb_table_str ) | Id | Directory | Number | Description | Maintainer | |:--------------|:------------|:---------|:---------------------------------------------------|:----------------| | utils | nbs | 00 | Code for keeping the repository tidy | Ayrton Bourn | | EUMETSAT | nbs | 01 | Development of the API wrapper for ems | Ayrton Bourn | | Reprojection | nbs | 02 | Development of the reprojection operator | Ayrton Bourn | | Zarr | nbs | 03 | Development of wrappers for loading/saving to Zarr | Ayrton Bourn | | GCP | nbs | 04 | Development of GCP interface wrappers | Laurence Watson | | Pipeline | nbs | 05 | Development of the pipeline processes | Ayrton Bourn | | Downloading | nbs | 101 | Guidance for using the ems download manager | Ayrton Bourn | | Reprojecting | nbs | 102 | Guidance for using the reprojection operator | Ayrton Bourn | | Loading | nbs | 103 | Guidance for retrieving saved data from Zarr | Ayrton Bourn | | Documentation | docs | - | Automated generation of docs from notebooks | Ayrton Bourn | Logging \u00b6 We'll now initialise the logger and make a test log logger = set_up_logging ( __name__ , '.' , slack_id = slack_id , slack_webhook_url = slack_webhook_url ) logger . log ( logging . INFO , 'This will output to file and Jupyter but not to Slack as it is not critical' ) 2020-11-12 09:58:41,301 - INFO - This will output to file and Jupyter but not to Slack as it is not critical We'll now shutdown the logger handlers and then delete the log file we just made handlers = logger . handlers [:] for handler in handlers : handler . close () logger . removeHandler ( handler ) os . remove ( f ' { __name__ } .txt' ) Finally we'll export the specified functions to the utils.py module","title":"Utilities"},{"location":"00_utils/#repository-helpers","text":"","title":"Repository Helpers"},{"location":"00_utils/#loading-environment-variables","text":"First we'll load the the environment variables env_vars_fp = '../.env' dotenv . load_dotenv ( env_vars_fp ) slack_id = os . environ . get ( 'slack_id' ) slack_webhook_url = os . environ . get ( 'slack_webhook_url' )","title":"Loading Environment Variables"},{"location":"00_utils/#notebook-information","text":"We can now easily construct markdown tables notebook_info = { # development 'Utilities' : { 'Directory' : 'nbs' , 'Number' : '00' , 'Description' : 'Code for keeping the repository tidy' , 'Maintainer' : 'Ayrton Bourn' }, 'EUMETSAT' : { 'Directory' : 'nbs' , 'Number' : '01' , 'Description' : 'Development of the API wrapper for ems' , 'Maintainer' : 'Ayrton Bourn' }, 'Reprojection' : { 'Directory' : 'nbs' , 'Number' : '02' , 'Description' : 'Development of the reprojection operator' , 'Maintainer' : 'Ayrton Bourn' }, 'Zarr' : { 'Directory' : 'nbs' , 'Number' : '03' , 'Description' : 'Development of wrappers for loading/saving to Zarr' , 'Maintainer' : 'Ayrton Bourn' }, 'GCP' : { 'Directory' : 'nbs' , 'Number' : '04' , 'Description' : 'Development of GCP interface wrappers' , 'Maintainer' : 'Laurence Watson' }, 'Pipeline' : { 'Directory' : 'nbs' , 'Number' : '05' , 'Description' : 'Development of the pipeline processes' , 'Maintainer' : 'Ayrton Bourn' }, 'Downloading' : { 'Directory' : 'nbs' , 'Number' : '101' , 'Description' : 'Guidance for using the ems download manager' , 'Maintainer' : 'Ayrton Bourn' }, 'Reprojecting' : { 'Directory' : 'nbs' , 'Number' : '102' , 'Description' : 'Guidance for using the reprojection operator' , 'Maintainer' : 'Ayrton Bourn' }, 'Loading' : { 'Directory' : 'nbs' , 'Number' : '103' , 'Description' : 'Guidance for retrieving saved data from Zarr' , 'Maintainer' : 'Ayrton Bourn' }, 'Documentation' : { 'Directory' : 'docs' , 'Number' : '-' , 'Description' : 'Automated generation of docs from notebooks' , 'Maintainer' : 'Ayrton Bourn' }, } nb_table_str = create_markdown_table ( notebook_info ) print ( nb_table_str ) | Id | Directory | Number | Description | Maintainer | |:--------------|:------------|:---------|:---------------------------------------------------|:----------------| | utils | nbs | 00 | Code for keeping the repository tidy | Ayrton Bourn | | EUMETSAT | nbs | 01 | Development of the API wrapper for ems | Ayrton Bourn | | Reprojection | nbs | 02 | Development of the reprojection operator | Ayrton Bourn | | Zarr | nbs | 03 | Development of wrappers for loading/saving to Zarr | Ayrton Bourn | | GCP | nbs | 04 | Development of GCP interface wrappers | Laurence Watson | | Pipeline | nbs | 05 | Development of the pipeline processes | Ayrton Bourn | | Downloading | nbs | 101 | Guidance for using the ems download manager | Ayrton Bourn | | Reprojecting | nbs | 102 | Guidance for using the reprojection operator | Ayrton Bourn | | Loading | nbs | 103 | Guidance for retrieving saved data from Zarr | Ayrton Bourn | | Documentation | docs | - | Automated generation of docs from notebooks | Ayrton Bourn |","title":"Notebook Information"},{"location":"00_utils/#logging","text":"We'll now initialise the logger and make a test log logger = set_up_logging ( __name__ , '.' , slack_id = slack_id , slack_webhook_url = slack_webhook_url ) logger . log ( logging . INFO , 'This will output to file and Jupyter but not to Slack as it is not critical' ) 2020-11-12 09:58:41,301 - INFO - This will output to file and Jupyter but not to Slack as it is not critical We'll now shutdown the logger handlers and then delete the log file we just made handlers = logger . handlers [:] for handler in handlers : handler . close () logger . removeHandler ( handler ) os . remove ( f ' { __name__ } .txt' ) Finally we'll export the specified functions to the utils.py module","title":"Logging"},{"location":"01_eumetsat/","text":"EUMETSAT API Wrapper Development \u00b6 User Input \u00b6 data_dir = '../data/raw' compressed_dir = '../data/compressed' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' download_data = True Authorising API Access \u00b6 First we'll load the the environment variables dotenv . load_dotenv ( env_vars_fp ) user_key = os . environ . get ( 'USER_KEY' ) user_secret = os . environ . get ( 'USER_SECRET' ) slack_id = os . environ . get ( 'SLACK_ID' ) slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ) And test they were loaded successfully def check_env_vars_have_loaded ( env_vars ): for name , value in env_vars . items (): assert value is not None , f ' { name } ` should not be None' return env_vars = { 'user_key' : user_key , 'user_secret' : user_secret , 'slack_id' : slack_id , 'slack_webhook_url' : slack_webhook_url } check_env_vars_have_loaded ( env_vars ) We'll then use them to request an access token for the API We'll then use them to request an access token for the API access_token = request_access_token ( user_key , user_secret ) Querying Available Data \u00b6 Before we can download any data we have to know where it's stored. To learn this we can query their search-products API, which returns a JSON containing a list of file metadata. We'll quickly make a test request to this end-point start_date = '2019-10-01' end_date = '2019-10-07' r = query_data_products ( start_date , end_date ) r_json = r . json () JSON ( r_json ) However the search-api is capped (at 10,000) for the number of files it will return metadata for, so we'll create a while loop that waits until all the relevant data has been returned. We'll then extract just the list of features from the returned JSONs. We'll check that the same number of available datasets are identified %% time datasets = identify_available_datasets ( start_date , end_date ) print ( f ' { len ( datasets ) } datasets have been identified' ) Finally we'll create a helper function for converting the dataset ids into their file urls. We'll now test this works. N.b. You cannot use the link returned here directly as it will not be OAuth'ed dataset_ids = sorted ([ dataset [ 'id' ] for dataset in datasets ]) example_data_link = dataset_id_to_link ( dataset_ids [ 0 ]) example_data_link Downloading Data \u00b6 Now that we know where our data is located we want to download it. First we'll check that the directory we wish to save the data in exists, if not we'll create it for folder in [ data_dir , sorted_dir ]: if not os . path . exists ( folder ): os . makedirs ( folder ) We also want to extract the relevant metadata information from each file. Here we'll create a generalised framework for extracting data from any product, to add a new one please add its metadata mapping under the relevant product_id . We're now ready to create a download manager that will handle all of the querying, processing and retrieving for us We'll now see what it looks like when we initialise the download manager dm = DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp , slack_webhook_url = slack_webhook_url , slack_id = slack_id ) start_date = '2020-10-01 12:00' end_date = '2020-10-01 12:05' if download_data == True : dm . download_date_range ( start_date , end_date ) df_metadata = dm . get_df_metadata () df_metadata . head () The get_size function was adapted from this stackoverflow answer data_dir_size = get_dir_size ( data_dir ) print ( f 'The data directory is currently { round ( data_dir_size / 1_000_000_000 , 2 ) : , } Gb' ) Integration with Google Cloud Storage \u00b6 If Google Cloud Platform (GCP) flags are passed ( bucket_name and bucket_prefix ), when downloading, then the DownloadManager should first check to see if the files already exist in the specified cloud storage bucket. If the files already exist, then they will not be downloaded locally - if the storage bucket arguments are passed. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2020\" dm = DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp , bucket_name = BUCKET_NAME , bucket_prefix = PREFIX ) # Bucket filenames can be accessed len ( dm . bucket_filenames ) Lets test this by examining some dates at the start of 2020 # Timings: around 2 hours to download 1 day. # DownloadManager should find these 2020 files on the VM start_date = '2020-01-01 00:00' end_date = '2020-01-02 00:00' dm . download_date_range ( start_date , end_date ) Name Convention changes in EUMETSAT files \u00b6 Probably due to the changes / creation of the EUMETSAT API around the end of 2019, newer files do not contain the previous 'order number' parts at the end of the filename. Some previously downloaded files follow a different file name convention: Files through new API: MSG3-SEVI-MSG15-0100-NA-20191001120415.883000000Z-NA.nat SatProgram-Instrument-SatNumber-AlgoVersion-InstrumentMode(?)-ReceptionStartDateUTC Files on GCP: MSG3-SEVI-MSG15-0100-NA-20191001120415.883000000Z-20191001120433-1399526-1.nat.bz2 SatProgram-Instrument-SatNumber-AlgoVersion-InstrumentMode(?)-ReceptionStartDateUTC-SensingStartDateUTC-OrderNumber-PartNumber We can use regex to take the first part of the filename for comparisons txt = \"MSG3-SEVI-MSG15-0100-NA-20190101000417.314000000Z-20190101000435-1377854-1.nat\" re . match ( \"([A-Z\\d.]+-) {6} \" , txt )[ 0 ][: - 1 ] # [:-1] to trim the trailing - To ensure we are comparing the same filenames, this regex is added into DownloadManager and the GCP helpers. Set up logging locally. debug_fp = '../logs/EUMETSAT_download.txt' log = utils . set_up_logging ( 'EUMETSAT Processing' , debug_fp ) Helper utils \u00b6 For local testing, this command downloads some files from the Google Cloud bucket: # get test files from GCP - these are compressed # !gsutil cp -r gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/2019/10/01/00/04 ../data/raw Compress downloaded native image files \u00b6 Once files have been downloaded from the EUMETSAT API in some location, they need to be compressed and saved in a cloud storage bucket. First, see which files have already been downloaded locally to test this functionality. full_native_filenames = glob . glob ( os . path . join ( data_dir , '*.nat' )) full_native_filenames We will compress locally downloaded files here using pbzip2 On ubuntu: sudo apt-get install -y pbzip2 On mac: brew install pbzip2 compress_downloaded_files ( data_dir = data_dir , compressed_dir = compressed_dir ) Syncing files to GCP Storage \u00b6 Compressed native files should be stored in a Google Cloud Storage Bucket. The folder structure follows the following convention: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/<year>/<month>/<day>/<hour>/<minute>/ # sync downloaded files in compressed_dir to the bucket BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/\"","title":"Downloading"},{"location":"01_eumetsat/#eumetsat-api-wrapper-development","text":"","title":"EUMETSAT API Wrapper Development"},{"location":"01_eumetsat/#user-input","text":"data_dir = '../data/raw' compressed_dir = '../data/compressed' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' download_data = True","title":"User Input"},{"location":"01_eumetsat/#authorising-api-access","text":"First we'll load the the environment variables dotenv . load_dotenv ( env_vars_fp ) user_key = os . environ . get ( 'USER_KEY' ) user_secret = os . environ . get ( 'USER_SECRET' ) slack_id = os . environ . get ( 'SLACK_ID' ) slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ) And test they were loaded successfully def check_env_vars_have_loaded ( env_vars ): for name , value in env_vars . items (): assert value is not None , f ' { name } ` should not be None' return env_vars = { 'user_key' : user_key , 'user_secret' : user_secret , 'slack_id' : slack_id , 'slack_webhook_url' : slack_webhook_url } check_env_vars_have_loaded ( env_vars ) We'll then use them to request an access token for the API We'll then use them to request an access token for the API access_token = request_access_token ( user_key , user_secret )","title":"Authorising API Access"},{"location":"01_eumetsat/#querying-available-data","text":"Before we can download any data we have to know where it's stored. To learn this we can query their search-products API, which returns a JSON containing a list of file metadata. We'll quickly make a test request to this end-point start_date = '2019-10-01' end_date = '2019-10-07' r = query_data_products ( start_date , end_date ) r_json = r . json () JSON ( r_json ) However the search-api is capped (at 10,000) for the number of files it will return metadata for, so we'll create a while loop that waits until all the relevant data has been returned. We'll then extract just the list of features from the returned JSONs. We'll check that the same number of available datasets are identified %% time datasets = identify_available_datasets ( start_date , end_date ) print ( f ' { len ( datasets ) } datasets have been identified' ) Finally we'll create a helper function for converting the dataset ids into their file urls. We'll now test this works. N.b. You cannot use the link returned here directly as it will not be OAuth'ed dataset_ids = sorted ([ dataset [ 'id' ] for dataset in datasets ]) example_data_link = dataset_id_to_link ( dataset_ids [ 0 ]) example_data_link","title":"Querying Available Data"},{"location":"01_eumetsat/#downloading-data","text":"Now that we know where our data is located we want to download it. First we'll check that the directory we wish to save the data in exists, if not we'll create it for folder in [ data_dir , sorted_dir ]: if not os . path . exists ( folder ): os . makedirs ( folder ) We also want to extract the relevant metadata information from each file. Here we'll create a generalised framework for extracting data from any product, to add a new one please add its metadata mapping under the relevant product_id . We're now ready to create a download manager that will handle all of the querying, processing and retrieving for us We'll now see what it looks like when we initialise the download manager dm = DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp , slack_webhook_url = slack_webhook_url , slack_id = slack_id ) start_date = '2020-10-01 12:00' end_date = '2020-10-01 12:05' if download_data == True : dm . download_date_range ( start_date , end_date ) df_metadata = dm . get_df_metadata () df_metadata . head () The get_size function was adapted from this stackoverflow answer data_dir_size = get_dir_size ( data_dir ) print ( f 'The data directory is currently { round ( data_dir_size / 1_000_000_000 , 2 ) : , } Gb' )","title":"Downloading Data"},{"location":"01_eumetsat/#integration-with-google-cloud-storage","text":"If Google Cloud Platform (GCP) flags are passed ( bucket_name and bucket_prefix ), when downloading, then the DownloadManager should first check to see if the files already exist in the specified cloud storage bucket. If the files already exist, then they will not be downloaded locally - if the storage bucket arguments are passed. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2020\" dm = DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp , bucket_name = BUCKET_NAME , bucket_prefix = PREFIX ) # Bucket filenames can be accessed len ( dm . bucket_filenames ) Lets test this by examining some dates at the start of 2020 # Timings: around 2 hours to download 1 day. # DownloadManager should find these 2020 files on the VM start_date = '2020-01-01 00:00' end_date = '2020-01-02 00:00' dm . download_date_range ( start_date , end_date )","title":"Integration with Google Cloud Storage"},{"location":"01_eumetsat/#name-convention-changes-in-eumetsat-files","text":"Probably due to the changes / creation of the EUMETSAT API around the end of 2019, newer files do not contain the previous 'order number' parts at the end of the filename. Some previously downloaded files follow a different file name convention: Files through new API: MSG3-SEVI-MSG15-0100-NA-20191001120415.883000000Z-NA.nat SatProgram-Instrument-SatNumber-AlgoVersion-InstrumentMode(?)-ReceptionStartDateUTC Files on GCP: MSG3-SEVI-MSG15-0100-NA-20191001120415.883000000Z-20191001120433-1399526-1.nat.bz2 SatProgram-Instrument-SatNumber-AlgoVersion-InstrumentMode(?)-ReceptionStartDateUTC-SensingStartDateUTC-OrderNumber-PartNumber We can use regex to take the first part of the filename for comparisons txt = \"MSG3-SEVI-MSG15-0100-NA-20190101000417.314000000Z-20190101000435-1377854-1.nat\" re . match ( \"([A-Z\\d.]+-) {6} \" , txt )[ 0 ][: - 1 ] # [:-1] to trim the trailing - To ensure we are comparing the same filenames, this regex is added into DownloadManager and the GCP helpers. Set up logging locally. debug_fp = '../logs/EUMETSAT_download.txt' log = utils . set_up_logging ( 'EUMETSAT Processing' , debug_fp )","title":"Name Convention changes in EUMETSAT files"},{"location":"01_eumetsat/#helper-utils","text":"For local testing, this command downloads some files from the Google Cloud bucket: # get test files from GCP - these are compressed # !gsutil cp -r gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/2019/10/01/00/04 ../data/raw","title":"Helper utils"},{"location":"01_eumetsat/#compress-downloaded-native-image-files","text":"Once files have been downloaded from the EUMETSAT API in some location, they need to be compressed and saved in a cloud storage bucket. First, see which files have already been downloaded locally to test this functionality. full_native_filenames = glob . glob ( os . path . join ( data_dir , '*.nat' )) full_native_filenames We will compress locally downloaded files here using pbzip2 On ubuntu: sudo apt-get install -y pbzip2 On mac: brew install pbzip2 compress_downloaded_files ( data_dir = data_dir , compressed_dir = compressed_dir )","title":"Compress downloaded native image files"},{"location":"01_eumetsat/#syncing-files-to-gcp-storage","text":"Compressed native files should be stored in a Google Cloud Storage Bucket. The folder structure follows the following convention: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/native/<year>/<month>/<day>/<hour>/<minute>/ # sync downloaded files in compressed_dir to the bucket BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/\"","title":"Syncing files to GCP Storage"},{"location":"02_reproj/","text":"Data Transformation \u00b6 #exports import json import pandas as pd import xarray as xr import numpy as np import numpy.ma as ma import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import colors import seaborn as sns import os import time from itertools import product from collections import OrderedDict from datetime import datetime from ipypb import track import FEAutils as hlp import satpy from satpy import Scene from satpy.readers import seviri_l1b_native import pyresample from pyresample.geometry import AreaDefinition try : import pyinterp import pyinterp.backends.xarray except : pass We'll separately install libraries that wont be needed for the satip module import rasterio from rasterio import Affine as A from rasterio.warp import reproject , Resampling , calculate_default_transform , transform from rasterio.control import GroundControlPoint from rasterio.transform import xy import geopandas as gpd from shapely.geometry import Point import cartopy.crs as ccrs from IPython.display import JSON User Input \u00b6 data_dir = '../data/raw' intermediate_data_dir = '../data/intermediate' calculate_reproj_coords = False Exploratory Data Analysis \u00b6 We'll start by identifying the available files native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fps [ 0 ] '../data/raw/MSG2-SEVI-MSG15-0100-NA-20201208090415.301000000Z-NA.nat' Then load one of them in as a SatPy scene native_fp = native_fps [ 0 ] scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) scene <satpy.scene.Scene at 0x294fae42e50> We can get a list of the available datasets (bands) scene . all_dataset_names () ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] Each band contains an XArray DataArray scene . load ([ 'HRV' ]) scene [ 'HRV' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'reshape-3b944f9ca9a40a223ab6382d90bfb37d' (y: 4176, x: 5568)> dask.array<mul, shape=(4176, 5568), dtype=float32, chunksize=(1392, 5568), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unknown\",E... * y (y) float64 1.395e+06 1.396e+06 1.397e+06 ... 5.57e+06 5.571e+06 * x (x) float64 3.164e+06 3.163e+06 3.162e+06 ... -2.402e+06 -2.403e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9697642568677852 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-9 sensor: seviri start_time: 2020-12-08 09:00:08.206321 end_time: 2020-12-08 09:05:08.329479 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'reshape-3b944f9ca9a40a223ab6382d90bfb37d' y : 4176 x : 5568 dask.array<chunksize=(1392, 5568), meta=np.ndarray> Array Chunk Bytes 93.01 MB 31.00 MB Shape (4176, 5568) (1392, 5568) Count 214 Tasks 3 Chunks Type float32 numpy.ndarray 5568 4176 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Geostationary Satellite (Sweep Y) Datum: unknown - Ellipsoid: unknown - Prime Meridian: Greenwich , dtype=object) y (y) float64 1.395e+06 1.396e+06 ... 5.571e+06 units : meter array([1395187.416673, 1396187.551022, 1397187.68537 , ..., 5568748.054504, 5569748.188853, 5570748.323202]) x (x) float64 3.164e+06 3.163e+06 ... -2.403e+06 units : meter array([ 3164425.079823, 3163424.945474, 3162424.811125, ..., -2401322.571635, -2402322.705984, -2403322.840333]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We can see that the DataArray contains a crs, however we'll make our own custom area definition that's more accurate. First we'll create a helper function that will create our area definitions. #exports def calculate_x_offset ( native_fp ): handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) lower_east_column_planned = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] x_offset = 32500 + (( 2733 - lower_east_column_planned ) * 1000 ) return x_offset def get_seviri_area_def ( native_fp , num_x_pixels = 5568 , num_y_pixels = 4176 ) -> AreaDefinition : \"\"\" The HRV channel on Meteosat Second Generation satellites doesn't scan the full number of columns. The east boundary of the HRV channel changes (e.g. to maximise the amount of the image which is illuminated by sunlight. Parameters: native_fp: Data filepath \"\"\" x_offset = calculate_x_offset ( native_fp ) # The EUMETSAT docs say \"The distance between spacecraft and centre of earth is 42,164 km. The idealized earth # is a perfect ellipsoid with an equator radius of 6378.1690 km and a polar radius of 6356.5838 km.\" # The projection used by SatPy expresses height as height above the Earth's surface (not distance # to the centre of the Earth). projection = { 'proj' : 'geos' , 'lon_0' : 9.5 , 'a' : 6378169.0 , 'b' : 6356583.8 , 'h' : 35785831.00 , 'units' : 'm' } seviri = AreaDefinition ( area_id = 'seviri' , description = 'SEVIRI RSS HRV' , proj_id = 'seviri' , projection = projection , width = num_x_pixels , height = num_y_pixels , area_extent = [ - 2768872.0236 + x_offset , # left 1394687.3495 , # bottom (from scene['HRV'].area) 2799876.1893 + x_offset , # right 5570248.4773 ] # top (from scene['HRV'].area) ) return seviri Then we'll use it to construct the relevant one for Seviri seviri = get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () seviri_crs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2020-12-16T23:15:15.552296 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +a=6378169.0 +rf=295.488065897001 +h=35785831.0 +lon_0=9.5 +no_defs=True +proj=geos +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We'll create a loader function that will extract the relevant data for lower_east_column_planned automatically #exports def load_scene ( native_fp ): # Reading scene and loading HRV scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) # Identifying and recording lower_east_column_planned handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) scene . attrs [ 'lower_east_column_planned' ] = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] return scene We'll see how quickly this loads %% time scene = load_scene ( native_fp ) scene . load ([ 'HRV' ]) Wall time: 1.18 s C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() We can visualise what a specific band looks like fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c808e50> One of the benefits of having access to the underlying XArray object is that we can more easily start to do some analysis with the data, for example defining a reflectance threshold reflectance_threshold = 35 cmap = colors . ListedColormap ([ ( 0 , 0 , 0 , 0 ), # transparent ( 251 / 255 , 242 / 255 , 180 / 255 , 1 ) # yellow # (0.533, 0.808, 0.922, 1) # grey-like blue ]) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , vmin = 0 , vmax = 50 , cmap = 'magma' , add_colorbar = False ) ( scene [ 'HRV' ] > reflectance_threshold ) . plot . imshow ( ax = ax , cmap = cmap , add_colorbar = False ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c809f40> We'll extract the values from the XArray object, then mask all NaN values to enable us to carry out statistical analysis HRV = scene [ \"HRV\" ] . values HRV_masked = ma . masked_array ( HRV , mask = xr . ufuncs . isnan ( scene [ \"HRV\" ]) . values ) np . mean ( HRV_masked ) 12.372444717553362 We can also visualise the full distribution. N.b. to reduce the time it takes to calculate the best KDE fit we'll take only a sample of the data. HRV_sample = np . random . choice ( HRV_masked . flatten (), 1_000_000 ) # Plotting fig , ax = plt . subplots ( dpi = 250 ) sns . kdeplot ( HRV_sample , ax = ax , fill = True ) ax . set_yticks ([]) ax . set_ylabel ( '' ) ax . set_xlabel ( 'HRV Reflectance' ) hlp . hide_spines ( ax , positions = [ 'top' , 'left' , 'right' ]) Evaluating Reprojection to Tranverse Mercator \u00b6 Before we can resample we need to define the area we're resampling to, we'll write a constructor to help us do this #exports def construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , pixel_size = None ): # If None then will use same number of x and y points # HRV's resolution will be more like 4km for Europe if pixel_size is not None : width = int (( east - west ) / pixel_size ) height = int (( north - south ) / pixel_size ) else : width = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . x . values . shape [ 0 ] height = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . y . values . shape [ 0 ] area_extent = ( west , south , east , north ) area_def = AreaDefinition ( area_id , description , proj_id , projection , width , height , area_extent ) return area_def def construct_TM_area_def ( scene ): meters_per_pixel = 4000 west , south , east , north = ( - 3090000 , 1690000 , 4390000 , 9014000 ) area_id = 'TM' description = 'Transverse Mercator' proj_id = 'TM' projection = { 'ellps' : 'WGS84' , 'proj' : 'tmerc' , # Transverse Mercator 'units' : 'm' # meters } tm_area_def = construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , meters_per_pixel ) return tm_area_def tm_area_def = construct_TM_area_def ( scene ) tm_area_def . to_cartopy_crs () C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2020-12-16T23:15:54.380829 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +k=1.0 +lat_0=0.0 +lon_0=0.0 +no_defs=True +proj=tmerc +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We can now carry out the resampling using the pyresample library %% time resampled_scene = scene . resample ( tm_area_def , resampler = 'nearest' ) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:123: RuntimeWarning: invalid value encountered in true_divide self.cart /= np.sqrt(np.einsum('...i, ...i', self.cart, self.cart)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:178: RuntimeWarning: invalid value encountered in double_scalars return (val + mod) % (2 * mod) - mod C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) Wall time: 8.86 s We'll quickly check that the reprojection looks ok fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-20-ec0e500c536a>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948d7e00d0> We want to gain a deeper understanding of the reprojection that's being carried out, to do this we'll manually reproject a sample of the original gridded coordinates %% time orig_x_values = scene [ 'HRV' ] . x . values [:: 50 ] orig_y_values = scene [ 'HRV' ] . y . values [:: 50 ] XX , YY = np . meshgrid ( orig_x_values , orig_y_values ) df_proj_points = ( gpd . GeoSeries ([ Point ( x , y ) for x , y in np . stack ([ XX . flatten (), YY . flatten ()], axis = 1 ) ]) . set_crs ( crs = scene [ 'HRV' ] . area . crs_wkt ) . to_crs ( crs = resampled_scene [ 'HRV' ] . area . crs_wkt ) . apply ( lambda point : pd . Series ( list ( point . coords )[ 0 ])) . rename ( columns = { 0 : 'x_reproj' , 1 : 'y_reproj' }) . replace ( np . inf , np . nan ) . pipe ( lambda df : df . assign ( x_orig = XX . flatten ())) . pipe ( lambda df : df . assign ( y_orig = YY . flatten ())) ) df_proj_points . head () Wall time: 5.41 s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_reproj y_reproj x_orig y_orig 0 4.863405e+06 1.917787e+06 3.164425e+06 1.395187e+06 1 4.781323e+06 1.899419e+06 3.114418e+06 1.395187e+06 2 4.700620e+06 1.881746e+06 3.064412e+06 1.395187e+06 3 4.621232e+06 1.864731e+06 3.014405e+06 1.395187e+06 4 4.543102e+06 1.848341e+06 2.964398e+06 1.395187e+06 We can then visualise the reprojection of the original grid against the regridded reprojection %% time fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) ax . scatter ( df_proj_points [ 'x_reproj' ][:: 10 ], df_proj_points [ 'y_reproj' ][:: 10 ], s = 2 , color = 'red' ) <timed exec>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) Wall time: 27.8 s <matplotlib.collections.PathCollection at 0x294fb0be3a0> This is useful for quick visual inspection, for example we can see that the y axis gets stretched further the nearer to the pole. However, we want to get a better understanding of how the local cell resolution is changing for any given point, we'll begin by looking at this change for Greenwich. def lon_lat_to_new_crs ( lon , lat , crs ): x , y = list ( gpd . GeoSeries ([ Point ( lon , lat )]) . set_crs ( 4326 ) . to_crs ( crs ) . iloc [ 0 ] . coords )[ 0 ] return x , y def calc_res_change ( src_x , src_y , src_da , dst_da , src_dx = 10 , src_dy = 10 ): src_crs = src_da . area . crs_wkt dst_crs = dst_da . area . crs_wkt src_x_width = np . abs ( np . diff ( src_da . x . values )[ 0 ]) src_y_width = np . abs ( np . diff ( src_da . y . values )[ 0 ]) dst_x_width = np . abs ( np . diff ( dst_da . x . values )[ 0 ]) dst_y_width = np . abs ( np . diff ( dst_da . y . values )[ 0 ]) s_points = ( gpd . GeoSeries ([ Point ( src_x , src_y ), Point ( src_x + src_dx , src_y ), Point ( src_x , src_y + src_dy ) ]) . set_crs ( src_crs ) . to_crs ( dst_crs ) ) dst_dx = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) dst_dy = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) x_ratio_change = ( dst_dx / dst_x_width ) / ( src_dx / src_x_width ) y_ratio_change = ( dst_dy / dst_y_width ) / ( src_dy / src_y_width ) return x_ratio_change , y_ratio_change lon = 0 lat = 51.4934 src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) x_ratio_change , y_ratio_change = calc_res_change ( src_x , src_y , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) x_ratio_change , y_ratio_change (0.27381567467569573, 0.528776076616483) We'll double check this by calculating it through a different method, in this case by locating the nearest cell for each scene and comparing their sizes in a common coordinate system def get_da_nearest_cell_width_height ( da , x , y , units_crs ): nearest_loc = da . sel ( x = x , y = y , method = 'nearest' ) nearest_x = nearest_loc . x . values nearest_y = nearest_loc . y . values next_nearest_x = da . x . values [ list ( da . x . values ) . index ( nearest_x ) + 1 ] next_nearest_y = da . y . values [ list ( da . y . values ) . index ( nearest_y ) + 1 ] s_points = ( gpd . GeoSeries ([ Point ( nearest_x , nearest_y ), Point ( next_nearest_x , nearest_y ), Point ( nearest_x , next_nearest_y ) ]) . set_crs ( da . area . crs_wkt ) . to_crs ( units_crs ) ) x_width = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) y_height = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) return x_width , y_height src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , resampled_scene [ 'HRV' ] . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( resampled_scene [ 'HRV' ], dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) The width has changed from 1.09 km to 4.0 km The height has changed from 2.12 km to 4.0 km This can easily be converted into a x and y pixel size ratio change which almost exactly matches our previous calculation. The first calculation is more accurate as the dx and dy can approach 0 and get closer to the true ratio change, however the get_da_nearest_cell_width_height function is still useful as it allows us to determine the cell width and height in more interpretable units x_ratio_change , y_ratio_change = src_x_width / dst_x_width , src_y_height / dst_y_height x_ratio_change , y_ratio_change (0.2738180115545141, 0.5290020702784486) Iceland is stretched further still def print_pixel_change ( lon , lat , da_src , da_dst ): src_x , src_y = lon_lat_to_new_crs ( lon , lat , da_src . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , da_dst . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( da_src , src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( da_dst , dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) return lon = - 18.779208 lat = 64.887370 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.52 km to 3.99 km The height has changed from 4.75 km to 3.99 km And contrasts with Marrakesh which is stretched less than Greenwich in the y axis lon = - 8.005657 lat = 31.636355 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km We can check what the cell height and width are at the center of the image, they should both be close to 1km according to the SEVIRI documentation LineDirGridStep gives the grid step size in km SSP in the line direction. Default value is 3km for VIS and IR, and 1km for HRV. The on-ground grid step size of 3 km at the SSP represents an instrument scan step of 251.53 microrad divided by 3. - EUMETSAT round_m_to_km = lambda m : round ( m / 1000 , 2 ) UTM_35N_epsg = 32632 # should be relatively accurate and is in meters src_x = np . median ( scene [ 'HRV' ] . x . values ) src_y = np . median ( scene [ 'HRV' ] . y . values ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , UTM_35N_epsg ) round_m_to_km ( src_x_width ), round_m_to_km ( src_y_height ) (1.04, 1.36) Comparing Reprojection Libraries \u00b6 In the last section we used pyresample to carry out the data reprojection, here we'll explore pyinterp . Before we start we'll quickly extract the xarrays for the original and reprojected coordinates. def extract_formatted_scene ( scene , variable = 'HRV' , x_coords_name = 'x' , y_coords_name = 'y' , x_units = 'metre' , y_units = 'metre' ): da = ( scene [ variable ] . copy () . rename ({ 'x' : x_coords_name , 'y' : y_coords_name }) ) da [ x_coords_name ] . attrs [ 'units' ] = x_units da [ y_coords_name ] . attrs [ 'units' ] = y_units return da da = extract_formatted_scene ( scene ) da_resampled = extract_formatted_scene ( resampled_scene ) da_resampled /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'my_index-25c95e08ed138cbd282b6596ed55c066' (y: 1831, x: 1870)> dask.array<copy, shape=(1831, 1870), dtype=float32, chunksize=(1831, 1870), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unknown ba... * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 -3.08e+06 ... 4.384e+06 4.388e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9697642568677852 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-9 sensor: seviri start_time: 2020-12-08 09:00:08.206321 end_time: 2020-12-08 09:05:08.329479 area: Area ID: TM\\nDescription: Transve... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'my_index-25c95e08ed138cbd282b6596ed55c066' y : 1831 x : 1870 dask.array<chunksize=(1831, 1870), meta=np.ndarray> Array Chunk Bytes 13.70 MB 13.70 MB Shape (1831, 1870) (1831, 1870) Count 360 Tasks 1 Chunks Type float32 numpy.ndarray 1870 1831 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Transverse Mercator Datum: Unknown based on WGS84 ellipsoid - Ellipsoid: WGS 84 - Prime Meridian: Greenwich , dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 units : metre array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 units : metre array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: TM Description: Transverse Mercator Projection ID: TM Projection: {'ellps': 'WGS84', 'k': '1', 'lat_0': '0', 'lon_0': '0', 'no_defs': 'None', 'proj': 'tmerc', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 1870 Number of rows: 1831 Area extent: (-3090000, 1690000, 4390000, 9014000) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We'll now save the coordinates of the grid we're using in the new projection new_grid_4km_TM = { 'x_coords' : list ( da_resampled . x . values ), 'y_coords' : list ( da_resampled . y . values ) } save_data = True if save_data == True : with open ( '../data/intermediate/new_grid_4km_TM.json' , 'w' ) as fp : json . dump ( new_grid_4km_TM , fp ) JSON ( new_grid_4km_TM ) <IPython.core.display.JSON object> As well as calculate the locations of those points in the original CRS %% time def chunks ( list_ , n ): \"\"\" Yield successive n-sized chunks from `list_`. \"\"\" for i in range ( 0 , len ( list_ ), n ): yield list_ [ i : i + n ] def reproject_geometries ( da , old_crs , new_crs , chunk_size = 5000 ): xx , yy = np . meshgrid ( da . x . values , da . y . values , indexing = 'ij' ) geometry = gpd . points_from_xy ( xx . flatten (), yy . flatten ()) new_coords_samples = [] for geometry_sample in chunks ( geometry , chunk_size ): df_new_coords_sample = ( gpd . GeoSeries ( geometry_sample , crs = old_crs ) . to_crs ( new_crs ) . apply ( lambda x : list ( x . coords [ 0 ])) . apply ( pd . Series ) . rename ( columns = { 0 : 'x' , 1 : 'y' }) ) new_coords_samples += [ df_new_coords_sample ] df_new_coords = pd . concat ( new_coords_samples , ignore_index = True ) return df_new_coords if not os . path . exists ( intermediate_data_dir ): os . makedirs ( intermediate_data_dir ) if calculate_reproj_coords == True : df_new_coords = reproject_geometries ( da_resampled , '+proj=tmerc' , seviri_crs . proj4_init ) df_new_coords . to_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' , index = False ) elif 'reproj_coords.csv' not in os . listdir ( intermediate_data_dir ): df_new_coords = pd . read_csv ( 'https://storage.googleapis.com/reprojection_cache/reproj_coords_TM_4km.csv' ) else : df_new_coords = pd . read_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' ) df_new_coords . head () Wall time: 3.36 s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y 0 inf inf 1 inf inf 2 inf inf 3 inf inf 4 inf inf We can layer these on top of each other to get an alternative view of the transform operation %% time old_x_positions , old_y_positions = [ elem . flatten () for elem in np . meshgrid ( da . x . values [:: 100 ], da . y . values [:: 100 ], indexing = 'ij' )] new_x_positions , new_y_positions = df_new_coords [ 'x' ][:: 100 ], df_new_coords [ 'y' ][:: 100 ] # Plotting fig , ax = plt . subplots ( dpi = 150 ) ax . scatter ( old_x_positions , old_y_positions , s = 0.1 ) ax . scatter ( new_x_positions , new_y_positions , s = 0.1 ) hlp . hide_spines ( ax ) Wall time: 98.8 ms We'll now use pyinterp to take these and use them to carry out the resampling. We'll also create a wrapper for converting the result back into an Xarray object. #exports def reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ): x_axis = pyinterp . Axis ( da . x . values ) y_axis = pyinterp . Axis ( da . y . values ) grid = pyinterp . Grid2D ( x_axis , y_axis , da . data . T ) reproj_data = ( pyinterp . bivariate ( grid , x_coords , y_coords ) . reshape (( len ( new_grid [ 'x_coords' ]), len ( new_grid [ 'y_coords' ]))) ) return reproj_data def reproj_to_xarray ( da , x_coords , y_coords , new_grid ): # We'll reproject the data reproj_data = reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ) # Then put it in an XArray DataArray da_reproj = xr . DataArray ( np . flip ( reproj_data . T , axis = ( 0 , 1 )), dims = ( 'y' , 'x' ), coords = { 'x' : new_grid [ 'x_coords' ][:: - 1 ], 'y' : new_grid [ 'y_coords' ][:: - 1 ] }, attrs = da . attrs ) return da_reproj We'll load the grid back in with open ( '../data/intermediate/new_grid_4km_TM.json' , 'r' ) as fp : new_grid = json . load ( fp ) JSON ( new_grid ) <IPython.core.display.JSON object> Confirm that the size of the grid definition arrays match the number of coordinates we have df_new_coords [ 'y' ] . size == len ( new_grid [ 'x_coords' ]) * len ( new_grid [ 'y_coords' ]) True And finally carry out the reprojection %% timeit da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) 1.78 s \u00c2\u00b1 239 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) Most importantly we'll carry out a visual check that the reprojection was carried out properly. da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_reproj . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-37-c765a7c3ab68>:5: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c866b50> #exports def full_scene_pyresample ( native_fp ): # Loading scene scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) # Constructing target area definition tm_area_def = construct_TM_area_def ( scene ) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da = scene [ dataset_name ] . sortby ( 'y' , ascending = False ) . sortby ( 'x' ) num_y_pixels , num_x_pixels = da . shape seviri_area_def = get_seviri_area_def ( native_fp , num_x_pixels = num_x_pixels , num_y_pixels = num_y_pixels ) resampler = satpy . resample . KDTreeResampler ( seviri_area_def , tm_area_def ) da_reproj = resampler . resample ( da ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = ( xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) . drop ( labels = 'crs' ) ) return ds_reproj def full_scene_pyinterp ( native_fp , new_x_coords , new_y_coords , new_grid_fp ): # Loading data scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) with open ( new_grid_fp , 'r' ) as fp : new_grid = json . load ( fp ) # Correcting x coordinates seviri_area_def = get_seviri_area_def ( native_fp ) area_extent = seviri_area_def . area_extent x_offset = calculate_x_offset ( native_fp ) width = scene [ 'HRV' ] . x . size corrected_x_coords = np . linspace ( area_extent [ 2 ], area_extent [ 0 ], width ) scene [ 'HRV' ] = scene [ 'HRV' ] . assign_coords ({ 'x' : corrected_x_coords }) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da_reproj = reproj_to_xarray ( scene [ dataset_name ], new_x_coords , new_y_coords , new_grid ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) return ds_reproj class Reprojector : def __init__ ( self , new_coords_fp = None , new_grid_fp = None ): if new_coords_fp is None and new_grid_fp is None : return df_new_coords = pd . read_csv ( new_coords_fp ) self . new_x_coords = df_new_coords [ 'x' ] self . new_y_coords = df_new_coords [ 'y' ] self . new_grid_fp = new_grid_fp return def reproject ( self , native_fp , reproj_library = 'pyresample' ): if reproj_library == 'pyinterp' : ds_reproj = full_scene_pyinterp ( native_fp , self . new_x_coords , self . new_y_coords , self . new_grid_fp ) elif reproj_library == 'pyresample' : ds_reproj = full_scene_pyresample ( native_fp ) else : raise ValueError ( f '`reproj_library` must be one of: pyresample, pyinterp. { reproj_library } can not be passed.' ) return ds_reproj %% capture -- no - stdout %% timeit new_coords_fp = f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) 15.9 s \u00c2\u00b1 2.24 s per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout %% timeit reprojector = Reprojector () ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) 9.24 s \u00c2\u00b1 1.18 s per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout ds_reproj = reprojector . reproject ( native_fp ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-41-4aa2b08f07bf> in <module> ----> 1 ds_reproj = reprojector.reproject(native_fp) 2 3 # Plotting 4 fig = plt.figure(dpi=250, figsize=(10, 10)) 5 ax = plt.axes(projection=ccrs.TransverseMercator()) NameError: name 'reprojector' is not defined","title":"Reprojection"},{"location":"02_reproj/#data-transformation","text":"#exports import json import pandas as pd import xarray as xr import numpy as np import numpy.ma as ma import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import colors import seaborn as sns import os import time from itertools import product from collections import OrderedDict from datetime import datetime from ipypb import track import FEAutils as hlp import satpy from satpy import Scene from satpy.readers import seviri_l1b_native import pyresample from pyresample.geometry import AreaDefinition try : import pyinterp import pyinterp.backends.xarray except : pass We'll separately install libraries that wont be needed for the satip module import rasterio from rasterio import Affine as A from rasterio.warp import reproject , Resampling , calculate_default_transform , transform from rasterio.control import GroundControlPoint from rasterio.transform import xy import geopandas as gpd from shapely.geometry import Point import cartopy.crs as ccrs from IPython.display import JSON","title":"Data Transformation"},{"location":"02_reproj/#user-input","text":"data_dir = '../data/raw' intermediate_data_dir = '../data/intermediate' calculate_reproj_coords = False","title":"User Input"},{"location":"02_reproj/#exploratory-data-analysis","text":"We'll start by identifying the available files native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fps [ 0 ] '../data/raw/MSG2-SEVI-MSG15-0100-NA-20201208090415.301000000Z-NA.nat' Then load one of them in as a SatPy scene native_fp = native_fps [ 0 ] scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) scene <satpy.scene.Scene at 0x294fae42e50> We can get a list of the available datasets (bands) scene . all_dataset_names () ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] Each band contains an XArray DataArray scene . load ([ 'HRV' ]) scene [ 'HRV' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'reshape-3b944f9ca9a40a223ab6382d90bfb37d' (y: 4176, x: 5568)> dask.array<mul, shape=(4176, 5568), dtype=float32, chunksize=(1392, 5568), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unknown\",E... * y (y) float64 1.395e+06 1.396e+06 1.397e+06 ... 5.57e+06 5.571e+06 * x (x) float64 3.164e+06 3.163e+06 3.162e+06 ... -2.402e+06 -2.403e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9697642568677852 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-9 sensor: seviri start_time: 2020-12-08 09:00:08.206321 end_time: 2020-12-08 09:05:08.329479 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'reshape-3b944f9ca9a40a223ab6382d90bfb37d' y : 4176 x : 5568 dask.array<chunksize=(1392, 5568), meta=np.ndarray> Array Chunk Bytes 93.01 MB 31.00 MB Shape (4176, 5568) (1392, 5568) Count 214 Tasks 3 Chunks Type float32 numpy.ndarray 5568 4176 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Geostationary Satellite (Sweep Y) Datum: unknown - Ellipsoid: unknown - Prime Meridian: Greenwich , dtype=object) y (y) float64 1.395e+06 1.396e+06 ... 5.571e+06 units : meter array([1395187.416673, 1396187.551022, 1397187.68537 , ..., 5568748.054504, 5569748.188853, 5570748.323202]) x (x) float64 3.164e+06 3.163e+06 ... -2.403e+06 units : meter array([ 3164425.079823, 3163424.945474, 3162424.811125, ..., -2401322.571635, -2402322.705984, -2403322.840333]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We can see that the DataArray contains a crs, however we'll make our own custom area definition that's more accurate. First we'll create a helper function that will create our area definitions. #exports def calculate_x_offset ( native_fp ): handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) lower_east_column_planned = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] x_offset = 32500 + (( 2733 - lower_east_column_planned ) * 1000 ) return x_offset def get_seviri_area_def ( native_fp , num_x_pixels = 5568 , num_y_pixels = 4176 ) -> AreaDefinition : \"\"\" The HRV channel on Meteosat Second Generation satellites doesn't scan the full number of columns. The east boundary of the HRV channel changes (e.g. to maximise the amount of the image which is illuminated by sunlight. Parameters: native_fp: Data filepath \"\"\" x_offset = calculate_x_offset ( native_fp ) # The EUMETSAT docs say \"The distance between spacecraft and centre of earth is 42,164 km. The idealized earth # is a perfect ellipsoid with an equator radius of 6378.1690 km and a polar radius of 6356.5838 km.\" # The projection used by SatPy expresses height as height above the Earth's surface (not distance # to the centre of the Earth). projection = { 'proj' : 'geos' , 'lon_0' : 9.5 , 'a' : 6378169.0 , 'b' : 6356583.8 , 'h' : 35785831.00 , 'units' : 'm' } seviri = AreaDefinition ( area_id = 'seviri' , description = 'SEVIRI RSS HRV' , proj_id = 'seviri' , projection = projection , width = num_x_pixels , height = num_y_pixels , area_extent = [ - 2768872.0236 + x_offset , # left 1394687.3495 , # bottom (from scene['HRV'].area) 2799876.1893 + x_offset , # right 5570248.4773 ] # top (from scene['HRV'].area) ) return seviri Then we'll use it to construct the relevant one for Seviri seviri = get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () seviri_crs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2020-12-16T23:15:15.552296 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +a=6378169.0 +rf=295.488065897001 +h=35785831.0 +lon_0=9.5 +no_defs=True +proj=geos +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We'll create a loader function that will extract the relevant data for lower_east_column_planned automatically #exports def load_scene ( native_fp ): # Reading scene and loading HRV scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) # Identifying and recording lower_east_column_planned handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) scene . attrs [ 'lower_east_column_planned' ] = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] return scene We'll see how quickly this loads %% time scene = load_scene ( native_fp ) scene . load ([ 'HRV' ]) Wall time: 1.18 s C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() We can visualise what a specific band looks like fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c808e50> One of the benefits of having access to the underlying XArray object is that we can more easily start to do some analysis with the data, for example defining a reflectance threshold reflectance_threshold = 35 cmap = colors . ListedColormap ([ ( 0 , 0 , 0 , 0 ), # transparent ( 251 / 255 , 242 / 255 , 180 / 255 , 1 ) # yellow # (0.533, 0.808, 0.922, 1) # grey-like blue ]) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , vmin = 0 , vmax = 50 , cmap = 'magma' , add_colorbar = False ) ( scene [ 'HRV' ] > reflectance_threshold ) . plot . imshow ( ax = ax , cmap = cmap , add_colorbar = False ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c809f40> We'll extract the values from the XArray object, then mask all NaN values to enable us to carry out statistical analysis HRV = scene [ \"HRV\" ] . values HRV_masked = ma . masked_array ( HRV , mask = xr . ufuncs . isnan ( scene [ \"HRV\" ]) . values ) np . mean ( HRV_masked ) 12.372444717553362 We can also visualise the full distribution. N.b. to reduce the time it takes to calculate the best KDE fit we'll take only a sample of the data. HRV_sample = np . random . choice ( HRV_masked . flatten (), 1_000_000 ) # Plotting fig , ax = plt . subplots ( dpi = 250 ) sns . kdeplot ( HRV_sample , ax = ax , fill = True ) ax . set_yticks ([]) ax . set_ylabel ( '' ) ax . set_xlabel ( 'HRV Reflectance' ) hlp . hide_spines ( ax , positions = [ 'top' , 'left' , 'right' ])","title":"Exploratory Data Analysis"},{"location":"02_reproj/#evaluating-reprojection-to-tranverse-mercator","text":"Before we can resample we need to define the area we're resampling to, we'll write a constructor to help us do this #exports def construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , pixel_size = None ): # If None then will use same number of x and y points # HRV's resolution will be more like 4km for Europe if pixel_size is not None : width = int (( east - west ) / pixel_size ) height = int (( north - south ) / pixel_size ) else : width = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . x . values . shape [ 0 ] height = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . y . values . shape [ 0 ] area_extent = ( west , south , east , north ) area_def = AreaDefinition ( area_id , description , proj_id , projection , width , height , area_extent ) return area_def def construct_TM_area_def ( scene ): meters_per_pixel = 4000 west , south , east , north = ( - 3090000 , 1690000 , 4390000 , 9014000 ) area_id = 'TM' description = 'Transverse Mercator' proj_id = 'TM' projection = { 'ellps' : 'WGS84' , 'proj' : 'tmerc' , # Transverse Mercator 'units' : 'm' # meters } tm_area_def = construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , meters_per_pixel ) return tm_area_def tm_area_def = construct_TM_area_def ( scene ) tm_area_def . to_cartopy_crs () C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() 2020-12-16T23:15:54.380829 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +k=1.0 +lat_0=0.0 +lon_0=0.0 +no_defs=True +proj=tmerc +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We can now carry out the resampling using the pyresample library %% time resampled_scene = scene . resample ( tm_area_def , resampler = 'nearest' ) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:123: RuntimeWarning: invalid value encountered in true_divide self.cart /= np.sqrt(np.einsum('...i, ...i', self.cart, self.cart)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyresample\\spherical.py:178: RuntimeWarning: invalid value encountered in double_scalars return (val + mod) % (2 * mod) - mod C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) Wall time: 8.86 s We'll quickly check that the reprojection looks ok fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-20-ec0e500c536a>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948d7e00d0> We want to gain a deeper understanding of the reprojection that's being carried out, to do this we'll manually reproject a sample of the original gridded coordinates %% time orig_x_values = scene [ 'HRV' ] . x . values [:: 50 ] orig_y_values = scene [ 'HRV' ] . y . values [:: 50 ] XX , YY = np . meshgrid ( orig_x_values , orig_y_values ) df_proj_points = ( gpd . GeoSeries ([ Point ( x , y ) for x , y in np . stack ([ XX . flatten (), YY . flatten ()], axis = 1 ) ]) . set_crs ( crs = scene [ 'HRV' ] . area . crs_wkt ) . to_crs ( crs = resampled_scene [ 'HRV' ] . area . crs_wkt ) . apply ( lambda point : pd . Series ( list ( point . coords )[ 0 ])) . rename ( columns = { 0 : 'x_reproj' , 1 : 'y_reproj' }) . replace ( np . inf , np . nan ) . pipe ( lambda df : df . assign ( x_orig = XX . flatten ())) . pipe ( lambda df : df . assign ( y_orig = YY . flatten ())) ) df_proj_points . head () Wall time: 5.41 s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_reproj y_reproj x_orig y_orig 0 4.863405e+06 1.917787e+06 3.164425e+06 1.395187e+06 1 4.781323e+06 1.899419e+06 3.114418e+06 1.395187e+06 2 4.700620e+06 1.881746e+06 3.064412e+06 1.395187e+06 3 4.621232e+06 1.864731e+06 3.014405e+06 1.395187e+06 4 4.543102e+06 1.848341e+06 2.964398e+06 1.395187e+06 We can then visualise the reprojection of the original grid against the regridded reprojection %% time fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) ax . scatter ( df_proj_points [ 'x_reproj' ][:: 10 ], df_proj_points [ 'y_reproj' ][:: 10 ], s = 2 , color = 'red' ) <timed exec>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dask\\core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) Wall time: 27.8 s <matplotlib.collections.PathCollection at 0x294fb0be3a0> This is useful for quick visual inspection, for example we can see that the y axis gets stretched further the nearer to the pole. However, we want to get a better understanding of how the local cell resolution is changing for any given point, we'll begin by looking at this change for Greenwich. def lon_lat_to_new_crs ( lon , lat , crs ): x , y = list ( gpd . GeoSeries ([ Point ( lon , lat )]) . set_crs ( 4326 ) . to_crs ( crs ) . iloc [ 0 ] . coords )[ 0 ] return x , y def calc_res_change ( src_x , src_y , src_da , dst_da , src_dx = 10 , src_dy = 10 ): src_crs = src_da . area . crs_wkt dst_crs = dst_da . area . crs_wkt src_x_width = np . abs ( np . diff ( src_da . x . values )[ 0 ]) src_y_width = np . abs ( np . diff ( src_da . y . values )[ 0 ]) dst_x_width = np . abs ( np . diff ( dst_da . x . values )[ 0 ]) dst_y_width = np . abs ( np . diff ( dst_da . y . values )[ 0 ]) s_points = ( gpd . GeoSeries ([ Point ( src_x , src_y ), Point ( src_x + src_dx , src_y ), Point ( src_x , src_y + src_dy ) ]) . set_crs ( src_crs ) . to_crs ( dst_crs ) ) dst_dx = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) dst_dy = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) x_ratio_change = ( dst_dx / dst_x_width ) / ( src_dx / src_x_width ) y_ratio_change = ( dst_dy / dst_y_width ) / ( src_dy / src_y_width ) return x_ratio_change , y_ratio_change lon = 0 lat = 51.4934 src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) x_ratio_change , y_ratio_change = calc_res_change ( src_x , src_y , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) x_ratio_change , y_ratio_change (0.27381567467569573, 0.528776076616483) We'll double check this by calculating it through a different method, in this case by locating the nearest cell for each scene and comparing their sizes in a common coordinate system def get_da_nearest_cell_width_height ( da , x , y , units_crs ): nearest_loc = da . sel ( x = x , y = y , method = 'nearest' ) nearest_x = nearest_loc . x . values nearest_y = nearest_loc . y . values next_nearest_x = da . x . values [ list ( da . x . values ) . index ( nearest_x ) + 1 ] next_nearest_y = da . y . values [ list ( da . y . values ) . index ( nearest_y ) + 1 ] s_points = ( gpd . GeoSeries ([ Point ( nearest_x , nearest_y ), Point ( next_nearest_x , nearest_y ), Point ( nearest_x , next_nearest_y ) ]) . set_crs ( da . area . crs_wkt ) . to_crs ( units_crs ) ) x_width = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) y_height = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) return x_width , y_height src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , resampled_scene [ 'HRV' ] . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( resampled_scene [ 'HRV' ], dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) The width has changed from 1.09 km to 4.0 km The height has changed from 2.12 km to 4.0 km This can easily be converted into a x and y pixel size ratio change which almost exactly matches our previous calculation. The first calculation is more accurate as the dx and dy can approach 0 and get closer to the true ratio change, however the get_da_nearest_cell_width_height function is still useful as it allows us to determine the cell width and height in more interpretable units x_ratio_change , y_ratio_change = src_x_width / dst_x_width , src_y_height / dst_y_height x_ratio_change , y_ratio_change (0.2738180115545141, 0.5290020702784486) Iceland is stretched further still def print_pixel_change ( lon , lat , da_src , da_dst ): src_x , src_y = lon_lat_to_new_crs ( lon , lat , da_src . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , da_dst . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( da_src , src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( da_dst , dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) return lon = - 18.779208 lat = 64.887370 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.52 km to 3.99 km The height has changed from 4.75 km to 3.99 km And contrasts with Marrakesh which is stretched less than Greenwich in the y axis lon = - 8.005657 lat = 31.636355 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km We can check what the cell height and width are at the center of the image, they should both be close to 1km according to the SEVIRI documentation LineDirGridStep gives the grid step size in km SSP in the line direction. Default value is 3km for VIS and IR, and 1km for HRV. The on-ground grid step size of 3 km at the SSP represents an instrument scan step of 251.53 microrad divided by 3. - EUMETSAT round_m_to_km = lambda m : round ( m / 1000 , 2 ) UTM_35N_epsg = 32632 # should be relatively accurate and is in meters src_x = np . median ( scene [ 'HRV' ] . x . values ) src_y = np . median ( scene [ 'HRV' ] . y . values ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , UTM_35N_epsg ) round_m_to_km ( src_x_width ), round_m_to_km ( src_y_height ) (1.04, 1.36)","title":"Evaluating Reprojection to Tranverse Mercator"},{"location":"02_reproj/#comparing-reprojection-libraries","text":"In the last section we used pyresample to carry out the data reprojection, here we'll explore pyinterp . Before we start we'll quickly extract the xarrays for the original and reprojected coordinates. def extract_formatted_scene ( scene , variable = 'HRV' , x_coords_name = 'x' , y_coords_name = 'y' , x_units = 'metre' , y_units = 'metre' ): da = ( scene [ variable ] . copy () . rename ({ 'x' : x_coords_name , 'y' : y_coords_name }) ) da [ x_coords_name ] . attrs [ 'units' ] = x_units da [ y_coords_name ] . attrs [ 'units' ] = y_units return da da = extract_formatted_scene ( scene ) da_resampled = extract_formatted_scene ( resampled_scene ) da_resampled /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'my_index-25c95e08ed138cbd282b6596ed55c066' (y: 1831, x: 1870)> dask.array<copy, shape=(1831, 1870), dtype=float32, chunksize=(1831, 1870), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unknown ba... * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 -3.08e+06 ... 4.384e+06 4.388e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9697642568677852 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-9 sensor: seviri start_time: 2020-12-08 09:00:08.206321 end_time: 2020-12-08 09:05:08.329479 area: Area ID: TM\\nDescription: Transve... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'my_index-25c95e08ed138cbd282b6596ed55c066' y : 1831 x : 1870 dask.array<chunksize=(1831, 1870), meta=np.ndarray> Array Chunk Bytes 13.70 MB 13.70 MB Shape (1831, 1870) (1831, 1870) Count 360 Tasks 1 Chunks Type float32 numpy.ndarray 1870 1831 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Transverse Mercator Datum: Unknown based on WGS84 ellipsoid - Ellipsoid: WGS 84 - Prime Meridian: Greenwich , dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 units : metre array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 units : metre array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: TM Description: Transverse Mercator Projection ID: TM Projection: {'ellps': 'WGS84', 'k': '1', 'lat_0': '0', 'lon_0': '0', 'no_defs': 'None', 'proj': 'tmerc', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 1870 Number of rows: 1831 Area extent: (-3090000, 1690000, 4390000, 9014000) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We'll now save the coordinates of the grid we're using in the new projection new_grid_4km_TM = { 'x_coords' : list ( da_resampled . x . values ), 'y_coords' : list ( da_resampled . y . values ) } save_data = True if save_data == True : with open ( '../data/intermediate/new_grid_4km_TM.json' , 'w' ) as fp : json . dump ( new_grid_4km_TM , fp ) JSON ( new_grid_4km_TM ) <IPython.core.display.JSON object> As well as calculate the locations of those points in the original CRS %% time def chunks ( list_ , n ): \"\"\" Yield successive n-sized chunks from `list_`. \"\"\" for i in range ( 0 , len ( list_ ), n ): yield list_ [ i : i + n ] def reproject_geometries ( da , old_crs , new_crs , chunk_size = 5000 ): xx , yy = np . meshgrid ( da . x . values , da . y . values , indexing = 'ij' ) geometry = gpd . points_from_xy ( xx . flatten (), yy . flatten ()) new_coords_samples = [] for geometry_sample in chunks ( geometry , chunk_size ): df_new_coords_sample = ( gpd . GeoSeries ( geometry_sample , crs = old_crs ) . to_crs ( new_crs ) . apply ( lambda x : list ( x . coords [ 0 ])) . apply ( pd . Series ) . rename ( columns = { 0 : 'x' , 1 : 'y' }) ) new_coords_samples += [ df_new_coords_sample ] df_new_coords = pd . concat ( new_coords_samples , ignore_index = True ) return df_new_coords if not os . path . exists ( intermediate_data_dir ): os . makedirs ( intermediate_data_dir ) if calculate_reproj_coords == True : df_new_coords = reproject_geometries ( da_resampled , '+proj=tmerc' , seviri_crs . proj4_init ) df_new_coords . to_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' , index = False ) elif 'reproj_coords.csv' not in os . listdir ( intermediate_data_dir ): df_new_coords = pd . read_csv ( 'https://storage.googleapis.com/reprojection_cache/reproj_coords_TM_4km.csv' ) else : df_new_coords = pd . read_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' ) df_new_coords . head () Wall time: 3.36 s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y 0 inf inf 1 inf inf 2 inf inf 3 inf inf 4 inf inf We can layer these on top of each other to get an alternative view of the transform operation %% time old_x_positions , old_y_positions = [ elem . flatten () for elem in np . meshgrid ( da . x . values [:: 100 ], da . y . values [:: 100 ], indexing = 'ij' )] new_x_positions , new_y_positions = df_new_coords [ 'x' ][:: 100 ], df_new_coords [ 'y' ][:: 100 ] # Plotting fig , ax = plt . subplots ( dpi = 150 ) ax . scatter ( old_x_positions , old_y_positions , s = 0.1 ) ax . scatter ( new_x_positions , new_y_positions , s = 0.1 ) hlp . hide_spines ( ax ) Wall time: 98.8 ms We'll now use pyinterp to take these and use them to carry out the resampling. We'll also create a wrapper for converting the result back into an Xarray object. #exports def reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ): x_axis = pyinterp . Axis ( da . x . values ) y_axis = pyinterp . Axis ( da . y . values ) grid = pyinterp . Grid2D ( x_axis , y_axis , da . data . T ) reproj_data = ( pyinterp . bivariate ( grid , x_coords , y_coords ) . reshape (( len ( new_grid [ 'x_coords' ]), len ( new_grid [ 'y_coords' ]))) ) return reproj_data def reproj_to_xarray ( da , x_coords , y_coords , new_grid ): # We'll reproject the data reproj_data = reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ) # Then put it in an XArray DataArray da_reproj = xr . DataArray ( np . flip ( reproj_data . T , axis = ( 0 , 1 )), dims = ( 'y' , 'x' ), coords = { 'x' : new_grid [ 'x_coords' ][:: - 1 ], 'y' : new_grid [ 'y_coords' ][:: - 1 ] }, attrs = da . attrs ) return da_reproj We'll load the grid back in with open ( '../data/intermediate/new_grid_4km_TM.json' , 'r' ) as fp : new_grid = json . load ( fp ) JSON ( new_grid ) <IPython.core.display.JSON object> Confirm that the size of the grid definition arrays match the number of coordinates we have df_new_coords [ 'y' ] . size == len ( new_grid [ 'x_coords' ]) * len ( new_grid [ 'y_coords' ]) True And finally carry out the reprojection %% timeit da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) 1.78 s \u00c2\u00b1 239 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) Most importantly we'll carry out a visual check that the reprojection was carried out properly. da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_reproj . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-37-c765a7c3ab68>:5: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x2948c866b50> #exports def full_scene_pyresample ( native_fp ): # Loading scene scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) # Constructing target area definition tm_area_def = construct_TM_area_def ( scene ) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da = scene [ dataset_name ] . sortby ( 'y' , ascending = False ) . sortby ( 'x' ) num_y_pixels , num_x_pixels = da . shape seviri_area_def = get_seviri_area_def ( native_fp , num_x_pixels = num_x_pixels , num_y_pixels = num_y_pixels ) resampler = satpy . resample . KDTreeResampler ( seviri_area_def , tm_area_def ) da_reproj = resampler . resample ( da ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = ( xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) . drop ( labels = 'crs' ) ) return ds_reproj def full_scene_pyinterp ( native_fp , new_x_coords , new_y_coords , new_grid_fp ): # Loading data scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) with open ( new_grid_fp , 'r' ) as fp : new_grid = json . load ( fp ) # Correcting x coordinates seviri_area_def = get_seviri_area_def ( native_fp ) area_extent = seviri_area_def . area_extent x_offset = calculate_x_offset ( native_fp ) width = scene [ 'HRV' ] . x . size corrected_x_coords = np . linspace ( area_extent [ 2 ], area_extent [ 0 ], width ) scene [ 'HRV' ] = scene [ 'HRV' ] . assign_coords ({ 'x' : corrected_x_coords }) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da_reproj = reproj_to_xarray ( scene [ dataset_name ], new_x_coords , new_y_coords , new_grid ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) return ds_reproj class Reprojector : def __init__ ( self , new_coords_fp = None , new_grid_fp = None ): if new_coords_fp is None and new_grid_fp is None : return df_new_coords = pd . read_csv ( new_coords_fp ) self . new_x_coords = df_new_coords [ 'x' ] self . new_y_coords = df_new_coords [ 'y' ] self . new_grid_fp = new_grid_fp return def reproject ( self , native_fp , reproj_library = 'pyresample' ): if reproj_library == 'pyinterp' : ds_reproj = full_scene_pyinterp ( native_fp , self . new_x_coords , self . new_y_coords , self . new_grid_fp ) elif reproj_library == 'pyresample' : ds_reproj = full_scene_pyresample ( native_fp ) else : raise ValueError ( f '`reproj_library` must be one of: pyresample, pyinterp. { reproj_library } can not be passed.' ) return ds_reproj %% capture -- no - stdout %% timeit new_coords_fp = f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) 15.9 s \u00c2\u00b1 2.24 s per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout %% timeit reprojector = Reprojector () ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) 9.24 s \u00c2\u00b1 1.18 s per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout ds_reproj = reprojector . reproject ( native_fp ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-41-4aa2b08f07bf> in <module> ----> 1 ds_reproj = reprojector.reproject(native_fp) 2 3 # Plotting 4 fig = plt.figure(dpi=250, figsize=(10, 10)) 5 ax = plt.axes(projection=ccrs.TransverseMercator()) NameError: name 'reprojector' is not defined","title":"Comparing Reprojection Libraries"},{"location":"02_reprojection/","text":"Data Transformation \u00b6 #exports import json import pandas as pd import xarray as xr import numpy as np import numpy.ma as ma import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import colors import seaborn as sns import os import time from itertools import product from collections import OrderedDict from datetime import datetime from ipypb import track import FEAutils as hlp import satpy from satpy import Scene from satpy.readers import seviri_l1b_native import pyresample from pyresample.geometry import AreaDefinition # pyinterp fails to import on some machines for unknown reasons - leave it optional try : import pyinterp import pyinterp.backends.xarray except : pass We'll separately install libraries that wont be needed for the satip module import rasterio from rasterio import Affine as A from rasterio.warp import reproject , Resampling , calculate_default_transform , transform from rasterio.control import GroundControlPoint from rasterio.transform import xy import geopandas as gpd from shapely.geometry import Point import cartopy.crs as ccrs from IPython.display import JSON User Input \u00b6 data_dir = '../data/raw' intermediate_data_dir = '../data/intermediate' calculate_reproj_coords = False Exploratory Data Analysis \u00b6 We'll start by identifying the available files native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fps [ 0 ] '../data/raw/MSG3-SEVI-MSG15-0100-NA-20200101000414.102000000Z-NA.nat' Then load one of them in as a SatPy scene native_fp = native_fps [ 0 ] scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) scene <satpy.scene.Scene at 0x7fefffd372e0> We can get a list of the available datasets (bands) scene . all_dataset_names () ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] Each band contains an XArray DataArray scene . load ([ 'HRV' ]) scene [ 'HRV' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'reshape-fd3ddacb7375d17e09a9a699dec1d796' (y: 4176, x: 5568)> dask.array<mul, shape=(4176, 5568), dtype=float32, chunksize=(1392, 5568), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unknown\",E... * y (y) float64 1.395e+06 1.396e+06 1.397e+06 ... 5.57e+06 5.571e+06 * x (x) float64 2.848e+06 2.847e+06 2.846e+06 ... -2.718e+06 -2.719e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9666341022821399 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2020-01-01 00:00:07.683136 end_time: 2020-01-01 00:05:08.789141 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'reshape-fd3ddacb7375d17e09a9a699dec1d796' y : 4176 x : 5568 dask.array<chunksize=(1392, 5568), meta=np.ndarray> Array Chunk Bytes 93.01 MB 31.00 MB Shape (4176, 5568) (1392, 5568) Count 214 Tasks 3 Chunks Type float32 numpy.ndarray 5568 4176 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Geostationary Satellite (Sweep Y) Datum: unknown - Ellipsoid: unknown - Prime Meridian: Greenwich , dtype=object) y (y) float64 1.395e+06 1.396e+06 ... 5.571e+06 units : meter array([1395187.416673, 1396187.551022, 1397187.68537 , ..., 5568748.054504, 5569748.188853, 5570748.323202]) x (x) float64 2.848e+06 2.847e+06 ... -2.719e+06 units : meter array([ 2848382.62558 , 2847382.491231, 2846382.356882, ..., -2717365.025878, -2718365.160227, -2719365.294576]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9666341022821399 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2020-01-01 00:00:07.683136 end_time : 2020-01-01 00:05:08.789141 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2848882.6928, 5571248.3904, -2719865.3618, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We can see that the DataArray contains a crs, however we'll make our own custom area definition that's more accurate. First we'll create a helper function that will create our area definitions. #exports def calculate_x_offset ( native_fp ): handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) lower_east_column_planned = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] x_offset = 32500 + (( 2733 - lower_east_column_planned ) * 1000 ) return x_offset def get_seviri_area_def ( native_fp , num_x_pixels = 5568 , num_y_pixels = 4176 ) -> AreaDefinition : \"\"\" The HRV channel on Meteosat Second Generation satellites doesn't scan the full number of columns. The east boundary of the HRV channel changes (e.g. to maximise the amount of the image which is illuminated by sunlight. Parameters: native_fp: Data filepath \"\"\" x_offset = calculate_x_offset ( native_fp ) # The EUMETSAT docs say \"The distance between spacecraft and centre of earth is 42,164 km. The idealized earth # is a perfect ellipsoid with an equator radius of 6378.1690 km and a polar radius of 6356.5838 km.\" # The projection used by SatPy expresses height as height above the Earth's surface (not distance # to the centre of the Earth). projection = { 'proj' : 'geos' , 'lon_0' : 9.5 , 'a' : 6378169.0 , 'b' : 6356583.8 , 'h' : 35785831.00 , 'units' : 'm' } seviri = AreaDefinition ( area_id = 'seviri' , description = 'SEVIRI RSS HRV' , proj_id = 'seviri' , projection = projection , width = num_x_pixels , height = num_y_pixels , area_extent = [ - 2768872.0236 + x_offset , # left 1394687.3495 , # bottom (from scene['HRV'].area) 2799876.1893 + x_offset , # right 5570248.4773 ] # top (from scene['HRV'].area) ) return seviri Then we'll use it to construct the relevant one for Seviri seviri = get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () seviri_crs 2021-01-07T10:54:43.449892 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +a=6378169.0 +rf=295.488065897001 +h=35785831.0 +lon_0=9.5 +no_defs=True +proj=geos +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We'll create a loader function that will extract the relevant data for lower_east_column_planned automatically #exports def load_scene ( native_fp ): # Reading scene and loading HRV scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) # Identifying and recording lower_east_column_planned handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) scene . attrs [ 'lower_east_column_planned' ] = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] return scene We'll see how quickly this loads %% time scene = load_scene ( native_fp ) scene . load ([ 'HRV' ]) CPU times: user 382 ms, sys: 35.9 ms, total: 418 ms Wall time: 424 ms We can visualise what a specific band looks like fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7ff000b93550> One of the benefits of having access to the underlying XArray object is that we can more easily start to do some analysis with the data, for example defining a reflectance threshold reflectance_threshold = 35 cmap = colors . ListedColormap ([ ( 0 , 0 , 0 , 0 ), # transparent ( 251 / 255 , 242 / 255 , 180 / 255 , 1 ) # yellow # (0.533, 0.808, 0.922, 1) # grey-like blue ]) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , vmin = 0 , vmax = 50 , cmap = 'magma' , add_colorbar = False ) ( scene [ 'HRV' ] > reflectance_threshold ) . plot . imshow ( ax = ax , cmap = cmap , add_colorbar = False ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fefdea7fc70> We'll extract the values from the XArray object, then mask all NaN values to enable us to carry out statistical analysis HRV = scene [ \"HRV\" ] . values HRV_masked = ma . masked_array ( HRV , mask = xr . ufuncs . isnan ( scene [ \"HRV\" ]) . values ) np . mean ( HRV_masked ) 0.042987997682800906 We can also visualise the full distribution. N.b. to reduce the time it takes to calculate the best KDE fit we'll take only a sample of the data. HRV_sample = np . random . choice ( HRV_masked . flatten (), 1_000_000 ) # Plotting fig , ax = plt . subplots ( dpi = 250 ) sns . kdeplot ( HRV_sample , ax = ax , fill = True ) ax . set_yticks ([]) ax . set_ylabel ( '' ) ax . set_xlabel ( 'HRV Reflectance' ) hlp . hide_spines ( ax , positions = [ 'top' , 'left' , 'right' ]) Evaluating Reprojection to Tranverse Mercator \u00b6 Before we can resample we need to define the area we're resampling to, we'll write a constructor to help us do this #exports def construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , pixel_size = None ): # If None then will use same number of x and y points # HRV's resolution will be more like 4km for Europe if pixel_size is not None : width = int (( east - west ) / pixel_size ) height = int (( north - south ) / pixel_size ) else : width = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . x . values . shape [ 0 ] height = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . y . values . shape [ 0 ] area_extent = ( west , south , east , north ) area_def = AreaDefinition ( area_id , description , proj_id , projection , width , height , area_extent ) return area_def def construct_TM_area_def ( scene ): meters_per_pixel = 4000 west , south , east , north = ( - 3090000 , 1690000 , 4390000 , 9014000 ) area_id = 'TM' description = 'Transverse Mercator' proj_id = 'TM' projection = { 'ellps' : 'WGS84' , 'proj' : 'tmerc' , # Transverse Mercator 'units' : 'm' # meters } tm_area_def = construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , meters_per_pixel ) return tm_area_def tm_area_def = construct_TM_area_def ( scene ) tm_area_def . to_cartopy_crs () 2021-01-07T10:55:42.310544 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +k=1.0 +lat_0=0.0 +lon_0=0.0 +no_defs=True +proj=tmerc +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We can now carry out the resampling using the pyresample library %% time resampled_scene = scene . resample ( tm_area_def , resampler = 'nearest' ) CPU times: user 2.71 s, sys: 52.7 ms, total: 2.76 s Wall time: 2.74 s We'll quickly check that the reprojection looks ok fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fef0e182a00> We want to gain a deeper understanding of the reprojection that's being carried out, to do this we'll manually reproject a sample of the original gridded coordinates %% time orig_x_values = scene [ 'HRV' ] . x . values [:: 50 ] orig_y_values = scene [ 'HRV' ] . y . values [:: 50 ] XX , YY = np . meshgrid ( orig_x_values , orig_y_values ) df_proj_points = ( gpd . GeoSeries ([ Point ( x , y ) for x , y in np . stack ([ XX . flatten (), YY . flatten ()], axis = 1 ) ]) . set_crs ( crs = scene [ 'HRV' ] . area . crs_wkt ) . to_crs ( crs = resampled_scene [ 'HRV' ] . area . crs_wkt ) . apply ( lambda point : pd . Series ( list ( point . coords )[ 0 ])) . rename ( columns = { 0 : 'x_reproj' , 1 : 'y_reproj' }) . replace ( np . inf , np . nan ) . pipe ( lambda df : df . assign ( x_orig = XX . flatten ())) . pipe ( lambda df : df . assign ( y_orig = YY . flatten ())) ) df_proj_points . head () CPU times: user 3.42 s, sys: 101 ms, total: 3.52 s Wall time: 3.52 s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_reproj y_reproj x_orig y_orig 0 4.366380e+06 1.812549e+06 2.848383e+06 1.395187e+06 1 4.292044e+06 1.798016e+06 2.798376e+06 1.395187e+06 2 4.218748e+06 1.783987e+06 2.748369e+06 1.395187e+06 3 4.146448e+06 1.770437e+06 2.698362e+06 1.395187e+06 4 4.075104e+06 1.757345e+06 2.648356e+06 1.395187e+06 We can then visualise the reprojection of the original grid against the regridded reprojection %% time fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) ax . scatter ( df_proj_points [ 'x_reproj' ][:: 10 ], df_proj_points [ 'y_reproj' ][:: 10 ], s = 2 , color = 'red' ) CPU times: user 21.1 s, sys: 2.86 s, total: 23.9 s Wall time: 16.1 s <matplotlib.collections.PathCollection at 0x7fef0e1a0b20> This is useful for quick visual inspection, for example we can see that the y axis gets stretched further the nearer to the pole. However, we want to get a better understanding of how the local cell resolution is changing for any given point, we'll begin by looking at this change for Greenwich. def lon_lat_to_new_crs ( lon , lat , crs ): x , y = list ( gpd . GeoSeries ([ Point ( lon , lat )]) . set_crs ( 4326 ) . to_crs ( crs ) . iloc [ 0 ] . coords )[ 0 ] return x , y def calc_res_change ( src_x , src_y , src_da , dst_da , src_dx = 10 , src_dy = 10 ): src_crs = src_da . area . crs_wkt dst_crs = dst_da . area . crs_wkt src_x_width = np . abs ( np . diff ( src_da . x . values )[ 0 ]) src_y_width = np . abs ( np . diff ( src_da . y . values )[ 0 ]) dst_x_width = np . abs ( np . diff ( dst_da . x . values )[ 0 ]) dst_y_width = np . abs ( np . diff ( dst_da . y . values )[ 0 ]) s_points = ( gpd . GeoSeries ([ Point ( src_x , src_y ), Point ( src_x + src_dx , src_y ), Point ( src_x , src_y + src_dy ) ]) . set_crs ( src_crs ) . to_crs ( dst_crs ) ) dst_dx = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) dst_dy = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) x_ratio_change = ( dst_dx / dst_x_width ) / ( src_dx / src_x_width ) y_ratio_change = ( dst_dy / dst_y_width ) / ( src_dy / src_y_width ) return x_ratio_change , y_ratio_change lon = 0 lat = 51.4934 src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) x_ratio_change , y_ratio_change = calc_res_change ( src_x , src_y , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) x_ratio_change , y_ratio_change (0.2738156746729371, 0.528776076616483) We'll double check this by calculating it through a different method, in this case by locating the nearest cell for each scene and comparing their sizes in a common coordinate system def get_da_nearest_cell_width_height ( da , x , y , units_crs ): nearest_loc = da . sel ( x = x , y = y , method = 'nearest' ) nearest_x = nearest_loc . x . values nearest_y = nearest_loc . y . values next_nearest_x = da . x . values [ list ( da . x . values ) . index ( nearest_x ) + 1 ] next_nearest_y = da . y . values [ list ( da . y . values ) . index ( nearest_y ) + 1 ] s_points = ( gpd . GeoSeries ([ Point ( nearest_x , nearest_y ), Point ( next_nearest_x , nearest_y ), Point ( nearest_x , next_nearest_y ) ]) . set_crs ( da . area . crs_wkt ) . to_crs ( units_crs ) ) x_width = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) y_height = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) return x_width , y_height src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , resampled_scene [ 'HRV' ] . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( resampled_scene [ 'HRV' ], dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km This can easily be converted into a x and y pixel size ratio change which almost exactly matches our previous calculation. The first calculation is more accurate as the dx and dy can approach 0 and get closer to the true ratio change, however the get_da_nearest_cell_width_height function is still useful as it allows us to determine the cell width and height in more interpretable units x_ratio_change , y_ratio_change = src_x_width / dst_x_width , src_y_height / dst_y_height x_ratio_change , y_ratio_change (0.25878590720382494, 0.3405084839876136) Iceland is stretched further still def print_pixel_change ( lon , lat , da_src , da_dst ): src_x , src_y = lon_lat_to_new_crs ( lon , lat , da_src . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , da_dst . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( da_src , src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( da_dst , dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) return lon = - 18.779208 lat = 64.887370 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.52 km to 3.99 km The height has changed from 4.75 km to 3.99 km And contrasts with Marrakesh which is stretched less than Greenwich in the y axis lon = - 8.005657 lat = 31.636355 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km We can check what the cell height and width are at the center of the image, they should both be close to 1km according to the SEVIRI documentation LineDirGridStep gives the grid step size in km SSP in the line direction. Default value is 3km for VIS and IR, and 1km for HRV. The on-ground grid step size of 3 km at the SSP represents an instrument scan step of 251.53 microrad divided by 3. - EUMETSAT round_m_to_km = lambda m : round ( m / 1000 , 2 ) UTM_35N_epsg = 32632 # should be relatively accurate and is in meters src_x = np . median ( scene [ 'HRV' ] . x . values ) src_y = np . median ( scene [ 'HRV' ] . y . values ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , UTM_35N_epsg ) round_m_to_km ( src_x_width ), round_m_to_km ( src_y_height ) Comparing Reprojection Libraries \u00b6 In the last section we used pyresample to carry out the data reprojection, here we'll explore pyinterp . Before we start we'll quickly extract the xarrays for the original and reprojected coordinates. def extract_formatted_scene ( scene , variable = 'HRV' , x_coords_name = 'x' , y_coords_name = 'y' , x_units = 'metre' , y_units = 'metre' ): da = ( scene [ variable ] . copy () . rename ({ 'x' : x_coords_name , 'y' : y_coords_name }) ) da [ x_coords_name ] . attrs [ 'units' ] = x_units da [ y_coords_name ] . attrs [ 'units' ] = y_units return da da = extract_formatted_scene ( scene ) da_resampled = extract_formatted_scene ( resampled_scene ) da_resampled /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'my_index-c404aea544fb57092a221d3fc106759f' (y: 1831, x: 1870)> dask.array<copy, shape=(1831, 1870), dtype=float32, chunksize=(1831, 1870), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unknown ba... * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 -3.08e+06 ... 4.384e+06 4.388e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9666341022821399 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2020-01-01 00:00:07.683136 end_time: 2020-01-01 00:05:08.789141 area: Area ID: TM\\nDescription: Transve... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'my_index-c404aea544fb57092a221d3fc106759f' y : 1831 x : 1870 dask.array<chunksize=(1831, 1870), meta=np.ndarray> Array Chunk Bytes 13.70 MB 13.70 MB Shape (1831, 1870) (1831, 1870) Count 360 Tasks 1 Chunks Type float32 numpy.ndarray 1870 1831 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Transverse Mercator Datum: Unknown based on WGS84 ellipsoid - Ellipsoid: WGS 84 - Prime Meridian: Greenwich , dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 units : metre array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 units : metre array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9666341022821399 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2020-01-01 00:00:07.683136 end_time : 2020-01-01 00:05:08.789141 area : Area ID: TM Description: Transverse Mercator Projection ID: TM Projection: {'ellps': 'WGS84', 'k': '1', 'lat_0': '0', 'lon_0': '0', 'no_defs': 'None', 'proj': 'tmerc', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 1870 Number of rows: 1831 Area extent: (-3090000, 1690000, 4390000, 9014000) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We'll now save the coordinates of the grid we're using in the new projection new_grid_4km_TM = { 'x_coords' : list ( da_resampled . x . values ), 'y_coords' : list ( da_resampled . y . values ) } save_data = True if save_data == True : with open ( '../data/intermediate/new_grid_4km_TM.json' , 'w' ) as fp : json . dump ( new_grid_4km_TM , fp ) JSON ( new_grid_4km_TM ) <IPython.core.display.JSON object> As well as calculate the locations of those points in the original CRS %% time def chunks ( list_ , n ): \"\"\" Yield successive n-sized chunks from `list_`. \"\"\" for i in range ( 0 , len ( list_ ), n ): yield list_ [ i : i + n ] def reproject_geometries ( da , old_crs , new_crs , chunk_size = 5000 ): xx , yy = np . meshgrid ( da . x . values , da . y . values , indexing = 'ij' ) geometry = gpd . points_from_xy ( xx . flatten (), yy . flatten ()) new_coords_samples = [] for geometry_sample in chunks ( geometry , chunk_size ): df_new_coords_sample = ( gpd . GeoSeries ( geometry_sample , crs = old_crs ) . to_crs ( new_crs ) . apply ( lambda x : list ( x . coords [ 0 ])) . apply ( pd . Series ) . rename ( columns = { 0 : 'x' , 1 : 'y' }) ) new_coords_samples += [ df_new_coords_sample ] df_new_coords = pd . concat ( new_coords_samples , ignore_index = True ) return df_new_coords if not os . path . exists ( intermediate_data_dir ): os . makedirs ( intermediate_data_dir ) if calculate_reproj_coords == True : df_new_coords = reproject_geometries ( da_resampled , '+proj=tmerc' , seviri_crs . proj4_init ) df_new_coords . to_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' , index = False ) elif 'reproj_coords_TM_4km.csv' not in os . listdir ( intermediate_data_dir ): df_new_coords = pd . read_csv ( 'https://storage.googleapis.com/reprojection_cache/reproj_coords_TM_4km.csv' ) else : df_new_coords = pd . read_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' ) df_new_coords . head () CPU times: user 1.31 s, sys: 125 ms, total: 1.43 s Wall time: 1.43 s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y 0 inf inf 1 inf inf 2 inf inf 3 inf inf 4 inf inf We can layer these on top of each other to get an alternative view of the transform operation %% time old_x_positions , old_y_positions = [ elem . flatten () for elem in np . meshgrid ( da . x . values [:: 100 ], da . y . values [:: 100 ], indexing = 'ij' )] new_x_positions , new_y_positions = df_new_coords [ 'x' ][:: 100 ], df_new_coords [ 'y' ][:: 100 ] # Plotting fig , ax = plt . subplots ( dpi = 150 ) ax . scatter ( old_x_positions , old_y_positions , s = 0.1 ) ax . scatter ( new_x_positions , new_y_positions , s = 0.1 ) hlp . hide_spines ( ax ) CPU times: user 41.4 ms, sys: 6.35 ms, total: 47.7 ms Wall time: 44.5 ms We'll now use pyinterp to take these and use them to carry out the resampling. We'll also create a wrapper for converting the result back into an Xarray object. #exports def reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ): x_axis = pyinterp . Axis ( da . x . values ) y_axis = pyinterp . Axis ( da . y . values ) grid = pyinterp . Grid2D ( x_axis , y_axis , da . data . T ) reproj_data = ( pyinterp . bivariate ( grid , x_coords , y_coords ) . reshape (( len ( new_grid [ 'x_coords' ]), len ( new_grid [ 'y_coords' ]))) ) return reproj_data def reproj_to_xarray ( da , x_coords , y_coords , new_grid ): # We'll reproject the data reproj_data = reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ) # Then put it in an XArray DataArray da_reproj = xr . DataArray ( np . flip ( reproj_data . T , axis = ( 0 , 1 )), dims = ( 'y' , 'x' ), coords = { 'x' : new_grid [ 'x_coords' ][:: - 1 ], 'y' : new_grid [ 'y_coords' ][:: - 1 ] }, attrs = da . attrs ) return da_reproj We'll load the grid back in with open ( '../data/intermediate/new_grid_4km_TM.json' , 'r' ) as fp : new_grid = json . load ( fp ) JSON ( new_grid ) <IPython.core.display.JSON object> Confirm that the size of the grid definition arrays match the number of coordinates we have df_new_coords [ 'y' ] . size == len ( new_grid [ 'x_coords' ]) * len ( new_grid [ 'y_coords' ]) True And finally carry out the reprojection %% timeit # if pyinterp not present try : da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) except : pass 5.81 \u00c2\u00b5s \u00c2\u00b1 26.2 ns per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 100000 loops each) Most importantly we'll carry out a visual check that the reprojection was carried out properly. # if pyinterp not present try : da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_reproj . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) except : pass #exports def full_scene_pyresample ( native_fp ): # Loading scene scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) # Constructing target area definition tm_area_def = construct_TM_area_def ( scene ) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da = scene [ dataset_name ] . sortby ( 'y' , ascending = False ) . sortby ( 'x' ) num_y_pixels , num_x_pixels = da . shape seviri_area_def = get_seviri_area_def ( native_fp , num_x_pixels = num_x_pixels , num_y_pixels = num_y_pixels ) resampler = satpy . resample . KDTreeResampler ( seviri_area_def , tm_area_def ) da_reproj = resampler . resample ( da ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = ( xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) . drop ( labels = 'crs' ) ) return ds_reproj def full_scene_pyinterp ( native_fp , new_x_coords , new_y_coords , new_grid_fp ): # Loading data scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) with open ( new_grid_fp , 'r' ) as fp : new_grid = json . load ( fp ) # Correcting x coordinates seviri_area_def = get_seviri_area_def ( native_fp ) area_extent = seviri_area_def . area_extent x_offset = calculate_x_offset ( native_fp ) width = scene [ 'HRV' ] . x . size corrected_x_coords = np . linspace ( area_extent [ 2 ], area_extent [ 0 ], width ) scene [ 'HRV' ] = scene [ 'HRV' ] . assign_coords ({ 'x' : corrected_x_coords }) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da_reproj = reproj_to_xarray ( scene [ dataset_name ], new_x_coords , new_y_coords , new_grid ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) return ds_reproj class Reprojector : def __init__ ( self , new_coords_fp = None , new_grid_fp = None ): if new_coords_fp is None and new_grid_fp is None : return df_new_coords = pd . read_csv ( new_coords_fp ) self . new_x_coords = df_new_coords [ 'x' ] self . new_y_coords = df_new_coords [ 'y' ] self . new_grid_fp = new_grid_fp return def reproject ( self , native_fp , reproj_library = 'pyresample' ): if reproj_library == 'pyinterp' : ds_reproj = full_scene_pyinterp ( native_fp , self . new_x_coords , self . new_y_coords , self . new_grid_fp ) elif reproj_library == 'pyresample' : ds_reproj = full_scene_pyresample ( native_fp ) else : raise ValueError ( f '`reproj_library` must be one of: pyresample, pyinterp. { reproj_library } can not be passed.' ) return ds_reproj new_coords_fp = f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = Reprojector ( new_coords_fp , new_grid_fp ) reprojector <__main__.Reprojector at 0x7fef0e0f3e50> %% capture -- no - stdout %% timeit # in case pyinterp is not available: try : ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) except : pass 976 ms \u00c2\u00b1 28.5 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout %% timeit reprojector = Reprojector () ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) 3.62 s \u00c2\u00b1 35.6 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout ds_reproj = reprojector . reproject ( native_fp ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7feffff382b0>","title":"Data Transformation"},{"location":"02_reprojection/#data-transformation","text":"#exports import json import pandas as pd import xarray as xr import numpy as np import numpy.ma as ma import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import colors import seaborn as sns import os import time from itertools import product from collections import OrderedDict from datetime import datetime from ipypb import track import FEAutils as hlp import satpy from satpy import Scene from satpy.readers import seviri_l1b_native import pyresample from pyresample.geometry import AreaDefinition # pyinterp fails to import on some machines for unknown reasons - leave it optional try : import pyinterp import pyinterp.backends.xarray except : pass We'll separately install libraries that wont be needed for the satip module import rasterio from rasterio import Affine as A from rasterio.warp import reproject , Resampling , calculate_default_transform , transform from rasterio.control import GroundControlPoint from rasterio.transform import xy import geopandas as gpd from shapely.geometry import Point import cartopy.crs as ccrs from IPython.display import JSON","title":"Data Transformation"},{"location":"02_reprojection/#user-input","text":"data_dir = '../data/raw' intermediate_data_dir = '../data/intermediate' calculate_reproj_coords = False","title":"User Input"},{"location":"02_reprojection/#exploratory-data-analysis","text":"We'll start by identifying the available files native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fps [ 0 ] '../data/raw/MSG3-SEVI-MSG15-0100-NA-20200101000414.102000000Z-NA.nat' Then load one of them in as a SatPy scene native_fp = native_fps [ 0 ] scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) scene <satpy.scene.Scene at 0x7fefffd372e0> We can get a list of the available datasets (bands) scene . all_dataset_names () ['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'] Each band contains an XArray DataArray scene . load ([ 'HRV' ]) scene [ 'HRV' ] /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'reshape-fd3ddacb7375d17e09a9a699dec1d796' (y: 4176, x: 5568)> dask.array<mul, shape=(4176, 5568), dtype=float32, chunksize=(1392, 5568), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unknown\",E... * y (y) float64 1.395e+06 1.396e+06 1.397e+06 ... 5.57e+06 5.571e+06 * x (x) float64 2.848e+06 2.847e+06 2.846e+06 ... -2.718e+06 -2.719e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9666341022821399 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2020-01-01 00:00:07.683136 end_time: 2020-01-01 00:05:08.789141 area: Area ID: geos_seviri_hrv\\nDescrip... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'reshape-fd3ddacb7375d17e09a9a699dec1d796' y : 4176 x : 5568 dask.array<chunksize=(1392, 5568), meta=np.ndarray> Array Chunk Bytes 93.01 MB 31.00 MB Shape (4176, 5568) (1392, 5568) Count 214 Tasks 3 Chunks Type float32 numpy.ndarray 5568 4176 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Geostationary Satellite (Sweep Y) Datum: unknown - Ellipsoid: unknown - Prime Meridian: Greenwich , dtype=object) y (y) float64 1.395e+06 1.396e+06 ... 5.571e+06 units : meter array([1395187.416673, 1396187.551022, 1397187.68537 , ..., 5568748.054504, 5569748.188853, 5570748.323202]) x (x) float64 2.848e+06 2.847e+06 ... -2.719e+06 units : meter array([ 2848382.62558 , 2847382.491231, 2846382.356882, ..., -2717365.025878, -2718365.160227, -2719365.294576]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9666341022821399 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2020-01-01 00:00:07.683136 end_time : 2020-01-01 00:05:08.789141 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2848882.6928, 5571248.3904, -2719865.3618, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We can see that the DataArray contains a crs, however we'll make our own custom area definition that's more accurate. First we'll create a helper function that will create our area definitions. #exports def calculate_x_offset ( native_fp ): handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) lower_east_column_planned = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] x_offset = 32500 + (( 2733 - lower_east_column_planned ) * 1000 ) return x_offset def get_seviri_area_def ( native_fp , num_x_pixels = 5568 , num_y_pixels = 4176 ) -> AreaDefinition : \"\"\" The HRV channel on Meteosat Second Generation satellites doesn't scan the full number of columns. The east boundary of the HRV channel changes (e.g. to maximise the amount of the image which is illuminated by sunlight. Parameters: native_fp: Data filepath \"\"\" x_offset = calculate_x_offset ( native_fp ) # The EUMETSAT docs say \"The distance between spacecraft and centre of earth is 42,164 km. The idealized earth # is a perfect ellipsoid with an equator radius of 6378.1690 km and a polar radius of 6356.5838 km.\" # The projection used by SatPy expresses height as height above the Earth's surface (not distance # to the centre of the Earth). projection = { 'proj' : 'geos' , 'lon_0' : 9.5 , 'a' : 6378169.0 , 'b' : 6356583.8 , 'h' : 35785831.00 , 'units' : 'm' } seviri = AreaDefinition ( area_id = 'seviri' , description = 'SEVIRI RSS HRV' , proj_id = 'seviri' , projection = projection , width = num_x_pixels , height = num_y_pixels , area_extent = [ - 2768872.0236 + x_offset , # left 1394687.3495 , # bottom (from scene['HRV'].area) 2799876.1893 + x_offset , # right 5570248.4773 ] # top (from scene['HRV'].area) ) return seviri Then we'll use it to construct the relevant one for Seviri seviri = get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () seviri_crs 2021-01-07T10:54:43.449892 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +a=6378169.0 +rf=295.488065897001 +h=35785831.0 +lon_0=9.5 +no_defs=True +proj=geos +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We'll create a loader function that will extract the relevant data for lower_east_column_planned automatically #exports def load_scene ( native_fp ): # Reading scene and loading HRV scene = Scene ( filenames = [ native_fp ], reader = 'seviri_l1b_native' ) # Identifying and recording lower_east_column_planned handler = seviri_l1b_native . NativeMSGFileHandler ( native_fp , {}, None ) scene . attrs [ 'lower_east_column_planned' ] = handler . header [ '15_DATA_HEADER' ][ 'ImageDescription' ][ 'PlannedCoverageHRV' ][ 'LowerEastColumnPlanned' ] return scene We'll see how quickly this loads %% time scene = load_scene ( native_fp ) scene . load ([ 'HRV' ]) CPU times: user 382 ms, sys: 35.9 ms, total: 418 ms Wall time: 424 ms We can visualise what a specific band looks like fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7ff000b93550> One of the benefits of having access to the underlying XArray object is that we can more easily start to do some analysis with the data, for example defining a reflectance threshold reflectance_threshold = 35 cmap = colors . ListedColormap ([ ( 0 , 0 , 0 , 0 ), # transparent ( 251 / 255 , 242 / 255 , 180 / 255 , 1 ) # yellow # (0.533, 0.808, 0.922, 1) # grey-like blue ]) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , vmin = 0 , vmax = 50 , cmap = 'magma' , add_colorbar = False ) ( scene [ 'HRV' ] > reflectance_threshold ) . plot . imshow ( ax = ax , cmap = cmap , add_colorbar = False ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fefdea7fc70> We'll extract the values from the XArray object, then mask all NaN values to enable us to carry out statistical analysis HRV = scene [ \"HRV\" ] . values HRV_masked = ma . masked_array ( HRV , mask = xr . ufuncs . isnan ( scene [ \"HRV\" ]) . values ) np . mean ( HRV_masked ) 0.042987997682800906 We can also visualise the full distribution. N.b. to reduce the time it takes to calculate the best KDE fit we'll take only a sample of the data. HRV_sample = np . random . choice ( HRV_masked . flatten (), 1_000_000 ) # Plotting fig , ax = plt . subplots ( dpi = 250 ) sns . kdeplot ( HRV_sample , ax = ax , fill = True ) ax . set_yticks ([]) ax . set_ylabel ( '' ) ax . set_xlabel ( 'HRV Reflectance' ) hlp . hide_spines ( ax , positions = [ 'top' , 'left' , 'right' ])","title":"Exploratory Data Analysis"},{"location":"02_reprojection/#evaluating-reprojection-to-tranverse-mercator","text":"Before we can resample we need to define the area we're resampling to, we'll write a constructor to help us do this #exports def construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , pixel_size = None ): # If None then will use same number of x and y points # HRV's resolution will be more like 4km for Europe if pixel_size is not None : width = int (( east - west ) / pixel_size ) height = int (( north - south ) / pixel_size ) else : width = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . x . values . shape [ 0 ] height = scene [ list ( scene . keys ())[ 0 ][ 'name' ]] . y . values . shape [ 0 ] area_extent = ( west , south , east , north ) area_def = AreaDefinition ( area_id , description , proj_id , projection , width , height , area_extent ) return area_def def construct_TM_area_def ( scene ): meters_per_pixel = 4000 west , south , east , north = ( - 3090000 , 1690000 , 4390000 , 9014000 ) area_id = 'TM' description = 'Transverse Mercator' proj_id = 'TM' projection = { 'ellps' : 'WGS84' , 'proj' : 'tmerc' , # Transverse Mercator 'units' : 'm' # meters } tm_area_def = construct_area_def ( scene , area_id , description , proj_id , projection , west , south , east , north , meters_per_pixel ) return tm_area_def tm_area_def = construct_TM_area_def ( scene ) tm_area_def . to_cartopy_crs () 2021-01-07T10:55:42.310544 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ *{stroke-linecap:butt;stroke-linejoin:round;} _PROJ4Projection(+ellps=WGS84 +k=1.0 +lat_0=0.0 +lon_0=0.0 +no_defs=True +proj=tmerc +type=crs +units=m +x_0=0.0 +y_0=0.0 +no_defs) We can now carry out the resampling using the pyresample library %% time resampled_scene = scene . resample ( tm_area_def , resampler = 'nearest' ) CPU times: user 2.71 s, sys: 52.7 ms, total: 2.76 s Wall time: 2.74 s We'll quickly check that the reprojection looks ok fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fef0e182a00> We want to gain a deeper understanding of the reprojection that's being carried out, to do this we'll manually reproject a sample of the original gridded coordinates %% time orig_x_values = scene [ 'HRV' ] . x . values [:: 50 ] orig_y_values = scene [ 'HRV' ] . y . values [:: 50 ] XX , YY = np . meshgrid ( orig_x_values , orig_y_values ) df_proj_points = ( gpd . GeoSeries ([ Point ( x , y ) for x , y in np . stack ([ XX . flatten (), YY . flatten ()], axis = 1 ) ]) . set_crs ( crs = scene [ 'HRV' ] . area . crs_wkt ) . to_crs ( crs = resampled_scene [ 'HRV' ] . area . crs_wkt ) . apply ( lambda point : pd . Series ( list ( point . coords )[ 0 ])) . rename ( columns = { 0 : 'x_reproj' , 1 : 'y_reproj' }) . replace ( np . inf , np . nan ) . pipe ( lambda df : df . assign ( x_orig = XX . flatten ())) . pipe ( lambda df : df . assign ( y_orig = YY . flatten ())) ) df_proj_points . head () CPU times: user 3.42 s, sys: 101 ms, total: 3.52 s Wall time: 3.52 s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x_reproj y_reproj x_orig y_orig 0 4.366380e+06 1.812549e+06 2.848383e+06 1.395187e+06 1 4.292044e+06 1.798016e+06 2.798376e+06 1.395187e+06 2 4.218748e+06 1.783987e+06 2.748369e+06 1.395187e+06 3 4.146448e+06 1.770437e+06 2.698362e+06 1.395187e+06 4 4.075104e+06 1.757345e+06 2.648356e+06 1.395187e+06 We can then visualise the reprojection of the original grid against the regridded reprojection %% time fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) resampled_scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) ax . scatter ( df_proj_points [ 'x_reproj' ][:: 10 ], df_proj_points [ 'y_reproj' ][:: 10 ], s = 2 , color = 'red' ) CPU times: user 21.1 s, sys: 2.86 s, total: 23.9 s Wall time: 16.1 s <matplotlib.collections.PathCollection at 0x7fef0e1a0b20> This is useful for quick visual inspection, for example we can see that the y axis gets stretched further the nearer to the pole. However, we want to get a better understanding of how the local cell resolution is changing for any given point, we'll begin by looking at this change for Greenwich. def lon_lat_to_new_crs ( lon , lat , crs ): x , y = list ( gpd . GeoSeries ([ Point ( lon , lat )]) . set_crs ( 4326 ) . to_crs ( crs ) . iloc [ 0 ] . coords )[ 0 ] return x , y def calc_res_change ( src_x , src_y , src_da , dst_da , src_dx = 10 , src_dy = 10 ): src_crs = src_da . area . crs_wkt dst_crs = dst_da . area . crs_wkt src_x_width = np . abs ( np . diff ( src_da . x . values )[ 0 ]) src_y_width = np . abs ( np . diff ( src_da . y . values )[ 0 ]) dst_x_width = np . abs ( np . diff ( dst_da . x . values )[ 0 ]) dst_y_width = np . abs ( np . diff ( dst_da . y . values )[ 0 ]) s_points = ( gpd . GeoSeries ([ Point ( src_x , src_y ), Point ( src_x + src_dx , src_y ), Point ( src_x , src_y + src_dy ) ]) . set_crs ( src_crs ) . to_crs ( dst_crs ) ) dst_dx = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) dst_dy = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) x_ratio_change = ( dst_dx / dst_x_width ) / ( src_dx / src_x_width ) y_ratio_change = ( dst_dy / dst_y_width ) / ( src_dy / src_y_width ) return x_ratio_change , y_ratio_change lon = 0 lat = 51.4934 src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) x_ratio_change , y_ratio_change = calc_res_change ( src_x , src_y , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) x_ratio_change , y_ratio_change (0.2738156746729371, 0.528776076616483) We'll double check this by calculating it through a different method, in this case by locating the nearest cell for each scene and comparing their sizes in a common coordinate system def get_da_nearest_cell_width_height ( da , x , y , units_crs ): nearest_loc = da . sel ( x = x , y = y , method = 'nearest' ) nearest_x = nearest_loc . x . values nearest_y = nearest_loc . y . values next_nearest_x = da . x . values [ list ( da . x . values ) . index ( nearest_x ) + 1 ] next_nearest_y = da . y . values [ list ( da . y . values ) . index ( nearest_y ) + 1 ] s_points = ( gpd . GeoSeries ([ Point ( nearest_x , nearest_y ), Point ( next_nearest_x , nearest_y ), Point ( nearest_x , next_nearest_y ) ]) . set_crs ( da . area . crs_wkt ) . to_crs ( units_crs ) ) x_width = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 1 ]) y_height = s_points . iloc [ 0 ] . distance ( s_points . iloc [ 2 ]) return x_width , y_height src_x , src_y = lon_lat_to_new_crs ( lon , lat , scene [ 'HRV' ] . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , resampled_scene [ 'HRV' ] . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( resampled_scene [ 'HRV' ], dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km This can easily be converted into a x and y pixel size ratio change which almost exactly matches our previous calculation. The first calculation is more accurate as the dx and dy can approach 0 and get closer to the true ratio change, however the get_da_nearest_cell_width_height function is still useful as it allows us to determine the cell width and height in more interpretable units x_ratio_change , y_ratio_change = src_x_width / dst_x_width , src_y_height / dst_y_height x_ratio_change , y_ratio_change (0.25878590720382494, 0.3405084839876136) Iceland is stretched further still def print_pixel_change ( lon , lat , da_src , da_dst ): src_x , src_y = lon_lat_to_new_crs ( lon , lat , da_src . area . crs_wkt ) dst_x , dst_y = lon_lat_to_new_crs ( lon , lat , da_dst . area . crs_wkt ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( da_src , src_x , src_y , 27700 ) dst_x_width , dst_y_height = get_da_nearest_cell_width_height ( da_dst , dst_x , dst_y , 27700 ) print ( f 'The width has changed from { round ( src_x_width / 1000 , 2 ) } km to { round ( dst_x_width / 1000 , 2 ) } km' ) print ( f 'The height has changed from { round ( src_y_height / 1000 , 2 ) } km to { round ( dst_y_height / 1000 , 2 ) } km' ) return lon = - 18.779208 lat = 64.887370 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.52 km to 3.99 km The height has changed from 4.75 km to 3.99 km And contrasts with Marrakesh which is stretched less than Greenwich in the y axis lon = - 8.005657 lat = 31.636355 print_pixel_change ( lon , lat , scene [ 'HRV' ], resampled_scene [ 'HRV' ]) The width has changed from 1.11 km to 3.99 km The height has changed from 1.33 km to 3.99 km We can check what the cell height and width are at the center of the image, they should both be close to 1km according to the SEVIRI documentation LineDirGridStep gives the grid step size in km SSP in the line direction. Default value is 3km for VIS and IR, and 1km for HRV. The on-ground grid step size of 3 km at the SSP represents an instrument scan step of 251.53 microrad divided by 3. - EUMETSAT round_m_to_km = lambda m : round ( m / 1000 , 2 ) UTM_35N_epsg = 32632 # should be relatively accurate and is in meters src_x = np . median ( scene [ 'HRV' ] . x . values ) src_y = np . median ( scene [ 'HRV' ] . y . values ) src_x_width , src_y_height = get_da_nearest_cell_width_height ( scene [ 'HRV' ], src_x , src_y , UTM_35N_epsg ) round_m_to_km ( src_x_width ), round_m_to_km ( src_y_height )","title":"Evaluating Reprojection to Tranverse Mercator"},{"location":"02_reprojection/#comparing-reprojection-libraries","text":"In the last section we used pyresample to carry out the data reprojection, here we'll explore pyinterp . Before we start we'll quickly extract the xarrays for the original and reprojected coordinates. def extract_formatted_scene ( scene , variable = 'HRV' , x_coords_name = 'x' , y_coords_name = 'y' , x_units = 'metre' , y_units = 'metre' ): da = ( scene [ variable ] . copy () . rename ({ 'x' : x_coords_name , 'y' : y_coords_name }) ) da [ x_coords_name ] . attrs [ 'units' ] = x_units da [ y_coords_name ] . attrs [ 'units' ] = y_units return da da = extract_formatted_scene ( scene ) da_resampled = extract_formatted_scene ( resampled_scene ) da_resampled /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'my_index-c404aea544fb57092a221d3fc106759f' (y: 1831, x: 1870)> dask.array<copy, shape=(1831, 1870), dtype=float32, chunksize=(1831, 1870), chunktype=numpy.ndarray> Coordinates: crs object PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unknown ba... * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 -3.08e+06 ... 4.384e+06 4.388e+06 Attributes: orbital_parameters: {'projection_longitude': 9.5, 'pr... sun_earth_distance_correction_applied: True sun_earth_distance_correction_factor: 0.9666341022821399 units: % wavelength: 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name: toa_bidirectional_reflectance platform_name: Meteosat-10 sensor: seviri start_time: 2020-01-01 00:00:07.683136 end_time: 2020-01-01 00:05:08.789141 area: Area ID: TM\\nDescription: Transve... name: HRV resolution: 1000.134348869 calibration: reflectance modifiers: () _satpy_id: DataID(name='HRV', wavelength=Wav... ancillary_variables: [] xarray.DataArray 'my_index-c404aea544fb57092a221d3fc106759f' y : 1831 x : 1870 dask.array<chunksize=(1831, 1870), meta=np.ndarray> Array Chunk Bytes 13.70 MB 13.70 MB Shape (1831, 1870) (1831, 1870) Count 360 Tasks 1 Chunks Type float32 numpy.ndarray 1870 1831 Coordinates: (3) crs () object PROJCRS[\"unknown\",BASEGEOGCRS[\"u... array(<Projected CRS: PROJCRS[\"unknown\",BASEGEOGCRS[\"unknown\",DATUM[\"Unk ...> Name: unknown Axis Info [cartesian]: - E[east]: Easting (metre) - N[north]: Northing (metre) Area of Use: - undefined Coordinate Operation: - name: unknown - method: Transverse Mercator Datum: Unknown based on WGS84 ellipsoid - Ellipsoid: WGS 84 - Prime Meridian: Greenwich , dtype=object) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 units : metre array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 units : metre array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) Attributes: (17) orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9666341022821399 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-10 sensor : seviri start_time : 2020-01-01 00:00:07.683136 end_time : 2020-01-01 00:05:08.789141 area : Area ID: TM Description: Transverse Mercator Projection ID: TM Projection: {'ellps': 'WGS84', 'k': '1', 'lat_0': '0', 'lon_0': '0', 'no_defs': 'None', 'proj': 'tmerc', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 1870 Number of rows: 1831 Area extent: (-3090000, 1690000, 4390000, 9014000) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] We'll now save the coordinates of the grid we're using in the new projection new_grid_4km_TM = { 'x_coords' : list ( da_resampled . x . values ), 'y_coords' : list ( da_resampled . y . values ) } save_data = True if save_data == True : with open ( '../data/intermediate/new_grid_4km_TM.json' , 'w' ) as fp : json . dump ( new_grid_4km_TM , fp ) JSON ( new_grid_4km_TM ) <IPython.core.display.JSON object> As well as calculate the locations of those points in the original CRS %% time def chunks ( list_ , n ): \"\"\" Yield successive n-sized chunks from `list_`. \"\"\" for i in range ( 0 , len ( list_ ), n ): yield list_ [ i : i + n ] def reproject_geometries ( da , old_crs , new_crs , chunk_size = 5000 ): xx , yy = np . meshgrid ( da . x . values , da . y . values , indexing = 'ij' ) geometry = gpd . points_from_xy ( xx . flatten (), yy . flatten ()) new_coords_samples = [] for geometry_sample in chunks ( geometry , chunk_size ): df_new_coords_sample = ( gpd . GeoSeries ( geometry_sample , crs = old_crs ) . to_crs ( new_crs ) . apply ( lambda x : list ( x . coords [ 0 ])) . apply ( pd . Series ) . rename ( columns = { 0 : 'x' , 1 : 'y' }) ) new_coords_samples += [ df_new_coords_sample ] df_new_coords = pd . concat ( new_coords_samples , ignore_index = True ) return df_new_coords if not os . path . exists ( intermediate_data_dir ): os . makedirs ( intermediate_data_dir ) if calculate_reproj_coords == True : df_new_coords = reproject_geometries ( da_resampled , '+proj=tmerc' , seviri_crs . proj4_init ) df_new_coords . to_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' , index = False ) elif 'reproj_coords_TM_4km.csv' not in os . listdir ( intermediate_data_dir ): df_new_coords = pd . read_csv ( 'https://storage.googleapis.com/reprojection_cache/reproj_coords_TM_4km.csv' ) else : df_new_coords = pd . read_csv ( f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' ) df_new_coords . head () CPU times: user 1.31 s, sys: 125 ms, total: 1.43 s Wall time: 1.43 s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y 0 inf inf 1 inf inf 2 inf inf 3 inf inf 4 inf inf We can layer these on top of each other to get an alternative view of the transform operation %% time old_x_positions , old_y_positions = [ elem . flatten () for elem in np . meshgrid ( da . x . values [:: 100 ], da . y . values [:: 100 ], indexing = 'ij' )] new_x_positions , new_y_positions = df_new_coords [ 'x' ][:: 100 ], df_new_coords [ 'y' ][:: 100 ] # Plotting fig , ax = plt . subplots ( dpi = 150 ) ax . scatter ( old_x_positions , old_y_positions , s = 0.1 ) ax . scatter ( new_x_positions , new_y_positions , s = 0.1 ) hlp . hide_spines ( ax ) CPU times: user 41.4 ms, sys: 6.35 ms, total: 47.7 ms Wall time: 44.5 ms We'll now use pyinterp to take these and use them to carry out the resampling. We'll also create a wrapper for converting the result back into an Xarray object. #exports def reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ): x_axis = pyinterp . Axis ( da . x . values ) y_axis = pyinterp . Axis ( da . y . values ) grid = pyinterp . Grid2D ( x_axis , y_axis , da . data . T ) reproj_data = ( pyinterp . bivariate ( grid , x_coords , y_coords ) . reshape (( len ( new_grid [ 'x_coords' ]), len ( new_grid [ 'y_coords' ]))) ) return reproj_data def reproj_to_xarray ( da , x_coords , y_coords , new_grid ): # We'll reproject the data reproj_data = reproj_with_manual_grid ( da , x_coords , y_coords , new_grid ) # Then put it in an XArray DataArray da_reproj = xr . DataArray ( np . flip ( reproj_data . T , axis = ( 0 , 1 )), dims = ( 'y' , 'x' ), coords = { 'x' : new_grid [ 'x_coords' ][:: - 1 ], 'y' : new_grid [ 'y_coords' ][:: - 1 ] }, attrs = da . attrs ) return da_reproj We'll load the grid back in with open ( '../data/intermediate/new_grid_4km_TM.json' , 'r' ) as fp : new_grid = json . load ( fp ) JSON ( new_grid ) <IPython.core.display.JSON object> Confirm that the size of the grid definition arrays match the number of coordinates we have df_new_coords [ 'y' ] . size == len ( new_grid [ 'x_coords' ]) * len ( new_grid [ 'y_coords' ]) True And finally carry out the reprojection %% timeit # if pyinterp not present try : da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) except : pass 5.81 \u00c2\u00b5s \u00c2\u00b1 26.2 ns per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 100000 loops each) Most importantly we'll carry out a visual check that the reprojection was carried out properly. # if pyinterp not present try : da_reproj = reproj_to_xarray ( da , df_new_coords [ 'x' ], df_new_coords [ 'y' ], new_grid ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_reproj . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) except : pass #exports def full_scene_pyresample ( native_fp ): # Loading scene scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) # Constructing target area definition tm_area_def = construct_TM_area_def ( scene ) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da = scene [ dataset_name ] . sortby ( 'y' , ascending = False ) . sortby ( 'x' ) num_y_pixels , num_x_pixels = da . shape seviri_area_def = get_seviri_area_def ( native_fp , num_x_pixels = num_x_pixels , num_y_pixels = num_y_pixels ) resampler = satpy . resample . KDTreeResampler ( seviri_area_def , tm_area_def ) da_reproj = resampler . resample ( da ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = ( xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) . drop ( labels = 'crs' ) ) return ds_reproj def full_scene_pyinterp ( native_fp , new_x_coords , new_y_coords , new_grid_fp ): # Loading data scene = load_scene ( native_fp ) dataset_names = scene . all_dataset_names () scene . load ( dataset_names ) with open ( new_grid_fp , 'r' ) as fp : new_grid = json . load ( fp ) # Correcting x coordinates seviri_area_def = get_seviri_area_def ( native_fp ) area_extent = seviri_area_def . area_extent x_offset = calculate_x_offset ( native_fp ) width = scene [ 'HRV' ] . x . size corrected_x_coords = np . linspace ( area_extent [ 2 ], area_extent [ 0 ], width ) scene [ 'HRV' ] = scene [ 'HRV' ] . assign_coords ({ 'x' : corrected_x_coords }) # Reprojecting reproj_vars = list () for dataset_name in dataset_names : da_reproj = reproj_to_xarray ( scene [ dataset_name ], new_x_coords , new_y_coords , new_grid ) reproj_vars += [ da_reproj ] variable_idx = pd . Index ( dataset_names , name = 'variable' ) ds_reproj = xr . concat ( reproj_vars , dim = variable_idx ) . to_dataset ( name = 'stacked_eumetsat_data' ) return ds_reproj class Reprojector : def __init__ ( self , new_coords_fp = None , new_grid_fp = None ): if new_coords_fp is None and new_grid_fp is None : return df_new_coords = pd . read_csv ( new_coords_fp ) self . new_x_coords = df_new_coords [ 'x' ] self . new_y_coords = df_new_coords [ 'y' ] self . new_grid_fp = new_grid_fp return def reproject ( self , native_fp , reproj_library = 'pyresample' ): if reproj_library == 'pyinterp' : ds_reproj = full_scene_pyinterp ( native_fp , self . new_x_coords , self . new_y_coords , self . new_grid_fp ) elif reproj_library == 'pyresample' : ds_reproj = full_scene_pyresample ( native_fp ) else : raise ValueError ( f '`reproj_library` must be one of: pyresample, pyinterp. { reproj_library } can not be passed.' ) return ds_reproj new_coords_fp = f ' { intermediate_data_dir } /reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = Reprojector ( new_coords_fp , new_grid_fp ) reprojector <__main__.Reprojector at 0x7fef0e0f3e50> %% capture -- no - stdout %% timeit # in case pyinterp is not available: try : ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) except : pass 976 ms \u00c2\u00b1 28.5 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout %% timeit reprojector = Reprojector () ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) 3.62 s \u00c2\u00b1 35.6 ms per loop (mean \u00c2\u00b1 std. dev. of 7 runs, 1 loop each) %% capture -- no - stdout ds_reproj = reprojector . reproject ( native_fp ) # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'Greys_r' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7feffff382b0>","title":"Comparing Reprojection Libraries"},{"location":"03_zarr/","text":"Zarr \u00b6 Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 2.10rows/s] import os import dotenv import matplotlib.pyplot as plt import cartopy.crs as ccrs from IPython.display import JSON User Inputs \u00b6 data_dir = '../data/raw' metadata_db_fp = '../data/EUMETSAT_metadata.db' debug_fp = '../logs/EUMETSAT_download.txt' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' new_coords_fp = '../data/intermediate/reproj_coords_TM_4km.csv' in_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr' out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16' Loading Environment Variables \u00b6 dotenv . load_dotenv ( '../.env' ) user_key = os . environ . get ( 'USER_KEY' ) user_secret = os . environ . get ( 'USER_SECRET' ) slack_id = os . environ . get ( 'SLACK_ID' ) slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ) Preparing Data to Save to Zarr \u00b6 We'll start by loading in one of the datasets we've just downloaded, in this instance we'll take the most recent one by identifying it from the metadata db. dm = eumetsat . DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp ) df_metadata = dm . get_df_metadata () df_metadata . tail () 2021-01-08 09:43:50,879 - INFO - ********** Download Manager Initialised ************** .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } start_date end_date result_time platform_short_name platform_orbit_type instrument_name sensor_op_mode center_srs_name center_position file_name file_size missing_pct downloaded id 332 2020-01-01 00:00:07.683 2020-01-01 00:04:14.102 2020-01-01 00:04:14.102 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101000414.1020000... 99819 0.0 2021-01-07 20:39:02.727875 333 2020-01-01 00:05:08.795 2020-01-01 00:09:15.215 2020-01-01 00:09:15.215 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101000915.2150000... 99819 0.0 2021-01-07 20:40:35.463153 334 2020-01-01 00:10:09.908 2020-01-01 00:14:16.328 2020-01-01 00:14:16.328 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101001416.3280000... 99819 0.0 2021-01-07 20:42:01.806167 335 2020-01-01 00:15:11.021 2020-01-01 00:19:17.440 2020-01-01 00:19:17.440 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101001917.4400000... 99819 0.0 2021-01-07 20:42:42.769446 336 2021-01-07 20:50:09.828 2021-01-07 20:54:16.209 2021-01-07 20:54:16.209 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210107205416.2090000... 99819 0.0 2021-01-07 21:37:09.110106 We'll then load in the file filename = df_metadata . loc [ df_metadata . index [ - 2 ], 'file_name' ] native_fp = f ' { data_dir } / { filename } .nat' severi_area_def = reproj . get_seviri_area_def ( native_fp ) seviri_crs = severi_area_def . to_cartopy_crs () scene = reproj . load_scene ( native_fp ) scene . load ([ 'HRV' ]) /Users/laurence/software/anaconda3/envs/satip_dev/lib/python3.8/site-packages/pyproj/crs/crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() /Users/laurence/software/anaconda3/envs/satip_dev/lib/python3.8/site-packages/pyproj/crs/crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() And visualise it to test that everything is working fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fdf79164ca0> We now need to reproject it %% capture -- no - stdout %% time reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) CPU times: user 4.79 s, sys: 356 ms, total: 5.14 s Wall time: 5.41 s Which again we'll check through visualisation fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-12-53f177b0781d>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) /Users/laurence/software/anaconda3/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) /Users/laurence/software/anaconda3/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fdf55fddf70> Compressing \u00b6 We'll now develop our compressor class that will reduce the size of the datasets that we save to Zarr, in this instance we'll normalize the data and transform it to Int16. This has been found to reduce the size by ~50%. #exports def add_constant_coord_to_da ( da , coord_name , coord_val ): \"\"\" Adds a new coordinate with a constant value to the DataArray Parameters ---------- da : xr.DataArray DataArrray which will have the new coords added to it coord_name : str Name for the new coordinate dimensions coord_val Value that will be assigned to the new coordinates Returns ------- da : xr.DataArray DataArrray with the new coords added to it \"\"\" da = ( da . assign_coords ({ coord_name : coord_val }) . expand_dims ( coord_name ) ) return da class Compressor : def __init__ ( self , bits_per_pixel = 10 , mins = np . array ([ - 1.2278595 , - 2.5118103 , - 64.83977 , 63.404694 , 2.844452 , 199.10002 , - 17.254883 , - 26.29155 , - 1.1009827 , - 2.4184198 , 199.57048 , 198.95093 ]), maxs = np . array ([ 103.90016 , 69.60857 , 339.15588 , 340.26526 , 317.86752 , 313.2767 , 315.99194 , 274.82297 , 93.786545 , 101.34922 , 249.91806 , 286.96323 ]), variable_order = [ 'HRV' , 'IR_016' , 'IR_039' , 'IR_087' , 'IR_097' , 'IR_108' , 'IR_120' , 'IR_134' , 'VIS006' , 'VIS008' , 'WV_062' , 'WV_073' ] ): locals_ = locals () attrs_to_add = [ 'bits_per_pixel' , 'mins' , 'maxs' , 'variable_order' ] for attr in attrs_to_add : setattr ( self , attr , locals_ [ attr ]) return def fit ( self , da , dims = [ 'time' , 'y' , 'x' ]): self . mins = da . min ( dims ) . compute () self . maxs = da . max ( dims ) . compute () self . variable_order = da . coords [ 'variable' ] . values print ( f 'The mins are: { self . mins } ' ) print ( f 'The maxs are: { self . maxs } ' ) print ( f 'The variable order is: { self . variable_order } ' ) return def compress ( self , da ): da_meta = da . attrs for attr in [ 'mins' , 'maxs' ]: assert getattr ( self , attr ) is not None , f ' { attr } must be set in initialisation or through `fit`' if 'time' not in da . dims : time = pd . to_datetime ( da_meta [ 'end_time' ]) da = add_constant_coord_to_da ( da , 'time' , time ) da = ( da . reindex ({ 'variable' : self . variable_order }) . transpose ( 'time' , 'y' , 'x' , 'variable' ) ) upper_bound = ( 2 ** self . bits_per_pixel ) - 1 new_max = self . maxs - self . mins da -= self . mins da /= new_max da *= upper_bound da = ( da . fillna ( - 1 ) . round () . astype ( np . int16 ) ) da . attrs = { 'meta' : str ( da_meta )} # Must be serialisable return da %% time compressor = Compressor () da_compressed = compressor . compress ( ds_reproj [ 'stacked_eumetsat_data' ]) CPU times: user 20.5 ms, sys: 1.85 ms, total: 22.3 ms Wall time: 21.2 ms Saving to Zarr \u00b6 We'll now create a helper function for saving the data-array to a zarr database # exports get_time_as_unix = lambda da : pd . Series (( pd . to_datetime ( da . time . values ) - pd . Timestamp ( '1970-01-01' )) . total_seconds ()) . astype ( int ) . values def save_da_to_zarr ( da , zarr_bucket , dim_order = [ 'time' , 'x' , 'y' , 'variable' ], zarr_mode = 'a' ): da = da . transpose ( * dim_order ) da [ 'time' ] = get_time_as_unix ( da ) _ , y_size , x_size , _ = da . shape out_store = gcsfs . GCSMap ( root = zarr_bucket , gcs = gcsfs . GCSFileSystem ()) chunks = ( 36 , y_size , x_size , 1 ) ds = xr . Dataset ({ 'stacked_eumetsat_data' : da . chunk ( chunks )}) zarr_mode_to_extra_kwargs = { 'a' : { 'append_dim' : 'time' }, 'w' : { 'encoding' : { 'stacked_eumetsat_data' : { 'compressor' : numcodecs . Blosc ( cname = 'zstd' , clevel = 5 ), 'chunks' : chunks } } } } assert zarr_mode in [ 'a' , 'w' ], '`zarr_mode` must be one of: `a`, `w`' extra_kwargs = zarr_mode_to_extra_kwargs [ zarr_mode ] ds . to_zarr ( out_store , mode = zarr_mode , consolidated = True , ** extra_kwargs ) return ds Now we can save it! save_data = False if save_data == True : out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16' ds = save_da_to_zarr ( da_compressed , out_zarr_bucket , zarr_mode = 'w' ) Loading Zarr Data \u00b6 We'll start by defining a loading function and a replacement for the standard gcsfs.utils is_retriable function We'll now read it in %% time loaded_xarray = load_from_zarr_bucket ( out_zarr_bucket ) loaded_xarray . time . compute () CPU times: user 760 ms, sys: 73.8 ms, total: 834 ms Wall time: 3.56 s /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'time' (time: 781)> array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', ..., '2021-01-08T01:19:16.000000000', '2021-01-08T01:24:16.000000000', '2021-01-08T01:29:15.000000000'], dtype='datetime64[ns]') Coordinates: * time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-08T01:29:15 xarray.DataArray 'time' time : 781 2020-12-16T18:40:08 2021-01-07T12:04:16 ... 2021-01-08T01:29:15 array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', ..., '2021-01-08T01:19:16.000000000', '2021-01-08T01:24:16.000000000', '2021-01-08T01:29:15.000000000'], dtype='datetime64[ns]') Coordinates: (1) time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-... array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', ..., '2021-01-08T01:19:16.000000000', '2021-01-08T01:24:16.000000000', '2021-01-08T01:29:15.000000000'], dtype='datetime64[ns]') Attributes: (0) And finally we can plot the results fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) loaded_xarray [ 'stacked_eumetsat_data' ] . isel ( variable = 0 , time = 0 ) . T . plot ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-19-f7e189d5f897>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fdf4185de80> We can also identify missing datasets which will be useful for filling them in later #exports def identifying_missing_datasets ( start_date = '' , end_date = '' , eumetsat_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16' ): # Identifying date range if not fully provided if ( start_date == '' ) or ( end_date == '' ): ds_eumetsat = load_from_zarr_bucket ( eumetsat_zarr_bucket ) start_date = ds_eumetsat . time . min () . values end_date = ds_eumetsat . time . max () . values print ( f 'Earliest { start_date } , latest { end_date } ' ) # have to loop this by month for the API month_split = pd . date_range ( \"2020-01-01T00:09:15.000000000\" , \"2021-01-08T01:29:15.000000000\" , freq = \"M\" ) missing_datasets = [] for i in track ( range ( len ( month_split ) - 1 )): # Identifying all potential datasets over specified date range datasets = eumetsat . identify_available_datasets ( month_split [ i ], month_split [ i + 1 ]) # Extracting the datetime each dataset was finished end_dates = [ dataset [ 'properties' ][ 'date' ] . split ( '/' )[ - 1 ] for dataset in datasets ] cleaned_end_dates = pd . to_datetime ( end_dates ) . floor ( freq = 's' ) . tz_convert ( None ) # Identifying missing datasets from the Zarr DB ds_eumetsat = load_from_zarr_bucket ( eumetsat_zarr_bucket ) end_dates_to_datasets = dict ( zip ( cleaned_end_dates , datasets )) missing_dates = set ( cleaned_end_dates ) - set ( pd . to_datetime ( ds_eumetsat . time . values )) missing_datasets . append ([ data for date , data in end_dates_to_datasets . items () if date in missing_dates ]) return missing_datasets missing_datasets = identifying_missing_datasets () JSON ( missing_datasets ) Earliest 2020-01-01T00:09:15.000000000, latest 2021-01-08T01:29:15.000000000 27% 3/11 [00:18 < 00:06, 6.02s/it] JSON ( missing_datasets )","title":"Saving with Zarr"},{"location":"03_zarr/#zarr","text":"Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 2.10rows/s] import os import dotenv import matplotlib.pyplot as plt import cartopy.crs as ccrs from IPython.display import JSON","title":"Zarr"},{"location":"03_zarr/#user-inputs","text":"data_dir = '../data/raw' metadata_db_fp = '../data/EUMETSAT_metadata.db' debug_fp = '../logs/EUMETSAT_download.txt' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' new_coords_fp = '../data/intermediate/reproj_coords_TM_4km.csv' in_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr' out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16'","title":"User Inputs"},{"location":"03_zarr/#loading-environment-variables","text":"dotenv . load_dotenv ( '../.env' ) user_key = os . environ . get ( 'USER_KEY' ) user_secret = os . environ . get ( 'USER_SECRET' ) slack_id = os . environ . get ( 'SLACK_ID' ) slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' )","title":"Loading Environment Variables"},{"location":"03_zarr/#preparing-data-to-save-to-zarr","text":"We'll start by loading in one of the datasets we've just downloaded, in this instance we'll take the most recent one by identifying it from the metadata db. dm = eumetsat . DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp ) df_metadata = dm . get_df_metadata () df_metadata . tail () 2021-01-08 09:43:50,879 - INFO - ********** Download Manager Initialised ************** .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } start_date end_date result_time platform_short_name platform_orbit_type instrument_name sensor_op_mode center_srs_name center_position file_name file_size missing_pct downloaded id 332 2020-01-01 00:00:07.683 2020-01-01 00:04:14.102 2020-01-01 00:04:14.102 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101000414.1020000... 99819 0.0 2021-01-07 20:39:02.727875 333 2020-01-01 00:05:08.795 2020-01-01 00:09:15.215 2020-01-01 00:09:15.215 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101000915.2150000... 99819 0.0 2021-01-07 20:40:35.463153 334 2020-01-01 00:10:09.908 2020-01-01 00:14:16.328 2020-01-01 00:14:16.328 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101001416.3280000... 99819 0.0 2021-01-07 20:42:01.806167 335 2020-01-01 00:15:11.021 2020-01-01 00:19:17.440 2020-01-01 00:19:17.440 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101001917.4400000... 99819 0.0 2021-01-07 20:42:42.769446 336 2021-01-07 20:50:09.828 2021-01-07 20:54:16.209 2021-01-07 20:54:16.209 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20210107205416.2090000... 99819 0.0 2021-01-07 21:37:09.110106 We'll then load in the file filename = df_metadata . loc [ df_metadata . index [ - 2 ], 'file_name' ] native_fp = f ' { data_dir } / { filename } .nat' severi_area_def = reproj . get_seviri_area_def ( native_fp ) seviri_crs = severi_area_def . to_cartopy_crs () scene = reproj . load_scene ( native_fp ) scene . load ([ 'HRV' ]) /Users/laurence/software/anaconda3/envs/satip_dev/lib/python3.8/site-packages/pyproj/crs/crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() /Users/laurence/software/anaconda3/envs/satip_dev/lib/python3.8/site-packages/pyproj/crs/crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() And visualise it to test that everything is working fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fdf79164ca0> We now need to reproject it %% capture -- no - stdout %% time reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyresample' ) CPU times: user 4.79 s, sys: 356 ms, total: 5.14 s Wall time: 5.41 s Which again we'll check through visualisation fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) ds_reproj [ 'stacked_eumetsat_data' ] . sel ( variable = 'HRV' ) . plot . imshow ( ax = ax , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-12-53f177b0781d>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) /Users/laurence/software/anaconda3/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in cos return func(*(_execute_task(a, cache) for a in args)) /Users/laurence/software/anaconda3/envs/satip_dev/lib/python3.8/site-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in sin return func(*(_execute_task(a, cache) for a in args)) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fdf55fddf70>","title":"Preparing Data to Save to Zarr"},{"location":"03_zarr/#compressing","text":"We'll now develop our compressor class that will reduce the size of the datasets that we save to Zarr, in this instance we'll normalize the data and transform it to Int16. This has been found to reduce the size by ~50%. #exports def add_constant_coord_to_da ( da , coord_name , coord_val ): \"\"\" Adds a new coordinate with a constant value to the DataArray Parameters ---------- da : xr.DataArray DataArrray which will have the new coords added to it coord_name : str Name for the new coordinate dimensions coord_val Value that will be assigned to the new coordinates Returns ------- da : xr.DataArray DataArrray with the new coords added to it \"\"\" da = ( da . assign_coords ({ coord_name : coord_val }) . expand_dims ( coord_name ) ) return da class Compressor : def __init__ ( self , bits_per_pixel = 10 , mins = np . array ([ - 1.2278595 , - 2.5118103 , - 64.83977 , 63.404694 , 2.844452 , 199.10002 , - 17.254883 , - 26.29155 , - 1.1009827 , - 2.4184198 , 199.57048 , 198.95093 ]), maxs = np . array ([ 103.90016 , 69.60857 , 339.15588 , 340.26526 , 317.86752 , 313.2767 , 315.99194 , 274.82297 , 93.786545 , 101.34922 , 249.91806 , 286.96323 ]), variable_order = [ 'HRV' , 'IR_016' , 'IR_039' , 'IR_087' , 'IR_097' , 'IR_108' , 'IR_120' , 'IR_134' , 'VIS006' , 'VIS008' , 'WV_062' , 'WV_073' ] ): locals_ = locals () attrs_to_add = [ 'bits_per_pixel' , 'mins' , 'maxs' , 'variable_order' ] for attr in attrs_to_add : setattr ( self , attr , locals_ [ attr ]) return def fit ( self , da , dims = [ 'time' , 'y' , 'x' ]): self . mins = da . min ( dims ) . compute () self . maxs = da . max ( dims ) . compute () self . variable_order = da . coords [ 'variable' ] . values print ( f 'The mins are: { self . mins } ' ) print ( f 'The maxs are: { self . maxs } ' ) print ( f 'The variable order is: { self . variable_order } ' ) return def compress ( self , da ): da_meta = da . attrs for attr in [ 'mins' , 'maxs' ]: assert getattr ( self , attr ) is not None , f ' { attr } must be set in initialisation or through `fit`' if 'time' not in da . dims : time = pd . to_datetime ( da_meta [ 'end_time' ]) da = add_constant_coord_to_da ( da , 'time' , time ) da = ( da . reindex ({ 'variable' : self . variable_order }) . transpose ( 'time' , 'y' , 'x' , 'variable' ) ) upper_bound = ( 2 ** self . bits_per_pixel ) - 1 new_max = self . maxs - self . mins da -= self . mins da /= new_max da *= upper_bound da = ( da . fillna ( - 1 ) . round () . astype ( np . int16 ) ) da . attrs = { 'meta' : str ( da_meta )} # Must be serialisable return da %% time compressor = Compressor () da_compressed = compressor . compress ( ds_reproj [ 'stacked_eumetsat_data' ]) CPU times: user 20.5 ms, sys: 1.85 ms, total: 22.3 ms Wall time: 21.2 ms","title":"Compressing"},{"location":"03_zarr/#saving-to-zarr","text":"We'll now create a helper function for saving the data-array to a zarr database # exports get_time_as_unix = lambda da : pd . Series (( pd . to_datetime ( da . time . values ) - pd . Timestamp ( '1970-01-01' )) . total_seconds ()) . astype ( int ) . values def save_da_to_zarr ( da , zarr_bucket , dim_order = [ 'time' , 'x' , 'y' , 'variable' ], zarr_mode = 'a' ): da = da . transpose ( * dim_order ) da [ 'time' ] = get_time_as_unix ( da ) _ , y_size , x_size , _ = da . shape out_store = gcsfs . GCSMap ( root = zarr_bucket , gcs = gcsfs . GCSFileSystem ()) chunks = ( 36 , y_size , x_size , 1 ) ds = xr . Dataset ({ 'stacked_eumetsat_data' : da . chunk ( chunks )}) zarr_mode_to_extra_kwargs = { 'a' : { 'append_dim' : 'time' }, 'w' : { 'encoding' : { 'stacked_eumetsat_data' : { 'compressor' : numcodecs . Blosc ( cname = 'zstd' , clevel = 5 ), 'chunks' : chunks } } } } assert zarr_mode in [ 'a' , 'w' ], '`zarr_mode` must be one of: `a`, `w`' extra_kwargs = zarr_mode_to_extra_kwargs [ zarr_mode ] ds . to_zarr ( out_store , mode = zarr_mode , consolidated = True , ** extra_kwargs ) return ds Now we can save it! save_data = False if save_data == True : out_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16' ds = save_da_to_zarr ( da_compressed , out_zarr_bucket , zarr_mode = 'w' )","title":"Saving to Zarr"},{"location":"03_zarr/#loading-zarr-data","text":"We'll start by defining a loading function and a replacement for the standard gcsfs.utils is_retriable function We'll now read it in %% time loaded_xarray = load_from_zarr_bucket ( out_zarr_bucket ) loaded_xarray . time . compute () CPU times: user 760 ms, sys: 73.8 ms, total: 834 ms Wall time: 3.56 s /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'time' (time: 781)> array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', ..., '2021-01-08T01:19:16.000000000', '2021-01-08T01:24:16.000000000', '2021-01-08T01:29:15.000000000'], dtype='datetime64[ns]') Coordinates: * time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-08T01:29:15 xarray.DataArray 'time' time : 781 2020-12-16T18:40:08 2021-01-07T12:04:16 ... 2021-01-08T01:29:15 array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', ..., '2021-01-08T01:19:16.000000000', '2021-01-08T01:24:16.000000000', '2021-01-08T01:29:15.000000000'], dtype='datetime64[ns]') Coordinates: (1) time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-... array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', ..., '2021-01-08T01:19:16.000000000', '2021-01-08T01:24:16.000000000', '2021-01-08T01:29:15.000000000'], dtype='datetime64[ns]') Attributes: (0) And finally we can plot the results fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) loaded_xarray [ 'stacked_eumetsat_data' ] . isel ( variable = 0 , time = 0 ) . T . plot ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-19-f7e189d5f897>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x7fdf4185de80> We can also identify missing datasets which will be useful for filling them in later #exports def identifying_missing_datasets ( start_date = '' , end_date = '' , eumetsat_zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16' ): # Identifying date range if not fully provided if ( start_date == '' ) or ( end_date == '' ): ds_eumetsat = load_from_zarr_bucket ( eumetsat_zarr_bucket ) start_date = ds_eumetsat . time . min () . values end_date = ds_eumetsat . time . max () . values print ( f 'Earliest { start_date } , latest { end_date } ' ) # have to loop this by month for the API month_split = pd . date_range ( \"2020-01-01T00:09:15.000000000\" , \"2021-01-08T01:29:15.000000000\" , freq = \"M\" ) missing_datasets = [] for i in track ( range ( len ( month_split ) - 1 )): # Identifying all potential datasets over specified date range datasets = eumetsat . identify_available_datasets ( month_split [ i ], month_split [ i + 1 ]) # Extracting the datetime each dataset was finished end_dates = [ dataset [ 'properties' ][ 'date' ] . split ( '/' )[ - 1 ] for dataset in datasets ] cleaned_end_dates = pd . to_datetime ( end_dates ) . floor ( freq = 's' ) . tz_convert ( None ) # Identifying missing datasets from the Zarr DB ds_eumetsat = load_from_zarr_bucket ( eumetsat_zarr_bucket ) end_dates_to_datasets = dict ( zip ( cleaned_end_dates , datasets )) missing_dates = set ( cleaned_end_dates ) - set ( pd . to_datetime ( ds_eumetsat . time . values )) missing_datasets . append ([ data for date , data in end_dates_to_datasets . items () if date in missing_dates ]) return missing_datasets missing_datasets = identifying_missing_datasets () JSON ( missing_datasets ) Earliest 2020-01-01T00:09:15.000000000, latest 2021-01-08T01:29:15.000000000 27% 3/11 [00:18 < 00:06, 6.02s/it] JSON ( missing_datasets )","title":"Loading Zarr Data"},{"location":"04_gcp/","text":"EUMETSAT and Google Cloud Platform (GCP) \u00b6 Setup \u00b6 GCP Helpers \u00b6 First need a couple of helper functions to work with Google Cloud Platform. Ideally the principles will transfer easily to other cloud providers if necessary. First we want to be able to list files ('blobs') in a Google Cloud storage bucket, and get the metadata for a specific file ('blob'). We also want to be able to upload a file ('blob') to a storage bucket in an efficient way. Checking existing saved data in Google Cloud Storage \u00b6 Finding out how much data has been downloaded for different years in the OCF native data bucket. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2019/01/01\" blobs = list_blobs_with_prefix ( BUCKET_NAME , prefix = PREFIX ) print ( f 'There are { len ( blobs ) } files' ) There are 277 files Lets see how large the data for the whole of 2018 is - this may take a few minutes to run. storage_client = storage . Client () PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2018/\" # Note: Client.list_blobs requires at least package version 1.17.0. blobs_ = storage_client . list_blobs ( BUCKET_NAME , prefix = PREFIX ) sizes = [] for blob in blobs_ : sizes . append ( blob . size ) sum ( sizes ) / 1e9 2443.493799523 2018 contains 2.4TB of data Note that using the storage client to return blobs returns an iterable of blob metadata objects. From those we've extracted the names. We can go backwards from the names to interact with the blobs. df = pd . DataFrame ( blobs , columns = [ 'blobs' ]) df = df [ df [ 'blobs' ] . str . endswith ( '.nat.bz2' )] # only compressed data files df [ 'datetime' ] = pd . to_datetime ( df [ 'blobs' ] . str . slice ( start = 37 , stop = 53 ), format = \"%Y/%m/ %d /%H/%M\" ) It is helpful to see by month how many data files already exist as compressed .nat files. Note that this is not looking at files reprojected and stored in the Zarr database. months_in_order = [ 'January' , 'February' , 'March' , 'April' , 'May' , 'June' , 'July' , 'August' , 'September' , 'October' , 'November' , 'December' ] blobs_by_month = df \\ . assign ( year = lambda x : x [ 'datetime' ] . dt . year ) \\ . assign ( month = lambda x : x [ 'datetime' ] . dt . month_name ()) \\ . groupby ([ 'month' , 'year' ]) . count ()[ 'blobs' ] . to_frame () \\ . reset_index () \\ . pivot ( index = 'month' , columns = 'year' , values = 'blobs' ) \\ . reindex ( months_in_order ) blobs_by_month .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year 2019 month January 276.0 February NaN March NaN April NaN May NaN June NaN July NaN August NaN September NaN October NaN November NaN December NaN And lets plot this # credit: https://dfrieds.com/data-visualizations/visualize-historical-time-comparisons.html figure , axes = plt . subplots ( figsize = ( 10 , 11 )) sns . heatmap ( blobs_by_month , annot = True , linewidths =. 5 , ax = axes , cmap = \"Greys\" ) axes . axes . set_title ( \"Count of .nat.bz files in Storage by Month and Year\" , fontsize = 20 , y = 1.01 ) axes . axes . set_ylabel ( \"month\" , labelpad = 50 , rotation = 0 ) axes . axes . set_xlabel ( \"year\" , labelpad = 16 ); plt . yticks ( rotation = 0 ); Sometimes we'll want all of the original (uncompressed) filenames - for example to compare with the results of the EUMETSAT API so we can work out whether we should request a file or not. We'll make a function to get original filenames from compressed or uncompressed files stored as blobs on GCP. filenames = df [ 'blobs' ] . str . split ( '/' ) . str [ - 1 ] . str . replace ( '.bz2' , '' ) PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2019/10/01\" filenames = get_eumetsat_filenames ( BUCKET_NAME , prefix = PREFIX ) len ( filenames ) 68202 Write metadata to bigquery \u00b6 For cloud storage functions, storing metadata in a RDBS seems useful. BigQuery is a low hassle way to achieve this and can scale to lots of data with ease. Downsides are rather inflexible migrations and updates. # write_metadata_to_gcp(df, 'test', 'solar-pv-nowcasting') As well as writing to BigQuery, we also want to query it. We'll write a small wrapper that allows us to send any SQL query and get results as a pandas DataFrame. Naturally we need to know the GCP project id, and the BigQuery table name. Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.30rows/s] '2020-12-03 19:14'","title":"GCP Analytics"},{"location":"04_gcp/#eumetsat-and-google-cloud-platform-gcp","text":"","title":"EUMETSAT and Google Cloud Platform (GCP)"},{"location":"04_gcp/#setup","text":"","title":"Setup"},{"location":"04_gcp/#gcp-helpers","text":"First need a couple of helper functions to work with Google Cloud Platform. Ideally the principles will transfer easily to other cloud providers if necessary. First we want to be able to list files ('blobs') in a Google Cloud storage bucket, and get the metadata for a specific file ('blob'). We also want to be able to upload a file ('blob') to a storage bucket in an efficient way.","title":"GCP Helpers"},{"location":"04_gcp/#checking-existing-saved-data-in-google-cloud-storage","text":"Finding out how much data has been downloaded for different years in the OCF native data bucket. BUCKET_NAME = \"solar-pv-nowcasting-data\" PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2019/01/01\" blobs = list_blobs_with_prefix ( BUCKET_NAME , prefix = PREFIX ) print ( f 'There are { len ( blobs ) } files' ) There are 277 files Lets see how large the data for the whole of 2018 is - this may take a few minutes to run. storage_client = storage . Client () PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2018/\" # Note: Client.list_blobs requires at least package version 1.17.0. blobs_ = storage_client . list_blobs ( BUCKET_NAME , prefix = PREFIX ) sizes = [] for blob in blobs_ : sizes . append ( blob . size ) sum ( sizes ) / 1e9 2443.493799523 2018 contains 2.4TB of data Note that using the storage client to return blobs returns an iterable of blob metadata objects. From those we've extracted the names. We can go backwards from the names to interact with the blobs. df = pd . DataFrame ( blobs , columns = [ 'blobs' ]) df = df [ df [ 'blobs' ] . str . endswith ( '.nat.bz2' )] # only compressed data files df [ 'datetime' ] = pd . to_datetime ( df [ 'blobs' ] . str . slice ( start = 37 , stop = 53 ), format = \"%Y/%m/ %d /%H/%M\" ) It is helpful to see by month how many data files already exist as compressed .nat files. Note that this is not looking at files reprojected and stored in the Zarr database. months_in_order = [ 'January' , 'February' , 'March' , 'April' , 'May' , 'June' , 'July' , 'August' , 'September' , 'October' , 'November' , 'December' ] blobs_by_month = df \\ . assign ( year = lambda x : x [ 'datetime' ] . dt . year ) \\ . assign ( month = lambda x : x [ 'datetime' ] . dt . month_name ()) \\ . groupby ([ 'month' , 'year' ]) . count ()[ 'blobs' ] . to_frame () \\ . reset_index () \\ . pivot ( index = 'month' , columns = 'year' , values = 'blobs' ) \\ . reindex ( months_in_order ) blobs_by_month .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year 2019 month January 276.0 February NaN March NaN April NaN May NaN June NaN July NaN August NaN September NaN October NaN November NaN December NaN And lets plot this # credit: https://dfrieds.com/data-visualizations/visualize-historical-time-comparisons.html figure , axes = plt . subplots ( figsize = ( 10 , 11 )) sns . heatmap ( blobs_by_month , annot = True , linewidths =. 5 , ax = axes , cmap = \"Greys\" ) axes . axes . set_title ( \"Count of .nat.bz files in Storage by Month and Year\" , fontsize = 20 , y = 1.01 ) axes . axes . set_ylabel ( \"month\" , labelpad = 50 , rotation = 0 ) axes . axes . set_xlabel ( \"year\" , labelpad = 16 ); plt . yticks ( rotation = 0 ); Sometimes we'll want all of the original (uncompressed) filenames - for example to compare with the results of the EUMETSAT API so we can work out whether we should request a file or not. We'll make a function to get original filenames from compressed or uncompressed files stored as blobs on GCP. filenames = df [ 'blobs' ] . str . split ( '/' ) . str [ - 1 ] . str . replace ( '.bz2' , '' ) PREFIX = \"satellite/EUMETSAT/SEVIRI_RSS/native/2019/10/01\" filenames = get_eumetsat_filenames ( BUCKET_NAME , prefix = PREFIX ) len ( filenames ) 68202","title":"Checking existing saved data in Google Cloud Storage"},{"location":"04_gcp/#write-metadata-to-bigquery","text":"For cloud storage functions, storing metadata in a RDBS seems useful. BigQuery is a low hassle way to achieve this and can scale to lots of data with ease. Downsides are rather inflexible migrations and updates. # write_metadata_to_gcp(df, 'test', 'solar-pv-nowcasting') As well as writing to BigQuery, we also want to query it. We'll write a small wrapper that allows us to send any SQL query and get results as a pandas DataFrame. Naturally we need to know the GCP project id, and the BigQuery table name. Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.30rows/s] '2020-12-03 19:14'","title":"Write metadata to bigquery"},{"location":"05_pipeline/","text":"End-to-End Pipeline \u00b6 #exports import pandas as pd import xarray as xr from satip import eumetsat , reproj , io , gcp_helpers from dagster import execute_pipeline , pipeline , solid , Field import os import glob import dotenv import warnings C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.46rows/s] Log Cleaning \u00b6 We'll suppress some errors/warnings to make the logs easier to parse #exports warnings . filterwarnings ( 'ignore' , message = 'divide by zero encountered in true_divide' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in sin' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in cos' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in subtract' ) warnings . filterwarnings ( 'ignore' , message = 'You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems' ) Dagster Pipeline \u00b6 We're now going to combine these steps into a pipeline using dagster , first we'll create the individual components. #exports @solid () def download_eumetsat_files ( context , env_vars_fp : str , data_dir : str , metadata_db_fp : str , debug_fp : str , table_id : str , project_id : str , start_date : str = '' , end_date : str = '' , max_mins : int = 60 ): _ = dotenv . load_dotenv ( env_vars_fp ) if start_date == '' : sql_query = f 'select * from { table_id } where result_time = (select max(result_time) from { table_id } )' latest_saved_date = gcp_helpers . query ( sql_query , project_id )[ 'result_time' ] . iloc [ 0 ] . tz_localize ( None ) earliest_start_date = pd . Timestamp . now () - pd . Timedelta ( max_mins , unit = 'minutes' ) start_date = max ( earliest_start_date , latest_saved_date ) . strftime ( '%Y-%m- %d %H:%M' ) if end_date == '' : end_date = pd . Timestamp . now () . strftime ( '%Y-%m- %d %H:%M' ) context . log . info ( f 'Querying data between { start_date } - { end_date } ' ) dm = eumetsat . DownloadManager ( os . environ . get ( 'USER_KEY' ), os . environ . get ( 'USER_SECRET' ), data_dir , metadata_db_fp , debug_fp , slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ), slack_id = os . environ . get ( 'SLACK_ID' )) df_new_metadata = dm . download_date_range ( start_date , end_date ) if df_new_metadata is None : df_new_metadata = pd . DataFrame ( columns = [ 'result_time' , 'file_name' ]) else : df_new_metadata = df_new_metadata . iloc [ 1 :] # the first entry is the last one we downloaded return df_new_metadata @solid () def df_metadata_to_dt_to_fp_map ( _ , df_new_metadata , data_dir : str ) -> dict : \"\"\" Here we'll then identify downloaded files in the metadata dataframe and return a mapping between datetimes and filenames \"\"\" datetime_to_filename = ( df_new_metadata . set_index ( 'result_time' ) [ 'file_name' ] . drop_duplicates () . to_dict () ) datetime_to_filepath = { datetime : f \" { data_dir } / { filename } .nat\" for datetime , filename in datetime_to_filename . items () if filename != {} } return datetime_to_filepath @solid () def reproject_datasets ( _ , datetime_to_filepath : dict , new_coords_fp : str , new_grid_fp : str ): reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) reprojected_dss = [ ( reprojector . reproject ( filepath , reproj_library = 'pyresample' ) . pipe ( io . add_constant_coord_to_da , 'time' , pd . to_datetime ( datetime )) ) for datetime , filepath in datetime_to_filepath . items () ] if len ( reprojected_dss ) > 0 : ds_combined_reproj = xr . concat ( reprojected_dss , 'time' , coords = 'all' , data_vars = 'all' ) return ds_combined_reproj else : return xr . Dataset () @solid () def compress_and_save_datasets ( _ , ds_combined_reproj , zarr_bucket : str , var_name : str = 'stacked_eumetsat_data' ): # Handle case where no new data exists if len ( ds_combined_reproj . dims ) == 0 : return # Compressing the datasets compressor = io . Compressor () var_name = var_name da_compressed = compressor . compress ( ds_combined_reproj [ var_name ]) # Saving to Zarr ds_compressed = io . save_da_to_zarr ( da_compressed , zarr_bucket ) return ds_compressed @solid () def save_metadata ( context , ds_combined_compressed , df_new_metadata , table_id : str , project_id : str ): if ds_combined_compressed is not None : if df_new_metadata . shape [ 0 ] > 0 : gcp_helpers . write_metadata_to_gcp ( df_new_metadata , table_id , project_id , append = True ) context . log . info ( f ' { df_new_metadata . shape [ 0 ] } new metadata entries were added' ) else : context . log . info ( 'No metadata was available to be added' ) return True @solid () def compress_export_then_delete_raw ( context , ds_combined_compressed , data_dir : str , compressed_dir : str , BUCKET_NAME : str = 'solar-pv-nowcasting-data' , PREFIX : str = 'satellite/EUMETSAT/SEVIRI_RSS/native/' , ready_to_delete : bool = True ): if ready_to_delete == True : eumetsat . compress_downloaded_files ( data_dir = data_dir , compressed_dir = compressed_dir , log = context . log ) eumetsat . upload_compressed_files ( compressed_dir , BUCKET_NAME = BUCKET_NAME , PREFIX = PREFIX , log = None ) for dir_ in [ data_dir , compressed_dir ]: files = glob . glob ( f ' { dir_ } /*' ) for f in files : os . remove ( f ) Then we'll combine them in a pipeline #exports @pipeline def download_latest_data_pipeline (): df_new_metadata = download_eumetsat_files () datetime_to_filepath = df_metadata_to_dt_to_fp_map ( df_new_metadata ) ds_combined_reproj = reproject_datasets ( datetime_to_filepath ) ds_combined_compressed = compress_and_save_datasets ( ds_combined_reproj ) ready_to_delete = save_metadata ( ds_combined_compressed , df_new_metadata ) compress_export_then_delete_raw ( ready_to_delete ) Which we'll now run a test with run_config = { 'solids' : { 'download_eumetsat_files' : { 'inputs' : { 'env_vars_fp' : \"../.env\" , 'data_dir' : \"../data/raw\" , 'metadata_db_fp' : \"../data/EUMETSAT_metadata.db\" , 'debug_fp' : \"../logs/EUMETSAT_download.txt\" , 'table_id' : \"eumetsat.metadata\" , 'project_id' : \"solar-pv-nowcasting\" , 'start_date' : \"\" , 'end_date' : \"\" }, }, 'df_metadata_to_dt_to_fp_map' : { 'inputs' : { 'data_dir' : \"../data/raw\" } }, 'reproject_datasets' : { 'inputs' : { 'new_coords_fp' : \"../data/intermediate/reproj_coords_TM_4km.csv\" , 'new_grid_fp' : \"../data/intermediate/new_grid_4km_TM.json\" } }, 'compress_and_save_datasets' : { 'inputs' : { 'zarr_bucket' : \"solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16\" , 'var_name' : \"stacked_eumetsat_data\" } }, 'save_metadata' : { 'inputs' : { 'table_id' : \"eumetsat.metadata\" , 'project_id' : \"solar-pv-nowcasting\" }, }, 'compress_export_then_delete_raw' : { 'inputs' : { 'data_dir' : \"../data/raw\" , 'compressed_dir' : \"../data/compressed\" , 'BUCKET_NAME' : \"solar-pv-nowcasting-data\" , 'PREFIX' : \"satellite/EUMETSAT/SEVIRI_RSS/native/\" , 'ready_to_delete' : True }, } } } execute_pipeline ( download_latest_data_pipeline , run_config = run_config ) 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - ENGINE_EVENT - Starting initialization of resources [asset_store]. 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - ENGINE_EVENT - Finished initialization of resources [asset_store]. 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - PIPELINE_START - Started execution of pipeline \"download_latest_data_pipeline\". 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - ENGINE_EVENT - Executing steps in process (pid: 1108) 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_START - Started execution of step \"download_eumetsat_files.compute\". 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"env_vars_fp\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"metadata_db_fp\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"debug_fp\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"start_date\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"end_date\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"max_mins\" of type \"Int\". (Type check passed). Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 5.00rows/s] 2021-01-21 22:33:02 - dagster - INFO - system - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - download_eumetsat_files.compute - Querying data between 2021-01-21 21:33 - 2021-01-21 22:33 2021-01-21 22:33:02,396 - INFO - ********** Download Manager Initialised ************** 2021-01-21 22:33:02,869 - INFO - 11 files queried, 0 found in ../data/raw, 11 to download. 100% 11/11 [01:08 < 00:06, 6.19s/it] 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_SUCCESS - Finished execution of step \"download_eumetsat_files.compute\" in 1m10s. 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_START - Started execution of step \"df_metadata_to_dt_to_fp_map.compute\". 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle. 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed). 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_OUTPUT - Yielded output \"result\" of type \"dict\". (Type check passed). 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_SUCCESS - Finished execution of step \"df_metadata_to_dt_to_fp_map.compute\" in 15ms. 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_START - Started execution of step \"reproject_datasets.compute\". 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input datetime_to_filepath in memory object store using pickle. 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_INPUT - Got input \"datetime_to_filepath\" of type \"dict\". (Type check passed). 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_INPUT - Got input \"new_coords_fp\" of type \"String\". (Type check passed). 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_INPUT - Got input \"new_grid_fp\" of type \"String\". (Type check passed). C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_SUCCESS - Finished execution of step \"reproject_datasets.compute\" in 48.26s. 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_START - Started execution of step \"compress_and_save_datasets.compute\". 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_reproj in memory object store using pickle. 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"ds_combined_reproj\" of type \"Any\". (Type check passed). 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"zarr_bucket\" of type \"String\". (Type check passed). 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"var_name\" of type \"String\". (Type check passed). C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_SUCCESS - Finished execution of step \"compress_and_save_datasets.compute\" in 11m44s. 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_START - Started execution of step \"save_metadata.compute\". 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle. 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle. 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed). 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed). 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed). 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed). 1it [00:03, 3.73s/it] 2021-01-21 22:46:48 - dagster - INFO - system - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - save_metadata.compute - 10 new metadata entries were added 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_SUCCESS - Finished execution of step \"save_metadata.compute\" in 4.29s. 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_START - Started execution of step \"compress_export_then_delete_raw.compute\". 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle. 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"compressed_dir\" of type \"String\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"BUCKET_NAME\" of type \"String\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"PREFIX\" of type \"String\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ready_to_delete\" of type \"Bool\". (Type check passed). 2021-01-21 22:46:48 - dagster - INFO - system - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - compress_export_then_delete_raw.compute - Found 20 native files. 2021-01-21 22:46:48 - dagster - DEBUG - system - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - compress_export_then_delete_raw.compute - Compressing ../data/raw\\MSG3-SEVI-MSG15-0100-NA-20210121204918.196000000Z-NA.nat 10 rows written to BQ eumetsat.metadata, append=True Found 20 native files. 2021-01-21 22:46:49 - dagster - ERROR - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_FAILURE - Execution of step \"compress_export_then_delete_raw.compute\" failed. FileNotFoundError: [WinError 2] The system cannot find the file specified File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py\", line 180, in user_code_error_boundary yield File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py\", line 475, in _user_event_sequence_for_step_compute_fn for event in iterate_with_context(raise_interrupts_immediately, gen): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\utils\\__init__.py\", line 443, in iterate_with_context next_output = next(iterator) File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py\", line 105, in _execute_core_compute for step_output in _yield_compute_results(compute_context, inputs, compute_fn): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py\", line 76, in _yield_compute_results for event in user_event_sequence: File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\definitions\\decorators\\solid.py\", line 227, in compute result = fn(context, **kwargs) File \"<ipython-input-4-b374cee63da6>\", line 103, in compress_export_then_delete_raw eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) File \"c:\\users\\ayrto\\desktop\\freelance work\\fea\\work\\ocf\\satip\\satip\\eumetsat.py\", line 568, in compress_downloaded_files completed_process = subprocess.run(['pbzip2', '-5', full_native_filename]) File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 489, in run with Popen(*popenargs, **kwargs) as process: File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 854, in __init__ self._execute_child(args, executable, preexec_fn, close_fds, File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 1307, in _execute_child hp, ht, pid, tid = _winapi.CreateProcess(executable, args, 2021-01-21 22:46:49 - dagster - ERROR - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - PIPELINE_FAILURE - Execution of pipeline \"download_latest_data_pipeline\" failed. An exception was thrown during execution. FileNotFoundError: [WinError 2] The system cannot find the file specified File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py\", line 665, in _pipeline_execution_iterator for event in pipeline_context.executor.execute(pipeline_context, execution_plan): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\executor\\in_process.py\", line 36, in execute for event in inner_plan_execution_iterator(pipeline_context, execution_plan): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py\", line 77, in inner_plan_execution_iterator for step_event in check.generator( File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py\", line 272, in _dagster_event_sequence_for_step raise dagster_user_error.user_exception File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py\", line 180, in user_code_error_boundary yield File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py\", line 475, in _user_event_sequence_for_step_compute_fn for event in iterate_with_context(raise_interrupts_immediately, gen): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\utils\\__init__.py\", line 443, in iterate_with_context next_output = next(iterator) File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py\", line 105, in _execute_core_compute for step_output in _yield_compute_results(compute_context, inputs, compute_fn): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py\", line 76, in _yield_compute_results for event in user_event_sequence: File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\definitions\\decorators\\solid.py\", line 227, in compute result = fn(context, **kwargs) File \"<ipython-input-4-b374cee63da6>\", line 103, in compress_export_then_delete_raw eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) File \"c:\\users\\ayrto\\desktop\\freelance work\\fea\\work\\ocf\\satip\\satip\\eumetsat.py\", line 568, in compress_downloaded_files completed_process = subprocess.run(['pbzip2', '-5', full_native_filename]) File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 489, in run with Popen(*popenargs, **kwargs) as process: File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 854, in __init__ self._execute_child(args, executable, preexec_fn, close_fds, File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 1307, in _execute_child hp, ht, pid, tid = _winapi.CreateProcess(executable, args, --------------------------------------------------------------------------- DagsterExecutionStepExecutionError Traceback (most recent call last) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in _dagster_event_sequence_for_step(step_context, retries) 211 --> 212 for step_event in check.generator(step_events): 213 yield step_event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in core_dagster_event_sequence_for_step(step_context, prior_attempt_count) 285 # timer block above in order for time to be recorded accurately. --> 286 for user_event in check.generator( 287 _step_output_error_checked_user_event_sequence(step_context, user_event_sequence) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _step_output_error_checked_user_event_sequence(step_context, user_event_sequence) 58 ---> 59 for user_event in user_event_sequence: 60 if not isinstance(user_event, Output): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _user_event_sequence_for_step_compute_fn(step_context, evaluated_inputs) 475 for event in iterate_with_context(raise_interrupts_immediately, gen): --> 476 yield event 477 ~\\anaconda3\\envs\\satip_dev\\lib\\contextlib.py in __exit__(self, type, value, traceback) 130 try: --> 131 self.gen.throw(type, value, traceback) 132 except StopIteration as exc: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in user_code_error_boundary(error_cls, msg_fn, control_flow_exceptions, **kwargs) 189 # with the error reported further up the stack --> 190 raise_from( 191 error_cls(msg_fn(), user_exception=e, original_exc_info=sys.exc_info(), **kwargs), e ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\future\\utils\\__init__.py in raise_from(exc, cause) 402 execstr = \"raise __python_future_raise_from_exc from __python_future_raise_from_cause\" --> 403 exec(execstr, myglobals, mylocals) 404 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in <module> DagsterExecutionStepExecutionError: Error occurred during the execution of step: step key: \"compress_export_then_delete_raw.compute\" solid invocation: \"compress_export_then_delete_raw\" solid definition: \"compress_export_then_delete_raw\" During handling of the above exception, another exception occurred: FileNotFoundError Traceback (most recent call last) [... skipping hidden 1 frame] <ipython-input-6-7ed226242252> in <module> 49 ---> 50 execute_pipeline(download_latest_data_pipeline, run_config=run_config) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in execute_pipeline(pipeline, run_config, mode, preset, tags, solid_selection, instance, raise_on_error) 323 with _ephemeral_instance_if_missing(instance) as execute_instance: --> 324 return _logged_execute_pipeline( 325 pipeline, ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\telemetry.py in wrap(*args, **kwargs) 88 log_action(instance=instance, action=f.__name__ + \"_started\", client_time=start_time) ---> 89 result = f(*args, **kwargs) 90 end_time = datetime.datetime.now() ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in _logged_execute_pipeline(pipeline, instance, run_config, mode, preset, tags, solid_selection, raise_on_error) 374 --> 375 return execute_run(pipeline, pipeline_run, instance, raise_on_error=raise_on_error) 376 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in execute_run(pipeline, pipeline_run, instance, raise_on_error) 176 ) --> 177 event_list = list(_execute_run_iterable) 178 pipeline_context = _execute_run_iterable.pipeline_context ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in __iter__(self) 726 if self.pipeline_context: # False if we had a pipeline init failure --> 727 for event in self.iterator( 728 execution_plan=self.execution_plan, pipeline_context=self.pipeline_context, ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in _pipeline_execution_iterator(pipeline_context, execution_plan) 664 try: --> 665 for event in pipeline_context.executor.execute(pipeline_context, execution_plan): 666 if event.is_step_failure: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\executor\\in_process.py in execute(self, pipeline_context, execution_plan) 35 with time_execution_scope() as timer_result: ---> 36 for event in inner_plan_execution_iterator(pipeline_context, execution_plan): 37 yield event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in inner_plan_execution_iterator(pipeline_context, execution_plan) 76 else: ---> 77 for step_event in check.generator( 78 _dagster_event_sequence_for_step(step_context, retries) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in _dagster_event_sequence_for_step(step_context, retries) 271 if step_context.raise_on_error: --> 272 raise dagster_user_error.user_exception 273 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in user_code_error_boundary(error_cls, msg_fn, control_flow_exceptions, **kwargs) 179 try: --> 180 yield 181 except control_flow_exceptions as cf: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _user_event_sequence_for_step_compute_fn(step_context, evaluated_inputs) 474 # Allow interrupts again during each step of the execution --> 475 for event in iterate_with_context(raise_interrupts_immediately, gen): 476 yield event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\utils\\__init__.py in iterate_with_context(context_manager_class, iterator) 442 try: --> 443 next_output = next(iterator) 444 except StopIteration: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py in _execute_core_compute(compute_context, inputs, compute_fn) 104 all_results = [] --> 105 for step_output in _yield_compute_results(compute_context, inputs, compute_fn): 106 yield step_output ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py in _yield_compute_results(compute_context, inputs, compute_fn) 75 ---> 76 for event in user_event_sequence: 77 if isinstance(event, (Output, AssetMaterialization, Materialization, ExpectationResult)): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\definitions\\decorators\\solid.py in compute(context, input_defs) 226 --> 227 result = fn(context, **kwargs) 228 <ipython-input-4-b374cee63da6> in compress_export_then_delete_raw(context, ds_combined_compressed, data_dir, compressed_dir, BUCKET_NAME, PREFIX, ready_to_delete) 102 if ready_to_delete == True: --> 103 eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) 104 eumetsat.upload_compressed_files(compressed_dir, BUCKET_NAME=BUCKET_NAME, PREFIX=PREFIX, log=None) c:\\users\\ayrto\\desktop\\freelance work\\fea\\work\\ocf\\satip\\satip\\eumetsat.py in compress_downloaded_files(data_dir, compressed_dir, log) 567 --> 568 completed_process = subprocess.run(['pbzip2', '-5', full_native_filename]) 569 try: ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in run(input, capture_output, timeout, check, *popenargs, **kwargs) 488 --> 489 with Popen(*popenargs, **kwargs) as process: 490 try: ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text) 853 --> 854 self._execute_child(args, executable, preexec_fn, close_fds, 855 pass_fds, cwd, env, ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in _execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session) 1306 try: -> 1307 hp, ht, pid, tid = _winapi.CreateProcess(executable, args, 1308 # no special security FileNotFoundError: [WinError 2] The system cannot find the file specified The above exception was the direct cause of the following exception: DagsterExecutionStepExecutionError Traceback (most recent call last) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in _dagster_event_sequence_for_step(step_context, retries) 211 --> 212 for step_event in check.generator(step_events): 213 yield step_event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in core_dagster_event_sequence_for_step(step_context, prior_attempt_count) 285 # timer block above in order for time to be recorded accurately. --> 286 for user_event in check.generator( 287 _step_output_error_checked_user_event_sequence(step_context, user_event_sequence) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _step_output_error_checked_user_event_sequence(step_context, user_event_sequence) 58 ---> 59 for user_event in user_event_sequence: 60 if not isinstance(user_event, Output): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _user_event_sequence_for_step_compute_fn(step_context, evaluated_inputs) 475 for event in iterate_with_context(raise_interrupts_immediately, gen): --> 476 yield event 477 ~\\anaconda3\\envs\\satip_dev\\lib\\contextlib.py in __exit__(self, type, value, traceback) 130 try: --> 131 self.gen.throw(type, value, traceback) 132 except StopIteration as exc: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in user_code_error_boundary(error_cls, msg_fn, control_flow_exceptions, **kwargs) 189 # with the error reported further up the stack --> 190 raise_from( 191 error_cls(msg_fn(), user_exception=e, original_exc_info=sys.exc_info(), **kwargs), e ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\future\\utils\\__init__.py in raise_from(exc, cause) 402 execstr = \"raise __python_future_raise_from_exc from __python_future_raise_from_cause\" --> 403 exec(execstr, myglobals, mylocals) 404 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in <module> DagsterExecutionStepExecutionError: Error occurred during the execution of step: step key: \"compress_export_then_delete_raw.compute\" solid invocation: \"compress_export_then_delete_raw\" solid definition: \"compress_export_then_delete_raw\" During handling of the above exception, another exception occurred: FileNotFoundError Traceback (most recent call last) <ipython-input-6-7ed226242252> in <module> 48 } 49 ---> 50 execute_pipeline(download_latest_data_pipeline, run_config=run_config) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in execute_pipeline(pipeline, run_config, mode, preset, tags, solid_selection, instance, raise_on_error) 322 323 with _ephemeral_instance_if_missing(instance) as execute_instance: --> 324 return _logged_execute_pipeline( 325 pipeline, 326 instance=execute_instance, ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\telemetry.py in wrap(*args, **kwargs) 87 start_time = datetime.datetime.now() 88 log_action(instance=instance, action=f.__name__ + \"_started\", client_time=start_time) ---> 89 result = f(*args, **kwargs) 90 end_time = datetime.datetime.now() 91 log_action( ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in _logged_execute_pipeline(pipeline, instance, run_config, mode, preset, tags, solid_selection, raise_on_error) 373 ) 374 --> 375 return execute_run(pipeline, pipeline_run, instance, raise_on_error=raise_on_error) 376 377 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in execute_run(pipeline, pipeline_run, instance, raise_on_error) 175 ), 176 ) --> 177 event_list = list(_execute_run_iterable) 178 pipeline_context = _execute_run_iterable.pipeline_context 179 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in __iter__(self) 725 try: 726 if self.pipeline_context: # False if we had a pipeline init failure --> 727 for event in self.iterator( 728 execution_plan=self.execution_plan, pipeline_context=self.pipeline_context, 729 ): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in _pipeline_execution_iterator(pipeline_context, execution_plan) 663 generator_closed = False 664 try: --> 665 for event in pipeline_context.executor.execute(pipeline_context, execution_plan): 666 if event.is_step_failure: 667 failed_steps.append(event.step_key) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\executor\\in_process.py in execute(self, pipeline_context, execution_plan) 34 35 with time_execution_scope() as timer_result: ---> 36 for event in inner_plan_execution_iterator(pipeline_context, execution_plan): 37 yield event 38 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in inner_plan_execution_iterator(pipeline_context, execution_plan) 75 active_execution.mark_skipped(step.key) 76 else: ---> 77 for step_event in check.generator( 78 _dagster_event_sequence_for_step(step_context, retries) 79 ): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in _dagster_event_sequence_for_step(step_context, retries) 270 271 if step_context.raise_on_error: --> 272 raise dagster_user_error.user_exception 273 274 # case (4) in top comment ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in user_code_error_boundary(error_cls, msg_fn, control_flow_exceptions, **kwargs) 178 ) 179 try: --> 180 yield 181 except control_flow_exceptions as cf: 182 # A control flow exception has occurred and should be propagated ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _user_event_sequence_for_step_compute_fn(step_context, evaluated_inputs) 473 474 # Allow interrupts again during each step of the execution --> 475 for event in iterate_with_context(raise_interrupts_immediately, gen): 476 yield event 477 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\utils\\__init__.py in iterate_with_context(context_manager_class, iterator) 441 with context_manager_class(): 442 try: --> 443 next_output = next(iterator) 444 except StopIteration: 445 return ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py in _execute_core_compute(compute_context, inputs, compute_fn) 103 104 all_results = [] --> 105 for step_output in _yield_compute_results(compute_context, inputs, compute_fn): 106 yield step_output 107 if isinstance(step_output, Output): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py in _yield_compute_results(compute_context, inputs, compute_fn) 74 return 75 ---> 76 for event in user_event_sequence: 77 if isinstance(event, (Output, AssetMaterialization, Materialization, ExpectationResult)): 78 yield event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\definitions\\decorators\\solid.py in compute(context, input_defs) 225 kwargs[input_name] = input_defs[input_name] 226 --> 227 result = fn(context, **kwargs) 228 229 if inspect.isgenerator(result): <ipython-input-4-b374cee63da6> in compress_export_then_delete_raw(context, ds_combined_compressed, data_dir, compressed_dir, BUCKET_NAME, PREFIX, ready_to_delete) 101 def compress_export_then_delete_raw(context, ds_combined_compressed, data_dir: str, compressed_dir: str, BUCKET_NAME: str='solar-pv-nowcasting-data', PREFIX: str='satellite/EUMETSAT/SEVIRI_RSS/native/', ready_to_delete: bool=True): 102 if ready_to_delete == True: --> 103 eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) 104 eumetsat.upload_compressed_files(compressed_dir, BUCKET_NAME=BUCKET_NAME, PREFIX=PREFIX, log=None) 105 c:\\users\\ayrto\\desktop\\freelance work\\fea\\work\\ocf\\satip\\satip\\eumetsat.py in compress_downloaded_files(data_dir, compressed_dir, log) 566 log.debug(f'Compressing {full_native_filename}') 567 --> 568 completed_process = subprocess.run(['pbzip2', '-5', full_native_filename]) 569 try: 570 completed_process.check_returncode() ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in run(input, capture_output, timeout, check, *popenargs, **kwargs) 487 kwargs['stderr'] = PIPE 488 --> 489 with Popen(*popenargs, **kwargs) as process: 490 try: 491 stdout, stderr = process.communicate(input, timeout=timeout) ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text) 852 encoding=encoding, errors=errors) 853 --> 854 self._execute_child(args, executable, preexec_fn, close_fds, 855 pass_fds, cwd, env, 856 startupinfo, creationflags, shell, ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in _execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session) 1305 # Start the process 1306 try: -> 1307 hp, ht, pid, tid = _winapi.CreateProcess(executable, args, 1308 # no special security 1309 None, None, FileNotFoundError: [WinError 2] The system cannot find the file specified #exports @solid () def download_missing_eumetsat_files ( context , env_vars_fp : str , data_dir : str , metadata_db_fp : str , debug_fp : str , table_id : str , project_id : str , start_date : str = '' , end_date : str = '' ): _ = dotenv . load_dotenv ( env_vars_fp ) dm = eumetsat . DownloadManager ( os . environ . get ( 'USER_KEY' ), os . environ . get ( 'USER_SECRET' ), data_dir , metadata_db_fp , debug_fp , slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ), slack_id = os . environ . get ( 'SLACK_ID' )) missing_datasets = io . identifying_missing_datasets ( start_date , end_date ) df_new_metadata = dm . download_datasets ( missing_datasets ) if df_new_metadata is None : df_new_metadata = pd . DataFrame ( columns = [ 'result_time' , 'file_name' ]) else : df_new_metadata = df_new_metadata . iloc [ 1 :] # the first entry is the last one we downloaded return df_new_metadata","title":"Pipelines"},{"location":"05_pipeline/#end-to-end-pipeline","text":"#exports import pandas as pd import xarray as xr from satip import eumetsat , reproj , io , gcp_helpers from dagster import execute_pipeline , pipeline , solid , Field import os import glob import dotenv import warnings C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 4.46rows/s]","title":"End-to-End Pipeline"},{"location":"05_pipeline/#log-cleaning","text":"We'll suppress some errors/warnings to make the logs easier to parse #exports warnings . filterwarnings ( 'ignore' , message = 'divide by zero encountered in true_divide' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in sin' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in cos' ) warnings . filterwarnings ( 'ignore' , message = 'invalid value encountered in subtract' ) warnings . filterwarnings ( 'ignore' , message = 'You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems' )","title":"Log Cleaning"},{"location":"05_pipeline/#dagster-pipeline","text":"We're now going to combine these steps into a pipeline using dagster , first we'll create the individual components. #exports @solid () def download_eumetsat_files ( context , env_vars_fp : str , data_dir : str , metadata_db_fp : str , debug_fp : str , table_id : str , project_id : str , start_date : str = '' , end_date : str = '' , max_mins : int = 60 ): _ = dotenv . load_dotenv ( env_vars_fp ) if start_date == '' : sql_query = f 'select * from { table_id } where result_time = (select max(result_time) from { table_id } )' latest_saved_date = gcp_helpers . query ( sql_query , project_id )[ 'result_time' ] . iloc [ 0 ] . tz_localize ( None ) earliest_start_date = pd . Timestamp . now () - pd . Timedelta ( max_mins , unit = 'minutes' ) start_date = max ( earliest_start_date , latest_saved_date ) . strftime ( '%Y-%m- %d %H:%M' ) if end_date == '' : end_date = pd . Timestamp . now () . strftime ( '%Y-%m- %d %H:%M' ) context . log . info ( f 'Querying data between { start_date } - { end_date } ' ) dm = eumetsat . DownloadManager ( os . environ . get ( 'USER_KEY' ), os . environ . get ( 'USER_SECRET' ), data_dir , metadata_db_fp , debug_fp , slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ), slack_id = os . environ . get ( 'SLACK_ID' )) df_new_metadata = dm . download_date_range ( start_date , end_date ) if df_new_metadata is None : df_new_metadata = pd . DataFrame ( columns = [ 'result_time' , 'file_name' ]) else : df_new_metadata = df_new_metadata . iloc [ 1 :] # the first entry is the last one we downloaded return df_new_metadata @solid () def df_metadata_to_dt_to_fp_map ( _ , df_new_metadata , data_dir : str ) -> dict : \"\"\" Here we'll then identify downloaded files in the metadata dataframe and return a mapping between datetimes and filenames \"\"\" datetime_to_filename = ( df_new_metadata . set_index ( 'result_time' ) [ 'file_name' ] . drop_duplicates () . to_dict () ) datetime_to_filepath = { datetime : f \" { data_dir } / { filename } .nat\" for datetime , filename in datetime_to_filename . items () if filename != {} } return datetime_to_filepath @solid () def reproject_datasets ( _ , datetime_to_filepath : dict , new_coords_fp : str , new_grid_fp : str ): reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) reprojected_dss = [ ( reprojector . reproject ( filepath , reproj_library = 'pyresample' ) . pipe ( io . add_constant_coord_to_da , 'time' , pd . to_datetime ( datetime )) ) for datetime , filepath in datetime_to_filepath . items () ] if len ( reprojected_dss ) > 0 : ds_combined_reproj = xr . concat ( reprojected_dss , 'time' , coords = 'all' , data_vars = 'all' ) return ds_combined_reproj else : return xr . Dataset () @solid () def compress_and_save_datasets ( _ , ds_combined_reproj , zarr_bucket : str , var_name : str = 'stacked_eumetsat_data' ): # Handle case where no new data exists if len ( ds_combined_reproj . dims ) == 0 : return # Compressing the datasets compressor = io . Compressor () var_name = var_name da_compressed = compressor . compress ( ds_combined_reproj [ var_name ]) # Saving to Zarr ds_compressed = io . save_da_to_zarr ( da_compressed , zarr_bucket ) return ds_compressed @solid () def save_metadata ( context , ds_combined_compressed , df_new_metadata , table_id : str , project_id : str ): if ds_combined_compressed is not None : if df_new_metadata . shape [ 0 ] > 0 : gcp_helpers . write_metadata_to_gcp ( df_new_metadata , table_id , project_id , append = True ) context . log . info ( f ' { df_new_metadata . shape [ 0 ] } new metadata entries were added' ) else : context . log . info ( 'No metadata was available to be added' ) return True @solid () def compress_export_then_delete_raw ( context , ds_combined_compressed , data_dir : str , compressed_dir : str , BUCKET_NAME : str = 'solar-pv-nowcasting-data' , PREFIX : str = 'satellite/EUMETSAT/SEVIRI_RSS/native/' , ready_to_delete : bool = True ): if ready_to_delete == True : eumetsat . compress_downloaded_files ( data_dir = data_dir , compressed_dir = compressed_dir , log = context . log ) eumetsat . upload_compressed_files ( compressed_dir , BUCKET_NAME = BUCKET_NAME , PREFIX = PREFIX , log = None ) for dir_ in [ data_dir , compressed_dir ]: files = glob . glob ( f ' { dir_ } /*' ) for f in files : os . remove ( f ) Then we'll combine them in a pipeline #exports @pipeline def download_latest_data_pipeline (): df_new_metadata = download_eumetsat_files () datetime_to_filepath = df_metadata_to_dt_to_fp_map ( df_new_metadata ) ds_combined_reproj = reproject_datasets ( datetime_to_filepath ) ds_combined_compressed = compress_and_save_datasets ( ds_combined_reproj ) ready_to_delete = save_metadata ( ds_combined_compressed , df_new_metadata ) compress_export_then_delete_raw ( ready_to_delete ) Which we'll now run a test with run_config = { 'solids' : { 'download_eumetsat_files' : { 'inputs' : { 'env_vars_fp' : \"../.env\" , 'data_dir' : \"../data/raw\" , 'metadata_db_fp' : \"../data/EUMETSAT_metadata.db\" , 'debug_fp' : \"../logs/EUMETSAT_download.txt\" , 'table_id' : \"eumetsat.metadata\" , 'project_id' : \"solar-pv-nowcasting\" , 'start_date' : \"\" , 'end_date' : \"\" }, }, 'df_metadata_to_dt_to_fp_map' : { 'inputs' : { 'data_dir' : \"../data/raw\" } }, 'reproject_datasets' : { 'inputs' : { 'new_coords_fp' : \"../data/intermediate/reproj_coords_TM_4km.csv\" , 'new_grid_fp' : \"../data/intermediate/new_grid_4km_TM.json\" } }, 'compress_and_save_datasets' : { 'inputs' : { 'zarr_bucket' : \"solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16\" , 'var_name' : \"stacked_eumetsat_data\" } }, 'save_metadata' : { 'inputs' : { 'table_id' : \"eumetsat.metadata\" , 'project_id' : \"solar-pv-nowcasting\" }, }, 'compress_export_then_delete_raw' : { 'inputs' : { 'data_dir' : \"../data/raw\" , 'compressed_dir' : \"../data/compressed\" , 'BUCKET_NAME' : \"solar-pv-nowcasting-data\" , 'PREFIX' : \"satellite/EUMETSAT/SEVIRI_RSS/native/\" , 'ready_to_delete' : True }, } } } execute_pipeline ( download_latest_data_pipeline , run_config = run_config ) 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - ENGINE_EVENT - Starting initialization of resources [asset_store]. 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - ENGINE_EVENT - Finished initialization of resources [asset_store]. 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - PIPELINE_START - Started execution of pipeline \"download_latest_data_pipeline\". 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - ENGINE_EVENT - Executing steps in process (pid: 1108) 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_START - Started execution of step \"download_eumetsat_files.compute\". 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"env_vars_fp\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"metadata_db_fp\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"debug_fp\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"start_date\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"end_date\" of type \"String\". (Type check passed). 2021-01-21 22:33:00 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_INPUT - Got input \"max_mins\" of type \"Int\". (Type check passed). Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 5.00rows/s] 2021-01-21 22:33:02 - dagster - INFO - system - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - download_eumetsat_files.compute - Querying data between 2021-01-21 21:33 - 2021-01-21 22:33 2021-01-21 22:33:02,396 - INFO - ********** Download Manager Initialised ************** 2021-01-21 22:33:02,869 - INFO - 11 files queried, 0 found in ../data/raw, 11 to download. 100% 11/11 [01:08 < 00:06, 6.19s/it] 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - download_eumetsat_files.compute - STEP_SUCCESS - Finished execution of step \"download_eumetsat_files.compute\" in 1m10s. 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_START - Started execution of step \"df_metadata_to_dt_to_fp_map.compute\". 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle. 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed). 2021-01-21 22:34:10 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_OUTPUT - Yielded output \"result\" of type \"dict\". (Type check passed). 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - df_metadata_to_dt_to_fp_map.compute - STEP_SUCCESS - Finished execution of step \"df_metadata_to_dt_to_fp_map.compute\" in 15ms. 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_START - Started execution of step \"reproject_datasets.compute\". 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input datetime_to_filepath in memory object store using pickle. 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_INPUT - Got input \"datetime_to_filepath\" of type \"dict\". (Type check passed). 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_INPUT - Got input \"new_coords_fp\" of type \"String\". (Type check passed). 2021-01-21 22:34:11 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_INPUT - Got input \"new_grid_fp\" of type \"String\". (Type check passed). C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\numpy\\lib\\function_base.py:1280: RuntimeWarning: invalid value encountered in subtract a = op(a[slice1], a[slice2]) 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - reproject_datasets.compute - STEP_SUCCESS - Finished execution of step \"reproject_datasets.compute\" in 48.26s. 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_START - Started execution of step \"compress_and_save_datasets.compute\". 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_reproj in memory object store using pickle. 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"ds_combined_reproj\" of type \"Any\". (Type check passed). 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"zarr_bucket\" of type \"String\". (Type check passed). 2021-01-21 22:34:59 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"var_name\" of type \"String\". (Type check passed). C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_and_save_datasets.compute - STEP_SUCCESS - Finished execution of step \"compress_and_save_datasets.compute\" in 11m44s. 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_START - Started execution of step \"save_metadata.compute\". 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle. 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle. 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed). 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed). 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed). 2021-01-21 22:46:43 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed). 1it [00:03, 3.73s/it] 2021-01-21 22:46:48 - dagster - INFO - system - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - save_metadata.compute - 10 new metadata entries were added 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle. 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - save_metadata.compute - STEP_SUCCESS - Finished execution of step \"save_metadata.compute\" in 4.29s. 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_START - Started execution of step \"compress_export_then_delete_raw.compute\". 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle. 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"compressed_dir\" of type \"String\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"BUCKET_NAME\" of type \"String\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"PREFIX\" of type \"String\". (Type check passed). 2021-01-21 22:46:48 - dagster - DEBUG - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ready_to_delete\" of type \"Bool\". (Type check passed). 2021-01-21 22:46:48 - dagster - INFO - system - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - compress_export_then_delete_raw.compute - Found 20 native files. 2021-01-21 22:46:48 - dagster - DEBUG - system - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - compress_export_then_delete_raw.compute - Compressing ../data/raw\\MSG3-SEVI-MSG15-0100-NA-20210121204918.196000000Z-NA.nat 10 rows written to BQ eumetsat.metadata, append=True Found 20 native files. 2021-01-21 22:46:49 - dagster - ERROR - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - compress_export_then_delete_raw.compute - STEP_FAILURE - Execution of step \"compress_export_then_delete_raw.compute\" failed. FileNotFoundError: [WinError 2] The system cannot find the file specified File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py\", line 180, in user_code_error_boundary yield File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py\", line 475, in _user_event_sequence_for_step_compute_fn for event in iterate_with_context(raise_interrupts_immediately, gen): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\utils\\__init__.py\", line 443, in iterate_with_context next_output = next(iterator) File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py\", line 105, in _execute_core_compute for step_output in _yield_compute_results(compute_context, inputs, compute_fn): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py\", line 76, in _yield_compute_results for event in user_event_sequence: File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\definitions\\decorators\\solid.py\", line 227, in compute result = fn(context, **kwargs) File \"<ipython-input-4-b374cee63da6>\", line 103, in compress_export_then_delete_raw eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) File \"c:\\users\\ayrto\\desktop\\freelance work\\fea\\work\\ocf\\satip\\satip\\eumetsat.py\", line 568, in compress_downloaded_files completed_process = subprocess.run(['pbzip2', '-5', full_native_filename]) File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 489, in run with Popen(*popenargs, **kwargs) as process: File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 854, in __init__ self._execute_child(args, executable, preexec_fn, close_fds, File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 1307, in _execute_child hp, ht, pid, tid = _winapi.CreateProcess(executable, args, 2021-01-21 22:46:49 - dagster - ERROR - download_latest_data_pipeline - d3e2e4f6-c6a3-4ee2-af3a-2570ac7c607a - 1108 - PIPELINE_FAILURE - Execution of pipeline \"download_latest_data_pipeline\" failed. An exception was thrown during execution. FileNotFoundError: [WinError 2] The system cannot find the file specified File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py\", line 665, in _pipeline_execution_iterator for event in pipeline_context.executor.execute(pipeline_context, execution_plan): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\executor\\in_process.py\", line 36, in execute for event in inner_plan_execution_iterator(pipeline_context, execution_plan): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py\", line 77, in inner_plan_execution_iterator for step_event in check.generator( File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py\", line 272, in _dagster_event_sequence_for_step raise dagster_user_error.user_exception File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py\", line 180, in user_code_error_boundary yield File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py\", line 475, in _user_event_sequence_for_step_compute_fn for event in iterate_with_context(raise_interrupts_immediately, gen): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\utils\\__init__.py\", line 443, in iterate_with_context next_output = next(iterator) File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py\", line 105, in _execute_core_compute for step_output in _yield_compute_results(compute_context, inputs, compute_fn): File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py\", line 76, in _yield_compute_results for event in user_event_sequence: File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\definitions\\decorators\\solid.py\", line 227, in compute result = fn(context, **kwargs) File \"<ipython-input-4-b374cee63da6>\", line 103, in compress_export_then_delete_raw eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) File \"c:\\users\\ayrto\\desktop\\freelance work\\fea\\work\\ocf\\satip\\satip\\eumetsat.py\", line 568, in compress_downloaded_files completed_process = subprocess.run(['pbzip2', '-5', full_native_filename]) File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 489, in run with Popen(*popenargs, **kwargs) as process: File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 854, in __init__ self._execute_child(args, executable, preexec_fn, close_fds, File \"C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py\", line 1307, in _execute_child hp, ht, pid, tid = _winapi.CreateProcess(executable, args, --------------------------------------------------------------------------- DagsterExecutionStepExecutionError Traceback (most recent call last) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in _dagster_event_sequence_for_step(step_context, retries) 211 --> 212 for step_event in check.generator(step_events): 213 yield step_event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in core_dagster_event_sequence_for_step(step_context, prior_attempt_count) 285 # timer block above in order for time to be recorded accurately. --> 286 for user_event in check.generator( 287 _step_output_error_checked_user_event_sequence(step_context, user_event_sequence) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _step_output_error_checked_user_event_sequence(step_context, user_event_sequence) 58 ---> 59 for user_event in user_event_sequence: 60 if not isinstance(user_event, Output): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _user_event_sequence_for_step_compute_fn(step_context, evaluated_inputs) 475 for event in iterate_with_context(raise_interrupts_immediately, gen): --> 476 yield event 477 ~\\anaconda3\\envs\\satip_dev\\lib\\contextlib.py in __exit__(self, type, value, traceback) 130 try: --> 131 self.gen.throw(type, value, traceback) 132 except StopIteration as exc: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in user_code_error_boundary(error_cls, msg_fn, control_flow_exceptions, **kwargs) 189 # with the error reported further up the stack --> 190 raise_from( 191 error_cls(msg_fn(), user_exception=e, original_exc_info=sys.exc_info(), **kwargs), e ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\future\\utils\\__init__.py in raise_from(exc, cause) 402 execstr = \"raise __python_future_raise_from_exc from __python_future_raise_from_cause\" --> 403 exec(execstr, myglobals, mylocals) 404 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in <module> DagsterExecutionStepExecutionError: Error occurred during the execution of step: step key: \"compress_export_then_delete_raw.compute\" solid invocation: \"compress_export_then_delete_raw\" solid definition: \"compress_export_then_delete_raw\" During handling of the above exception, another exception occurred: FileNotFoundError Traceback (most recent call last) [... skipping hidden 1 frame] <ipython-input-6-7ed226242252> in <module> 49 ---> 50 execute_pipeline(download_latest_data_pipeline, run_config=run_config) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in execute_pipeline(pipeline, run_config, mode, preset, tags, solid_selection, instance, raise_on_error) 323 with _ephemeral_instance_if_missing(instance) as execute_instance: --> 324 return _logged_execute_pipeline( 325 pipeline, ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\telemetry.py in wrap(*args, **kwargs) 88 log_action(instance=instance, action=f.__name__ + \"_started\", client_time=start_time) ---> 89 result = f(*args, **kwargs) 90 end_time = datetime.datetime.now() ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in _logged_execute_pipeline(pipeline, instance, run_config, mode, preset, tags, solid_selection, raise_on_error) 374 --> 375 return execute_run(pipeline, pipeline_run, instance, raise_on_error=raise_on_error) 376 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in execute_run(pipeline, pipeline_run, instance, raise_on_error) 176 ) --> 177 event_list = list(_execute_run_iterable) 178 pipeline_context = _execute_run_iterable.pipeline_context ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in __iter__(self) 726 if self.pipeline_context: # False if we had a pipeline init failure --> 727 for event in self.iterator( 728 execution_plan=self.execution_plan, pipeline_context=self.pipeline_context, ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in _pipeline_execution_iterator(pipeline_context, execution_plan) 664 try: --> 665 for event in pipeline_context.executor.execute(pipeline_context, execution_plan): 666 if event.is_step_failure: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\executor\\in_process.py in execute(self, pipeline_context, execution_plan) 35 with time_execution_scope() as timer_result: ---> 36 for event in inner_plan_execution_iterator(pipeline_context, execution_plan): 37 yield event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in inner_plan_execution_iterator(pipeline_context, execution_plan) 76 else: ---> 77 for step_event in check.generator( 78 _dagster_event_sequence_for_step(step_context, retries) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in _dagster_event_sequence_for_step(step_context, retries) 271 if step_context.raise_on_error: --> 272 raise dagster_user_error.user_exception 273 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in user_code_error_boundary(error_cls, msg_fn, control_flow_exceptions, **kwargs) 179 try: --> 180 yield 181 except control_flow_exceptions as cf: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _user_event_sequence_for_step_compute_fn(step_context, evaluated_inputs) 474 # Allow interrupts again during each step of the execution --> 475 for event in iterate_with_context(raise_interrupts_immediately, gen): 476 yield event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\utils\\__init__.py in iterate_with_context(context_manager_class, iterator) 442 try: --> 443 next_output = next(iterator) 444 except StopIteration: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py in _execute_core_compute(compute_context, inputs, compute_fn) 104 all_results = [] --> 105 for step_output in _yield_compute_results(compute_context, inputs, compute_fn): 106 yield step_output ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py in _yield_compute_results(compute_context, inputs, compute_fn) 75 ---> 76 for event in user_event_sequence: 77 if isinstance(event, (Output, AssetMaterialization, Materialization, ExpectationResult)): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\definitions\\decorators\\solid.py in compute(context, input_defs) 226 --> 227 result = fn(context, **kwargs) 228 <ipython-input-4-b374cee63da6> in compress_export_then_delete_raw(context, ds_combined_compressed, data_dir, compressed_dir, BUCKET_NAME, PREFIX, ready_to_delete) 102 if ready_to_delete == True: --> 103 eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) 104 eumetsat.upload_compressed_files(compressed_dir, BUCKET_NAME=BUCKET_NAME, PREFIX=PREFIX, log=None) c:\\users\\ayrto\\desktop\\freelance work\\fea\\work\\ocf\\satip\\satip\\eumetsat.py in compress_downloaded_files(data_dir, compressed_dir, log) 567 --> 568 completed_process = subprocess.run(['pbzip2', '-5', full_native_filename]) 569 try: ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in run(input, capture_output, timeout, check, *popenargs, **kwargs) 488 --> 489 with Popen(*popenargs, **kwargs) as process: 490 try: ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text) 853 --> 854 self._execute_child(args, executable, preexec_fn, close_fds, 855 pass_fds, cwd, env, ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in _execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session) 1306 try: -> 1307 hp, ht, pid, tid = _winapi.CreateProcess(executable, args, 1308 # no special security FileNotFoundError: [WinError 2] The system cannot find the file specified The above exception was the direct cause of the following exception: DagsterExecutionStepExecutionError Traceback (most recent call last) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in _dagster_event_sequence_for_step(step_context, retries) 211 --> 212 for step_event in check.generator(step_events): 213 yield step_event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in core_dagster_event_sequence_for_step(step_context, prior_attempt_count) 285 # timer block above in order for time to be recorded accurately. --> 286 for user_event in check.generator( 287 _step_output_error_checked_user_event_sequence(step_context, user_event_sequence) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _step_output_error_checked_user_event_sequence(step_context, user_event_sequence) 58 ---> 59 for user_event in user_event_sequence: 60 if not isinstance(user_event, Output): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _user_event_sequence_for_step_compute_fn(step_context, evaluated_inputs) 475 for event in iterate_with_context(raise_interrupts_immediately, gen): --> 476 yield event 477 ~\\anaconda3\\envs\\satip_dev\\lib\\contextlib.py in __exit__(self, type, value, traceback) 130 try: --> 131 self.gen.throw(type, value, traceback) 132 except StopIteration as exc: ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in user_code_error_boundary(error_cls, msg_fn, control_flow_exceptions, **kwargs) 189 # with the error reported further up the stack --> 190 raise_from( 191 error_cls(msg_fn(), user_exception=e, original_exc_info=sys.exc_info(), **kwargs), e ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\future\\utils\\__init__.py in raise_from(exc, cause) 402 execstr = \"raise __python_future_raise_from_exc from __python_future_raise_from_cause\" --> 403 exec(execstr, myglobals, mylocals) 404 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in <module> DagsterExecutionStepExecutionError: Error occurred during the execution of step: step key: \"compress_export_then_delete_raw.compute\" solid invocation: \"compress_export_then_delete_raw\" solid definition: \"compress_export_then_delete_raw\" During handling of the above exception, another exception occurred: FileNotFoundError Traceback (most recent call last) <ipython-input-6-7ed226242252> in <module> 48 } 49 ---> 50 execute_pipeline(download_latest_data_pipeline, run_config=run_config) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in execute_pipeline(pipeline, run_config, mode, preset, tags, solid_selection, instance, raise_on_error) 322 323 with _ephemeral_instance_if_missing(instance) as execute_instance: --> 324 return _logged_execute_pipeline( 325 pipeline, 326 instance=execute_instance, ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\telemetry.py in wrap(*args, **kwargs) 87 start_time = datetime.datetime.now() 88 log_action(instance=instance, action=f.__name__ + \"_started\", client_time=start_time) ---> 89 result = f(*args, **kwargs) 90 end_time = datetime.datetime.now() 91 log_action( ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in _logged_execute_pipeline(pipeline, instance, run_config, mode, preset, tags, solid_selection, raise_on_error) 373 ) 374 --> 375 return execute_run(pipeline, pipeline_run, instance, raise_on_error=raise_on_error) 376 377 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in execute_run(pipeline, pipeline_run, instance, raise_on_error) 175 ), 176 ) --> 177 event_list = list(_execute_run_iterable) 178 pipeline_context = _execute_run_iterable.pipeline_context 179 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in __iter__(self) 725 try: 726 if self.pipeline_context: # False if we had a pipeline init failure --> 727 for event in self.iterator( 728 execution_plan=self.execution_plan, pipeline_context=self.pipeline_context, 729 ): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\api.py in _pipeline_execution_iterator(pipeline_context, execution_plan) 663 generator_closed = False 664 try: --> 665 for event in pipeline_context.executor.execute(pipeline_context, execution_plan): 666 if event.is_step_failure: 667 failed_steps.append(event.step_key) ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\executor\\in_process.py in execute(self, pipeline_context, execution_plan) 34 35 with time_execution_scope() as timer_result: ---> 36 for event in inner_plan_execution_iterator(pipeline_context, execution_plan): 37 yield event 38 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in inner_plan_execution_iterator(pipeline_context, execution_plan) 75 active_execution.mark_skipped(step.key) 76 else: ---> 77 for step_event in check.generator( 78 _dagster_event_sequence_for_step(step_context, retries) 79 ): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_plan.py in _dagster_event_sequence_for_step(step_context, retries) 270 271 if step_context.raise_on_error: --> 272 raise dagster_user_error.user_exception 273 274 # case (4) in top comment ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\errors.py in user_code_error_boundary(error_cls, msg_fn, control_flow_exceptions, **kwargs) 178 ) 179 try: --> 180 yield 181 except control_flow_exceptions as cf: 182 # A control flow exception has occurred and should be propagated ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\execute_step.py in _user_event_sequence_for_step_compute_fn(step_context, evaluated_inputs) 473 474 # Allow interrupts again during each step of the execution --> 475 for event in iterate_with_context(raise_interrupts_immediately, gen): 476 yield event 477 ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\utils\\__init__.py in iterate_with_context(context_manager_class, iterator) 441 with context_manager_class(): 442 try: --> 443 next_output = next(iterator) 444 except StopIteration: 445 return ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py in _execute_core_compute(compute_context, inputs, compute_fn) 103 104 all_results = [] --> 105 for step_output in _yield_compute_results(compute_context, inputs, compute_fn): 106 yield step_output 107 if isinstance(step_output, Output): ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\execution\\plan\\compute.py in _yield_compute_results(compute_context, inputs, compute_fn) 74 return 75 ---> 76 for event in user_event_sequence: 77 if isinstance(event, (Output, AssetMaterialization, Materialization, ExpectationResult)): 78 yield event ~\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\dagster\\core\\definitions\\decorators\\solid.py in compute(context, input_defs) 225 kwargs[input_name] = input_defs[input_name] 226 --> 227 result = fn(context, **kwargs) 228 229 if inspect.isgenerator(result): <ipython-input-4-b374cee63da6> in compress_export_then_delete_raw(context, ds_combined_compressed, data_dir, compressed_dir, BUCKET_NAME, PREFIX, ready_to_delete) 101 def compress_export_then_delete_raw(context, ds_combined_compressed, data_dir: str, compressed_dir: str, BUCKET_NAME: str='solar-pv-nowcasting-data', PREFIX: str='satellite/EUMETSAT/SEVIRI_RSS/native/', ready_to_delete: bool=True): 102 if ready_to_delete == True: --> 103 eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log) 104 eumetsat.upload_compressed_files(compressed_dir, BUCKET_NAME=BUCKET_NAME, PREFIX=PREFIX, log=None) 105 c:\\users\\ayrto\\desktop\\freelance work\\fea\\work\\ocf\\satip\\satip\\eumetsat.py in compress_downloaded_files(data_dir, compressed_dir, log) 566 log.debug(f'Compressing {full_native_filename}') 567 --> 568 completed_process = subprocess.run(['pbzip2', '-5', full_native_filename]) 569 try: 570 completed_process.check_returncode() ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in run(input, capture_output, timeout, check, *popenargs, **kwargs) 487 kwargs['stderr'] = PIPE 488 --> 489 with Popen(*popenargs, **kwargs) as process: 490 try: 491 stdout, stderr = process.communicate(input, timeout=timeout) ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text) 852 encoding=encoding, errors=errors) 853 --> 854 self._execute_child(args, executable, preexec_fn, close_fds, 855 pass_fds, cwd, env, 856 startupinfo, creationflags, shell, ~\\anaconda3\\envs\\satip_dev\\lib\\subprocess.py in _execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session) 1305 # Start the process 1306 try: -> 1307 hp, ht, pid, tid = _winapi.CreateProcess(executable, args, 1308 # no special security 1309 None, None, FileNotFoundError: [WinError 2] The system cannot find the file specified #exports @solid () def download_missing_eumetsat_files ( context , env_vars_fp : str , data_dir : str , metadata_db_fp : str , debug_fp : str , table_id : str , project_id : str , start_date : str = '' , end_date : str = '' ): _ = dotenv . load_dotenv ( env_vars_fp ) dm = eumetsat . DownloadManager ( os . environ . get ( 'USER_KEY' ), os . environ . get ( 'USER_SECRET' ), data_dir , metadata_db_fp , debug_fp , slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ), slack_id = os . environ . get ( 'SLACK_ID' )) missing_datasets = io . identifying_missing_datasets ( start_date , end_date ) df_new_metadata = dm . download_datasets ( missing_datasets ) if df_new_metadata is None : df_new_metadata = pd . DataFrame ( columns = [ 'result_time' , 'file_name' ]) else : df_new_metadata = df_new_metadata . iloc [ 1 :] # the first entry is the last one we downloaded return df_new_metadata","title":"Dagster Pipeline"},{"location":"06-ci-cd/","text":"CI/CD \u00b6 #exports import os import re import typer import logging from warnings import warn from configparser import ConfigParser Initialising CLI \u00b6 #exports app = typer . Typer () Incrementing the Package Version \u00b6 We'll start by retrieving the current package version specified in settings.ini #exports @app . command () def get_current_package_version ( settings_fp : str = 'settings.ini' ): config = ConfigParser ( delimiters = [ '=' ]) config . read ( settings_fp ) version = config . get ( 'DEFAULT' , 'version' ) return version settings_fp = '../settings.ini' original_version = get_current_package_version ( settings_fp ) original_version '1.0.2' We'll now increment the package version #exports @app . command () def increment_package_version ( old_version : str , increment_level : str = 'micro' ): increment = lambda rev : str ( int ( rev ) + 1 ) major , minor , micro = old_version . split ( '.' ) # naming from - https://the-hitchhikers-guide-to-packaging.readthedocs.io/en/latest/specification.html#sequence-based-scheme if increment_level == 'major' : major = increment ( major ) elif increment_level == 'minor' : minor = increment ( minor ) elif increment_level == 'micro' : micro = increment ( micro ) new_version = '.' . join ([ major , minor , micro ]) return new_version increment_package_version ( original_version ) '1.0.3' But what about if we've made large changes to the code-base and wish to express the size of these revisions in the version? For that we can specify the increment_level . increment_package_version ( original_version , increment_level = 'major' ) '2.0.2' And finally we can set the version #exports @app . command () def set_current_package_version ( version : str , settings_fp : str = 'settings.ini' ): version = version . replace ( 'v' , '' ) config = ConfigParser ( delimiters = [ '=' ]) config . read ( settings_fp ) config . set ( 'DEFAULT' , 'version' , version ) with open ( settings_fp , 'w' ) as configfile : config . write ( configfile ) logger = logging . getLogger ( 'package_release' ) logger . setLevel ( 'INFO' ) logger . info ( f 'The package version has to be updated to { version } ' ) return set_current_package_version ( '9.9.9' , settings_fp ) get_current_package_version ( settings_fp ) '9.9.9' Before we move on we'll change the version on file back to the original set_current_package_version ( original_version , settings_fp ) get_current_package_version ( settings_fp ) '1.0.2' Finally we need to ensure the CLI app is available when the module is loaded. N.b. we've included the condition '__file__' in globals() to make sure this isn't when inside the notebook #exports if __name__ == '__main__' and '__file__' in globals (): app ()","title":"CI/CD"},{"location":"06-ci-cd/#cicd","text":"#exports import os import re import typer import logging from warnings import warn from configparser import ConfigParser","title":"CI/CD"},{"location":"06-ci-cd/#initialising-cli","text":"#exports app = typer . Typer ()","title":"Initialising CLI"},{"location":"06-ci-cd/#incrementing-the-package-version","text":"We'll start by retrieving the current package version specified in settings.ini #exports @app . command () def get_current_package_version ( settings_fp : str = 'settings.ini' ): config = ConfigParser ( delimiters = [ '=' ]) config . read ( settings_fp ) version = config . get ( 'DEFAULT' , 'version' ) return version settings_fp = '../settings.ini' original_version = get_current_package_version ( settings_fp ) original_version '1.0.2' We'll now increment the package version #exports @app . command () def increment_package_version ( old_version : str , increment_level : str = 'micro' ): increment = lambda rev : str ( int ( rev ) + 1 ) major , minor , micro = old_version . split ( '.' ) # naming from - https://the-hitchhikers-guide-to-packaging.readthedocs.io/en/latest/specification.html#sequence-based-scheme if increment_level == 'major' : major = increment ( major ) elif increment_level == 'minor' : minor = increment ( minor ) elif increment_level == 'micro' : micro = increment ( micro ) new_version = '.' . join ([ major , minor , micro ]) return new_version increment_package_version ( original_version ) '1.0.3' But what about if we've made large changes to the code-base and wish to express the size of these revisions in the version? For that we can specify the increment_level . increment_package_version ( original_version , increment_level = 'major' ) '2.0.2' And finally we can set the version #exports @app . command () def set_current_package_version ( version : str , settings_fp : str = 'settings.ini' ): version = version . replace ( 'v' , '' ) config = ConfigParser ( delimiters = [ '=' ]) config . read ( settings_fp ) config . set ( 'DEFAULT' , 'version' , version ) with open ( settings_fp , 'w' ) as configfile : config . write ( configfile ) logger = logging . getLogger ( 'package_release' ) logger . setLevel ( 'INFO' ) logger . info ( f 'The package version has to be updated to { version } ' ) return set_current_package_version ( '9.9.9' , settings_fp ) get_current_package_version ( settings_fp ) '9.9.9' Before we move on we'll change the version on file back to the original set_current_package_version ( original_version , settings_fp ) get_current_package_version ( settings_fp ) '1.0.2' Finally we need to ensure the CLI app is available when the module is loaded. N.b. we've included the condition '__file__' in globals() to make sure this isn't when inside the notebook #exports if __name__ == '__main__' and '__file__' in globals (): app ()","title":"Incrementing the Package Version"},{"location":"101_downloading/","text":"Downloading Data From EUMETSAT \u00b6 from satip import eumetsat import matplotlib.pyplot as plt import cartopy.crs as ccrs import os import dotenv C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.40rows/s] User Inputs \u00b6 We have to specify the directory where the data native filepaths are located data_dir = '../data/raw' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' Using the Download Manager \u00b6 First we'll load the the environment variables dotenv . load_dotenv ( env_vars_fp ) user_key = os . environ . get ( 'USER_KEY' ) user_secret = os . environ . get ( 'USER_SECRET' ) slack_id = os . environ . get ( 'SLACK_ID' ) slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ) Then we'll use the download manager to retrieve a single dataset dm = eumetsat . DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp , slack_webhook_url = slack_webhook_url , slack_id = slack_id ) start_date = '2020-01-01 00:00' end_date = '2020-01-01 00:05' dm . download_date_range ( start_date , end_date ) 2020-12-17 00:21:11,192 - INFO - ********** Download Manager Initialised ************** 2020-12-17 00:21:11,777 - INFO - 1 files queried, 0 found in ../data/raw, 1 to download. 100% 1/1 [00:07 < 00:07, 6.59s/it] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } start_date end_date result_time platform_short_name platform_orbit_type instrument_name sensor_op_mode center_srs_name center_position file_name file_size missing_pct downloaded 0 2020-01-01 00:00:07.683000+00:00 2020-01-01 00:04:14.102000+00:00 2020-01-01 00:04:14.102000+00:00 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101000414.1020000... 99819 0.0 2020-12-17 00:21:18.312026 Once the files have been downloaded they will be automatically detected and skipped if downloading is attempted again _ = dm . download_date_range ( start_date , end_date ) 2020-12-17 00:21:31,507 - INFO - 1 files queried, 1 found in ../data/raw, 0 to download. 2020-12-17 00:21:31,512 - INFO - No files will be downloaded. Set DownloadManager bucket_name argument for local download We can retrieve the metadata for all historical downloads by calling the get_df_metadata method df_metadata = dm . get_df_metadata () df_metadata . head ()","title":"Downloading from EUMETSAT"},{"location":"101_downloading/#downloading-data-from-eumetsat","text":"from satip import eumetsat import matplotlib.pyplot as plt import cartopy.crs as ccrs import os import dotenv C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.40rows/s]","title":"Downloading Data From EUMETSAT"},{"location":"101_downloading/#user-inputs","text":"We have to specify the directory where the data native filepaths are located data_dir = '../data/raw' debug_fp = '../logs/EUMETSAT_download.txt' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db'","title":"User Inputs"},{"location":"101_downloading/#using-the-download-manager","text":"First we'll load the the environment variables dotenv . load_dotenv ( env_vars_fp ) user_key = os . environ . get ( 'USER_KEY' ) user_secret = os . environ . get ( 'USER_SECRET' ) slack_id = os . environ . get ( 'SLACK_ID' ) slack_webhook_url = os . environ . get ( 'SLACK_WEBHOOK_URL' ) Then we'll use the download manager to retrieve a single dataset dm = eumetsat . DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp , debug_fp , slack_webhook_url = slack_webhook_url , slack_id = slack_id ) start_date = '2020-01-01 00:00' end_date = '2020-01-01 00:05' dm . download_date_range ( start_date , end_date ) 2020-12-17 00:21:11,192 - INFO - ********** Download Manager Initialised ************** 2020-12-17 00:21:11,777 - INFO - 1 files queried, 0 found in ../data/raw, 1 to download. 100% 1/1 [00:07 < 00:07, 6.59s/it] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } start_date end_date result_time platform_short_name platform_orbit_type instrument_name sensor_op_mode center_srs_name center_position file_name file_size missing_pct downloaded 0 2020-01-01 00:00:07.683000+00:00 2020-01-01 00:04:14.102000+00:00 2020-01-01 00:04:14.102000+00:00 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20200101000414.1020000... 99819 0.0 2020-12-17 00:21:18.312026 Once the files have been downloaded they will be automatically detected and skipped if downloading is attempted again _ = dm . download_date_range ( start_date , end_date ) 2020-12-17 00:21:31,507 - INFO - 1 files queried, 1 found in ../data/raw, 0 to download. 2020-12-17 00:21:31,512 - INFO - No files will be downloaded. Set DownloadManager bucket_name argument for local download We can retrieve the metadata for all historical downloads by calling the get_df_metadata method df_metadata = dm . get_df_metadata () df_metadata . head ()","title":"Using the Download Manager"},{"location":"102_reprojecting/","text":"Reprojecting \u00b6 from satip import reproj import matplotlib.pyplot as plt import cartopy.crs as ccrs import os User Inputs \u00b6 We have to specify the directory where the data native filepaths are located data_dir = '../data/raw' Loading the Scene \u00b6 We'll then load the file using the reproj library native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fp = native_fps [ 0 ] scene = reproj . load_scene ( native_fp ) scene . load ([ 'HRV' ]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() Next we'll visualise the data in the HRV layer. In this particular image it looks like we've caught a period where the satellite is slightly off-kilter. Fortunately the area definition we create accounts for periods when this occurs. seviri = reproj . get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() <cartopy.mpl.feature_artist.FeatureArtist at 0x28f1fdd6970> Reprojection \u00b6 The main way to carry out a reprojection is with the Reprojector class reprojector = reproj . Reprojector () reprojector <satip.reproj.Reprojector at 0x28f14995100> From which the reproject method can be called, the default method that will be used is through pyresample %% capture -- no - stdout %% time ds_reproj = reprojector . reproject ( native_fp ) Wall time: 5.58 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Attributes: (0) It's also possible to use the functional api, e.g. for our task we could have used full_scene_pyresample to achieve the same results. %% capture -- no - stdout %% time ds_reproj = reproj . full_scene_pyresample ( native_fp ) Wall time: 4.98 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Attributes: (0) Alongside pyresample its also possible to use pyinterp which can be faster when the dataset has fewer layers. When using pyinterp we have to provide the coordinates of the new grid as well as the coordinates that grid has in the original CRS. %% capture -- no - stdout %% time new_coords_fp = f '../data/intermediate/reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) Wall time: 16.5 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * x (x) float64 4.388e+06 4.384e+06 ... -3.088e+06 * y (y) float64 1.692e+06 1.696e+06 ... 9.012e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float64 nan nan nan ... nan nan nan xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) x (x) float64 4.388e+06 4.384e+06 ... -3.088e+06 array([ 4388000., 4384000., 4380000., ..., -3080000., -3084000., -3088000.]) y (y) float64 1.692e+06 1.696e+06 ... 9.012e+06 array([1692000., 1696000., 1700000., ..., 9004000., 9008000., 9012000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float64 nan nan nan nan ... nan nan nan nan orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] array([[[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., ... ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]]]) Attributes: (0)","title":"Reprojecting"},{"location":"102_reprojecting/#reprojecting","text":"from satip import reproj import matplotlib.pyplot as plt import cartopy.crs as ccrs import os","title":"Reprojecting"},{"location":"102_reprojecting/#user-inputs","text":"We have to specify the directory where the data native filepaths are located data_dir = '../data/raw'","title":"User Inputs"},{"location":"102_reprojecting/#loading-the-scene","text":"We'll then load the file using the reproj library native_fps = sorted ([ f ' { data_dir } / { f } ' for f in os . listdir ( data_dir ) if '.nat' in f ]) native_fp = native_fps [ 0 ] scene = reproj . load_scene ( native_fp ) scene . load ([ 'HRV' ]) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() Next we'll visualise the data in the HRV layer. In this particular image it looks like we've caught a period where the satellite is slightly off-kilter. Fortunately the area definition we create accounts for periods when this occurs. seviri = reproj . get_seviri_area_def ( native_fp ) seviri_crs = seviri . to_cartopy_crs () # Plotting fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = seviri_crs ) scene [ 'HRV' ] . plot . imshow ( ax = ax , add_colorbar = False , cmap = 'magma' , vmin = 0 , vmax = 50 ) ax . set_title ( '' ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\pyproj\\crs\\crs.py:543: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems proj_string = self.to_proj4() <cartopy.mpl.feature_artist.FeatureArtist at 0x28f1fdd6970>","title":"Loading the Scene"},{"location":"102_reprojecting/#reprojection","text":"The main way to carry out a reprojection is with the Reprojector class reprojector = reproj . Reprojector () reprojector <satip.reproj.Reprojector at 0x28f14995100> From which the reproject method can be called, the default method that will be used is through pyresample %% capture -- no - stdout %% time ds_reproj = reprojector . reproject ( native_fp ) Wall time: 5.58 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Attributes: (0) It's also possible to use the functional api, e.g. for our task we could have used full_scene_pyresample to achieve the same results. %% capture -- no - stdout %% time ds_reproj = reproj . full_scene_pyresample ( native_fp ) Wall time: 4.98 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float32 dask.array<chunksize=(1, 1831, 1870), meta=np.ndarray> orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] Array Chunk Bytes 164.35 MB 13.70 MB Shape (12, 1831, 1870) (1, 1831, 1870) Count 1335 Tasks 12 Chunks Type float32 numpy.ndarray 1870 1831 12 Attributes: (0) Alongside pyresample its also possible to use pyinterp which can be faster when the dataset has fewer layers. When using pyinterp we have to provide the coordinates of the new grid as well as the coordinates that grid has in the original CRS. %% capture -- no - stdout %% time new_coords_fp = f '../data/intermediate/reproj_coords_TM_4km.csv' new_grid_fp = '../data/intermediate/new_grid_4km_TM.json' reprojector = reproj . Reprojector ( new_coords_fp , new_grid_fp ) ds_reproj = reprojector . reproject ( native_fp , reproj_library = 'pyinterp' ) Wall time: 16.5 s ds_reproj /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (variable: 12, x: 1870, y: 1831) Coordinates: * x (x) float64 4.388e+06 4.384e+06 ... -3.088e+06 * y (y) float64 1.692e+06 1.696e+06 ... 9.012e+06 * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' Data variables: stacked_eumetsat_data (variable, y, x) float64 nan nan nan ... nan nan nan xarray.Dataset Dimensions: variable : 12 x : 1870 y : 1831 Coordinates: (3) x (x) float64 4.388e+06 4.384e+06 ... -3.088e+06 array([ 4388000., 4384000., 4380000., ..., -3080000., -3084000., -3088000.]) y (y) float64 1.692e+06 1.696e+06 ... 9.012e+06 array([1692000., 1696000., 1700000., ..., 9004000., 9008000., 9012000.]) variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) Data variables: (1) stacked_eumetsat_data (variable, y, x) float64 nan nan nan nan ... nan nan nan nan orbital_parameters : {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0} sun_earth_distance_correction_applied : True sun_earth_distance_correction_factor : 0.9697642568677852 units : % wavelength : 0.7\u00e2\u20ac\u00af\u00c2\u00b5m\u00c2 (0.5-0.9\u00e2\u20ac\u00af\u00c2\u00b5m) standard_name : toa_bidirectional_reflectance platform_name : Meteosat-9 sensor : seviri start_time : 2020-12-08 09:00:08.206321 end_time : 2020-12-08 09:05:08.329479 area : Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (3164925.147, 5571248.3904, -2403822.9075, 1394687.3495) name : HRV resolution : 1000.134348869 calibration : reflectance modifiers : () _satpy_id : DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()) ancillary_variables : [] array([[[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., ... ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]]]) Attributes: (0)","title":"Reprojection"},{"location":"103_loading/","text":"Loading from Zarr \u00b6 from satip import io import matplotlib.pyplot as plt import cartopy.crs as ccrs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.32rows/s] User Inputs \u00b6 We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16' Loading Data \u00b6 Then the satip wrapper for loading data will generate an xarray Dataset ds = io . load_from_zarr_bucket ( zarr_bucket ) ds /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (time: 131, variable: 12, x: 1870, y: 1831) Coordinates: * time (time) datetime64[ns] 2020-12-16T15:19:15 ... 2020... * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 Data variables: stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> xarray.Dataset Dimensions: time : 131 variable : 12 x : 1870 y : 1831 Coordinates: (4) time (time) datetime64[ns] 2020-12-16T15:19:15 ... 2020-12-... array(['2020-12-16T15:19:15.000000000', '2020-12-16T15:24:16.000000000', '2020-12-16T15:29:17.000000000', '2020-12-16T15:34:18.000000000', '2020-12-16T15:39:18.000000000', '2020-12-16T15:44:18.000000000', '2020-12-16T15:49:18.000000000', '2020-12-16T15:54:16.000000000', '2020-12-16T15:59:15.000000000', '2020-12-16T16:04:13.000000000', '2020-12-16T16:14:13.000000000', '2020-12-16T16:19:13.000000000', '2020-12-16T16:24:14.000000000', '2020-12-16T16:29:15.000000000', '2020-12-16T16:39:16.000000000', '2020-12-16T16:44:16.000000000', '2020-12-16T16:49:16.000000000', '2020-12-16T16:54:16.000000000', '2020-12-16T16:59:15.000000000', '2020-12-16T17:04:15.000000000', '2020-12-16T17:09:15.000000000', '2020-12-16T17:19:15.000000000', '2020-12-16T17:24:16.000000000', '2020-12-16T17:29:17.000000000', '2020-12-16T17:34:18.000000000', '2020-12-16T17:39:18.000000000', '2020-12-16T21:44:18.000000000', '2020-12-16T21:54:16.000000000', '2020-12-16T21:59:16.000000000', '2020-12-16T22:04:16.000000000', '2020-12-16T22:09:16.000000000', '2020-12-16T22:14:16.000000000', '2020-12-16T22:19:15.000000000', '2020-12-16T23:24:16.000000000', '2020-12-16T23:39:18.000000000', '2020-12-17T00:29:15.000000000', '2020-12-17T00:34:15.000000000', '2020-12-17T00:39:15.000000000', '2020-12-17T00:44:15.000000000', '2020-12-17T00:49:15.000000000', '2020-12-17T00:54:16.000000000', '2020-12-17T01:04:15.000000000', '2020-12-17T01:09:15.000000000', '2020-12-17T01:14:15.000000000', '2020-12-17T01:19:15.000000000', '2020-12-17T01:24:16.000000000', '2020-12-17T01:34:18.000000000', '2020-12-17T01:39:18.000000000', '2020-12-17T01:44:18.000000000', '2020-12-17T01:49:18.000000000', '2020-12-17T01:54:16.000000000', '2020-12-17T02:04:16.000000000', '2020-12-17T02:09:16.000000000', '2020-12-17T02:14:16.000000000', '2020-12-17T02:19:15.000000000', '2020-12-17T02:24:15.000000000', '2020-12-17T02:34:15.000000000', '2020-12-17T02:39:15.000000000', '2020-12-17T02:44:15.000000000', '2020-12-17T02:49:15.000000000', '2020-12-17T02:54:16.000000000', '2020-12-17T03:04:15.000000000', '2020-12-17T03:09:15.000000000', '2020-12-17T03:14:15.000000000', '2020-12-17T03:19:15.000000000', '2020-12-17T03:29:17.000000000', '2020-12-17T03:34:18.000000000', '2020-12-17T03:39:18.000000000', '2020-12-17T03:44:18.000000000', '2020-12-17T03:49:18.000000000', '2020-12-17T03:54:16.000000000', '2020-12-17T04:04:16.000000000', '2020-12-17T04:09:16.000000000', '2020-12-17T04:14:16.000000000', '2020-12-17T04:19:15.000000000', '2020-12-17T04:24:15.000000000', '2020-12-17T04:34:15.000000000', '2020-12-17T04:39:15.000000000', '2020-12-17T04:44:15.000000000', '2020-12-17T04:49:15.000000000', '2020-12-17T04:59:15.000000000', '2020-12-17T05:04:15.000000000', '2020-12-17T05:09:15.000000000', '2020-12-17T05:14:15.000000000', '2020-12-17T05:19:15.000000000', '2020-12-17T05:29:17.000000000', '2020-12-17T05:34:18.000000000', '2020-12-17T05:39:18.000000000', '2020-12-17T05:44:18.000000000', '2020-12-17T05:49:18.000000000', '2020-12-17T05:54:16.000000000', '2020-12-17T06:04:16.000000000', '2020-12-17T06:09:16.000000000', '2020-12-17T06:14:16.000000000', '2020-12-17T06:19:16.000000000', '2020-12-17T06:29:15.000000000', '2020-12-17T06:34:15.000000000', '2020-12-17T06:39:15.000000000', '2020-12-17T06:44:15.000000000', '2020-12-17T06:49:15.000000000', '2020-12-17T06:54:16.000000000', '2020-12-17T07:04:15.000000000', '2020-12-17T07:09:15.000000000', '2020-12-17T07:14:15.000000000', '2020-12-17T07:19:15.000000000', '2020-12-17T07:24:16.000000000', '2020-12-17T07:34:18.000000000', '2020-12-17T07:39:18.000000000', '2020-12-17T07:44:18.000000000', '2020-12-17T07:49:18.000000000', '2020-12-17T07:54:16.000000000', '2020-12-17T08:04:14.000000000', '2020-12-17T08:09:13.000000000', '2020-12-17T08:14:13.000000000', '2020-12-17T08:19:13.000000000', '2020-12-17T08:29:15.000000000', '2020-12-17T08:34:16.000000000', '2020-12-17T08:39:16.000000000', '2020-12-17T08:44:16.000000000', '2020-12-17T08:49:16.000000000', '2020-12-17T08:54:16.000000000', '2020-12-17T09:04:15.000000000', '2020-12-17T09:09:15.000000000', '2020-12-17T09:14:15.000000000', '2020-12-17T09:19:15.000000000', '2020-12-17T09:24:16.000000000', '2020-12-17T09:34:18.000000000', '2020-12-17T09:39:18.000000000', '2020-12-17T09:44:18.000000000', '2020-12-17T09:49:18.000000000', '2020-12-17T09:54:16.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Data variables: (1) stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9680594019679534, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2020, 12, 16, 15, 15, 8, 939946), 'end_time': datetime.datetime(2020, 12, 16, 15, 20, 9, 986974), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2806877.0501, 5571248.3904, -2761871.0044, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Array Chunk Bytes 10.76 GB 246.53 MB Shape (131, 1870, 1831, 12) (36, 1870, 1831, 1) Count 49 Tasks 48 Chunks Type int16 numpy.ndarray 131 1 12 1831 1870 Attributes: (0) We can then index this as we would any other xarray object da_HRV_sample = ds [ 'stacked_eumetsat_data' ] . isel ( time = 0 ) . sel ( variable = 'HRV' ) da_HRV_sample /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (x: 1870, y: 1831)> dask.array<getitem, shape=(1870, 1831), dtype=int16, chunksize=(1870, 1831), chunktype=numpy.ndarray> Coordinates: time datetime64[ns] 2020-12-16T15:19:15 variable <U3 'HRV' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' x : 1870 y : 1831 dask.array<chunksize=(1870, 1831), meta=np.ndarray> Array Chunk Bytes 6.85 MB 6.85 MB Shape (1870, 1831) (1870, 1831) Count 62 Tasks 1 Chunks Type int16 numpy.ndarray 1831 1870 Coordinates: (4) time () datetime64[ns] 2020-12-16T15:19:15 array('2020-12-16T15:19:15.000000000', dtype='datetime64[ns]') variable () <U3 'HRV' array('HRV', dtype='<U3') x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9680594019679534, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2020, 12, 16, 15, 15, 8, 939946), 'end_time': datetime.datetime(2020, 12, 16, 15, 20, 9, 986974), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2806877.0501, 5571248.3904, -2761871.0044, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} As well as visualise it, here we'll use cartopy to plot the data with a coastline overlay. The darker area on the right hand side of the image are the areas where the sun has already set. fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_HRV_sample . T . plot . imshow ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-8-5badebb6746d>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x201ef3a5b20>","title":"Loading from Zarr"},{"location":"103_loading/#loading-from-zarr","text":"from satip import io import matplotlib.pyplot as plt import cartopy.crs as ccrs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.32rows/s]","title":"Loading from Zarr"},{"location":"103_loading/#user-inputs","text":"We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16'","title":"User Inputs"},{"location":"103_loading/#loading-data","text":"Then the satip wrapper for loading data will generate an xarray Dataset ds = io . load_from_zarr_bucket ( zarr_bucket ) ds /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (time: 131, variable: 12, x: 1870, y: 1831) Coordinates: * time (time) datetime64[ns] 2020-12-16T15:19:15 ... 2020... * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 Data variables: stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> xarray.Dataset Dimensions: time : 131 variable : 12 x : 1870 y : 1831 Coordinates: (4) time (time) datetime64[ns] 2020-12-16T15:19:15 ... 2020-12-... array(['2020-12-16T15:19:15.000000000', '2020-12-16T15:24:16.000000000', '2020-12-16T15:29:17.000000000', '2020-12-16T15:34:18.000000000', '2020-12-16T15:39:18.000000000', '2020-12-16T15:44:18.000000000', '2020-12-16T15:49:18.000000000', '2020-12-16T15:54:16.000000000', '2020-12-16T15:59:15.000000000', '2020-12-16T16:04:13.000000000', '2020-12-16T16:14:13.000000000', '2020-12-16T16:19:13.000000000', '2020-12-16T16:24:14.000000000', '2020-12-16T16:29:15.000000000', '2020-12-16T16:39:16.000000000', '2020-12-16T16:44:16.000000000', '2020-12-16T16:49:16.000000000', '2020-12-16T16:54:16.000000000', '2020-12-16T16:59:15.000000000', '2020-12-16T17:04:15.000000000', '2020-12-16T17:09:15.000000000', '2020-12-16T17:19:15.000000000', '2020-12-16T17:24:16.000000000', '2020-12-16T17:29:17.000000000', '2020-12-16T17:34:18.000000000', '2020-12-16T17:39:18.000000000', '2020-12-16T21:44:18.000000000', '2020-12-16T21:54:16.000000000', '2020-12-16T21:59:16.000000000', '2020-12-16T22:04:16.000000000', '2020-12-16T22:09:16.000000000', '2020-12-16T22:14:16.000000000', '2020-12-16T22:19:15.000000000', '2020-12-16T23:24:16.000000000', '2020-12-16T23:39:18.000000000', '2020-12-17T00:29:15.000000000', '2020-12-17T00:34:15.000000000', '2020-12-17T00:39:15.000000000', '2020-12-17T00:44:15.000000000', '2020-12-17T00:49:15.000000000', '2020-12-17T00:54:16.000000000', '2020-12-17T01:04:15.000000000', '2020-12-17T01:09:15.000000000', '2020-12-17T01:14:15.000000000', '2020-12-17T01:19:15.000000000', '2020-12-17T01:24:16.000000000', '2020-12-17T01:34:18.000000000', '2020-12-17T01:39:18.000000000', '2020-12-17T01:44:18.000000000', '2020-12-17T01:49:18.000000000', '2020-12-17T01:54:16.000000000', '2020-12-17T02:04:16.000000000', '2020-12-17T02:09:16.000000000', '2020-12-17T02:14:16.000000000', '2020-12-17T02:19:15.000000000', '2020-12-17T02:24:15.000000000', '2020-12-17T02:34:15.000000000', '2020-12-17T02:39:15.000000000', '2020-12-17T02:44:15.000000000', '2020-12-17T02:49:15.000000000', '2020-12-17T02:54:16.000000000', '2020-12-17T03:04:15.000000000', '2020-12-17T03:09:15.000000000', '2020-12-17T03:14:15.000000000', '2020-12-17T03:19:15.000000000', '2020-12-17T03:29:17.000000000', '2020-12-17T03:34:18.000000000', '2020-12-17T03:39:18.000000000', '2020-12-17T03:44:18.000000000', '2020-12-17T03:49:18.000000000', '2020-12-17T03:54:16.000000000', '2020-12-17T04:04:16.000000000', '2020-12-17T04:09:16.000000000', '2020-12-17T04:14:16.000000000', '2020-12-17T04:19:15.000000000', '2020-12-17T04:24:15.000000000', '2020-12-17T04:34:15.000000000', '2020-12-17T04:39:15.000000000', '2020-12-17T04:44:15.000000000', '2020-12-17T04:49:15.000000000', '2020-12-17T04:59:15.000000000', '2020-12-17T05:04:15.000000000', '2020-12-17T05:09:15.000000000', '2020-12-17T05:14:15.000000000', '2020-12-17T05:19:15.000000000', '2020-12-17T05:29:17.000000000', '2020-12-17T05:34:18.000000000', '2020-12-17T05:39:18.000000000', '2020-12-17T05:44:18.000000000', '2020-12-17T05:49:18.000000000', '2020-12-17T05:54:16.000000000', '2020-12-17T06:04:16.000000000', '2020-12-17T06:09:16.000000000', '2020-12-17T06:14:16.000000000', '2020-12-17T06:19:16.000000000', '2020-12-17T06:29:15.000000000', '2020-12-17T06:34:15.000000000', '2020-12-17T06:39:15.000000000', '2020-12-17T06:44:15.000000000', '2020-12-17T06:49:15.000000000', '2020-12-17T06:54:16.000000000', '2020-12-17T07:04:15.000000000', '2020-12-17T07:09:15.000000000', '2020-12-17T07:14:15.000000000', '2020-12-17T07:19:15.000000000', '2020-12-17T07:24:16.000000000', '2020-12-17T07:34:18.000000000', '2020-12-17T07:39:18.000000000', '2020-12-17T07:44:18.000000000', '2020-12-17T07:49:18.000000000', '2020-12-17T07:54:16.000000000', '2020-12-17T08:04:14.000000000', '2020-12-17T08:09:13.000000000', '2020-12-17T08:14:13.000000000', '2020-12-17T08:19:13.000000000', '2020-12-17T08:29:15.000000000', '2020-12-17T08:34:16.000000000', '2020-12-17T08:39:16.000000000', '2020-12-17T08:44:16.000000000', '2020-12-17T08:49:16.000000000', '2020-12-17T08:54:16.000000000', '2020-12-17T09:04:15.000000000', '2020-12-17T09:09:15.000000000', '2020-12-17T09:14:15.000000000', '2020-12-17T09:19:15.000000000', '2020-12-17T09:24:16.000000000', '2020-12-17T09:34:18.000000000', '2020-12-17T09:39:18.000000000', '2020-12-17T09:44:18.000000000', '2020-12-17T09:49:18.000000000', '2020-12-17T09:54:16.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Data variables: (1) stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9680594019679534, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2020, 12, 16, 15, 15, 8, 939946), 'end_time': datetime.datetime(2020, 12, 16, 15, 20, 9, 986974), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2806877.0501, 5571248.3904, -2761871.0044, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Array Chunk Bytes 10.76 GB 246.53 MB Shape (131, 1870, 1831, 12) (36, 1870, 1831, 1) Count 49 Tasks 48 Chunks Type int16 numpy.ndarray 131 1 12 1831 1870 Attributes: (0) We can then index this as we would any other xarray object da_HRV_sample = ds [ 'stacked_eumetsat_data' ] . isel ( time = 0 ) . sel ( variable = 'HRV' ) da_HRV_sample /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (x: 1870, y: 1831)> dask.array<getitem, shape=(1870, 1831), dtype=int16, chunksize=(1870, 1831), chunktype=numpy.ndarray> Coordinates: time datetime64[ns] 2020-12-16T15:19:15 variable <U3 'HRV' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' x : 1870 y : 1831 dask.array<chunksize=(1870, 1831), meta=np.ndarray> Array Chunk Bytes 6.85 MB 6.85 MB Shape (1870, 1831) (1870, 1831) Count 62 Tasks 1 Chunks Type int16 numpy.ndarray 1831 1870 Coordinates: (4) time () datetime64[ns] 2020-12-16T15:19:15 array('2020-12-16T15:19:15.000000000', dtype='datetime64[ns]') variable () <U3 'HRV' array('HRV', dtype='<U3') x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9680594019679534, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2020, 12, 16, 15, 15, 8, 939946), 'end_time': datetime.datetime(2020, 12, 16, 15, 20, 9, 986974), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2806877.0501, 5571248.3904, -2761871.0044, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} As well as visualise it, here we'll use cartopy to plot the data with a coastline overlay. The darker area on the right hand side of the image are the areas where the sun has already set. fig = plt . figure ( dpi = 250 , figsize = ( 10 , 10 )) ax = plt . axes ( projection = ccrs . TransverseMercator ()) da_HRV_sample . T . plot . imshow ( ax = ax , cmap = 'magma' , vmin =- 200 , vmax = 400 ) ax . coastlines ( resolution = '50m' , alpha = 0.8 , color = 'white' ) <ipython-input-8-5badebb6746d>:2: UserWarning: The default value for the *approx* keyword argument to TransverseMercator will change from True to False after 0.18. ax = plt.axes(projection=ccrs.TransverseMercator()) <cartopy.mpl.feature_artist.FeatureArtist at 0x201ef3a5b20>","title":"Loading Data"},{"location":"104_analysis/","text":"Loading from Zarr \u00b6 from satip import io import matplotlib.pyplot as plt import cartopy.crs as ccrs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.29rows/s] User Inputs \u00b6 We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16' Loading Data \u00b6 Then the satip wrapper for loading data will generate an xarray Dataset ds = io . load_from_zarr_bucket ( zarr_bucket ) ds /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (time: 924, variable: 12, x: 1870, y: 1831) Coordinates: * time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021... * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 Data variables: stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> xarray.Dataset Dimensions: time : 924 variable : 12 x : 1870 y : 1831 Coordinates: (4) time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-... array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', ..., '2021-01-21T22:14:15.000000000', '2021-01-21T22:19:15.000000000', '2021-01-21T22:24:16.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Data variables: (1) stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9680361623200268, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2020, 12, 16, 18, 35, 8, 985163), 'end_time': datetime.datetime(2020, 12, 16, 18, 40, 8, 829133), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2792875.1692, 5571248.3904, -2775872.8853, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Array Chunk Bytes 75.93 GB 246.53 MB Shape (924, 1870, 1831, 12) (36, 1870, 1831, 1) Count 313 Tasks 312 Chunks Type int16 numpy.ndarray 924 1 12 1831 1870 Attributes: (0) We can then index this as we would any other xarray object da_HRV_sample = ds [ 'stacked_eumetsat_data' ] . isel ( time = slice ( 0 , 100 )) . sel ( variable = 'HRV' ) da_HRV_sample /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 100, x: 1870, y: 1831)> dask.array<getitem, shape=(100, 1870, 1831), dtype=int16, chunksize=(36, 1870, 1831), chunktype=numpy.ndarray> Coordinates: * time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-07T20:09:16 variable <U3 'HRV' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 100 x : 1870 y : 1831 dask.array<chunksize=(36, 1870, 1831), meta=np.ndarray> Array Chunk Bytes 684.79 MB 246.53 MB Shape (100, 1870, 1831) (36, 1870, 1831) Count 352 Tasks 3 Chunks Type int16 numpy.ndarray 1831 1870 100 Coordinates: (4) time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-... array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', '2021-01-07T12:14:15.000000000', '2021-01-07T12:19:15.000000000', '2021-01-07T12:24:16.000000000', '2021-01-07T12:29:17.000000000', '2021-01-07T12:34:19.000000000', '2021-01-07T12:39:18.000000000', '2021-01-07T12:44:18.000000000', '2021-01-07T12:49:18.000000000', '2021-01-07T12:54:17.000000000', '2021-01-07T13:09:16.000000000', '2021-01-07T13:14:16.000000000', '2021-01-07T13:39:16.000000000', '2021-01-07T13:49:15.000000000', '2021-01-07T13:54:15.000000000', '2021-01-07T14:04:15.000000000', '2021-01-07T14:09:15.000000000', '2021-01-07T14:14:15.000000000', '2021-01-07T14:19:14.000000000', '2021-01-07T14:24:16.000000000', '2021-01-07T14:29:17.000000000', '2021-01-07T14:34:18.000000000', '2021-01-07T14:39:18.000000000', '2021-01-07T14:44:17.000000000', '2021-01-07T14:49:17.000000000', '2021-01-07T14:54:17.000000000', '2021-01-07T14:59:17.000000000', '2021-01-07T15:04:17.000000000', '2021-01-07T15:09:17.000000000', '2021-01-07T13:29:16.000000000', '2021-01-07T13:34:16.000000000', '2021-01-07T13:44:15.000000000', '2021-01-07T13:59:15.000000000', '2021-01-07T15:14:17.000000000', '2021-01-07T15:19:16.000000000', '2021-01-07T15:24:16.000000000', '2021-01-07T15:29:16.000000000', '2021-01-07T15:34:16.000000000', '2021-01-07T15:39:16.000000000', '2021-01-07T15:44:16.000000000', '2021-01-07T15:49:16.000000000', '2021-01-07T15:54:15.000000000', '2021-01-07T15:59:15.000000000', '2021-01-07T16:04:15.000000000', '2021-01-07T16:09:15.000000000', '2021-01-07T16:14:15.000000000', '2021-01-07T16:19:15.000000000', '2021-01-07T16:24:16.000000000', '2021-01-07T16:29:17.000000000', '2021-01-07T16:34:18.000000000', '2021-01-07T16:39:18.000000000', '2021-01-07T16:44:18.000000000', '2021-01-07T16:49:18.000000000', '2021-01-07T17:14:16.000000000', '2021-01-07T17:19:16.000000000', '2021-01-07T17:24:15.000000000', '2021-01-07T17:34:15.000000000', '2021-01-07T17:39:15.000000000', '2021-01-07T17:44:15.000000000', '2021-01-07T17:49:15.000000000', '2021-01-07T17:54:16.000000000', '2021-01-07T17:59:16.000000000', '2021-01-07T18:04:16.000000000', '2021-01-07T18:09:15.000000000', '2021-01-07T18:14:15.000000000', '2021-01-07T18:19:15.000000000', '2021-01-07T18:04:16.000000000', '2021-01-07T18:09:15.000000000', '2021-01-07T18:14:15.000000000', '2021-01-07T18:19:15.000000000', '2021-01-07T18:24:15.000000000', '2021-01-07T18:34:15.000000000', '2021-01-07T18:39:15.000000000', '2021-01-07T18:44:14.000000000', '2021-01-07T18:49:14.000000000', '2021-01-07T18:54:15.000000000', '2021-01-07T19:04:15.000000000', '2021-01-07T19:09:15.000000000', '2021-01-07T19:14:15.000000000', '2021-01-07T19:19:15.000000000', '2021-01-07T19:24:16.000000000', '2021-01-07T19:29:17.000000000', '2021-01-07T19:29:17.000000000', '2021-01-07T19:34:18.000000000', '2021-01-07T19:34:18.000000000', '2021-01-07T19:39:18.000000000', '2021-01-07T19:44:18.000000000', '2021-01-07T19:49:17.000000000', '2021-01-07T19:54:16.000000000', '2021-01-07T17:09:16.000000000', '2021-01-07T17:29:15.000000000', '2021-01-07T18:29:15.000000000', '2021-01-07T18:59:15.000000000', '2021-01-07T19:59:16.000000000', '2021-01-07T20:04:16.000000000', '2021-01-07T20:09:16.000000000', '2021-01-07T20:04:16.000000000', '2021-01-07T20:09:16.000000000'], dtype='datetime64[ns]') variable () <U3 'HRV' array('HRV', dtype='<U3') x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9680361623200268, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2020, 12, 16, 18, 35, 8, 985163), 'end_time': datetime.datetime(2020, 12, 16, 18, 40, 8, 829133), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2792875.1692, 5571248.3904, -2775872.8853, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} da_HRV_sample . interp ( x = , y = )","title":"Loading from Zarr"},{"location":"104_analysis/#loading-from-zarr","text":"from satip import io import matplotlib.pyplot as plt import cartopy.crs as ccrs C:\\Users\\Ayrto\\anaconda3\\envs\\satip_dev\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/ warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING) Downloading: 100%|\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6\u00e2\u2013\u02c6| 1/1 [00:00<00:00, 1.29rows/s]","title":"Loading from Zarr"},{"location":"104_analysis/#user-inputs","text":"We have to specify the bucket where the data is located zarr_bucket = 'solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16'","title":"User Inputs"},{"location":"104_analysis/#loading-data","text":"Then the satip wrapper for loading data will generate an xarray Dataset ds = io . load_from_zarr_bucket ( zarr_bucket ) ds /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.Dataset> Dimensions: (time: 924, variable: 12, x: 1870, y: 1831) Coordinates: * time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021... * variable (variable) object 'HRV' 'IR_016' ... 'WV_073' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 Data variables: stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> xarray.Dataset Dimensions: time : 924 variable : 12 x : 1870 y : 1831 Coordinates: (4) time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-... array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', ..., '2021-01-21T22:14:15.000000000', '2021-01-21T22:19:15.000000000', '2021-01-21T22:24:16.000000000'], dtype='datetime64[ns]') variable (variable) object 'HRV' 'IR_016' ... 'WV_073' array(['HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'], dtype=object) x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Data variables: (1) stacked_eumetsat_data (time, x, y, variable) int16 dask.array<chunksize=(36, 1870, 1831, 1), meta=np.ndarray> meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9680361623200268, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2020, 12, 16, 18, 35, 8, 985163), 'end_time': datetime.datetime(2020, 12, 16, 18, 40, 8, 829133), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2792875.1692, 5571248.3904, -2775872.8853, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} Array Chunk Bytes 75.93 GB 246.53 MB Shape (924, 1870, 1831, 12) (36, 1870, 1831, 1) Count 313 Tasks 312 Chunks Type int16 numpy.ndarray 924 1 12 1831 1870 Attributes: (0) We can then index this as we would any other xarray object da_HRV_sample = ds [ 'stacked_eumetsat_data' ] . isel ( time = slice ( 0 , 100 )) . sel ( variable = 'HRV' ) da_HRV_sample /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } html[theme=dark], body.vscode-dark { --xr-font-color0: rgba(255, 255, 255, 1); --xr-font-color2: rgba(255, 255, 255, 0.54); --xr-font-color3: rgba(255, 255, 255, 0.38); --xr-border-color: #1F1F1F; --xr-disabled-color: #515151; --xr-background-color: #111111; --xr-background-color-row-even: #111111; --xr-background-color-row-odd: #313131; } .xr-wrap { display: block; min-width: 300px; max-width: 700px; } .xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u00e2\u2013\u00ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u00e2\u2013\u00bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, .xr-attrs dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } <xarray.DataArray 'stacked_eumetsat_data' (time: 100, x: 1870, y: 1831)> dask.array<getitem, shape=(100, 1870, 1831), dtype=int16, chunksize=(36, 1870, 1831), chunktype=numpy.ndarray> Coordinates: * time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-07T20:09:16 variable <U3 'HRV' * x (x) float64 -3.088e+06 -3.084e+06 ... 4.384e+06 4.388e+06 * y (y) float64 9.012e+06 9.008e+06 9.004e+06 ... 1.696e+06 1.692e+06 Attributes: meta: {'orbital_parameters': {'projection_longitude': 9.5, 'projectio... xarray.DataArray 'stacked_eumetsat_data' time : 100 x : 1870 y : 1831 dask.array<chunksize=(36, 1870, 1831), meta=np.ndarray> Array Chunk Bytes 684.79 MB 246.53 MB Shape (100, 1870, 1831) (36, 1870, 1831) Count 352 Tasks 3 Chunks Type int16 numpy.ndarray 1831 1870 100 Coordinates: (4) time (time) datetime64[ns] 2020-12-16T18:40:08 ... 2021-01-... array(['2020-12-16T18:40:08.000000000', '2021-01-07T12:04:16.000000000', '2021-01-07T12:09:16.000000000', '2021-01-07T12:14:15.000000000', '2021-01-07T12:19:15.000000000', '2021-01-07T12:24:16.000000000', '2021-01-07T12:29:17.000000000', '2021-01-07T12:34:19.000000000', '2021-01-07T12:39:18.000000000', '2021-01-07T12:44:18.000000000', '2021-01-07T12:49:18.000000000', '2021-01-07T12:54:17.000000000', '2021-01-07T13:09:16.000000000', '2021-01-07T13:14:16.000000000', '2021-01-07T13:39:16.000000000', '2021-01-07T13:49:15.000000000', '2021-01-07T13:54:15.000000000', '2021-01-07T14:04:15.000000000', '2021-01-07T14:09:15.000000000', '2021-01-07T14:14:15.000000000', '2021-01-07T14:19:14.000000000', '2021-01-07T14:24:16.000000000', '2021-01-07T14:29:17.000000000', '2021-01-07T14:34:18.000000000', '2021-01-07T14:39:18.000000000', '2021-01-07T14:44:17.000000000', '2021-01-07T14:49:17.000000000', '2021-01-07T14:54:17.000000000', '2021-01-07T14:59:17.000000000', '2021-01-07T15:04:17.000000000', '2021-01-07T15:09:17.000000000', '2021-01-07T13:29:16.000000000', '2021-01-07T13:34:16.000000000', '2021-01-07T13:44:15.000000000', '2021-01-07T13:59:15.000000000', '2021-01-07T15:14:17.000000000', '2021-01-07T15:19:16.000000000', '2021-01-07T15:24:16.000000000', '2021-01-07T15:29:16.000000000', '2021-01-07T15:34:16.000000000', '2021-01-07T15:39:16.000000000', '2021-01-07T15:44:16.000000000', '2021-01-07T15:49:16.000000000', '2021-01-07T15:54:15.000000000', '2021-01-07T15:59:15.000000000', '2021-01-07T16:04:15.000000000', '2021-01-07T16:09:15.000000000', '2021-01-07T16:14:15.000000000', '2021-01-07T16:19:15.000000000', '2021-01-07T16:24:16.000000000', '2021-01-07T16:29:17.000000000', '2021-01-07T16:34:18.000000000', '2021-01-07T16:39:18.000000000', '2021-01-07T16:44:18.000000000', '2021-01-07T16:49:18.000000000', '2021-01-07T17:14:16.000000000', '2021-01-07T17:19:16.000000000', '2021-01-07T17:24:15.000000000', '2021-01-07T17:34:15.000000000', '2021-01-07T17:39:15.000000000', '2021-01-07T17:44:15.000000000', '2021-01-07T17:49:15.000000000', '2021-01-07T17:54:16.000000000', '2021-01-07T17:59:16.000000000', '2021-01-07T18:04:16.000000000', '2021-01-07T18:09:15.000000000', '2021-01-07T18:14:15.000000000', '2021-01-07T18:19:15.000000000', '2021-01-07T18:04:16.000000000', '2021-01-07T18:09:15.000000000', '2021-01-07T18:14:15.000000000', '2021-01-07T18:19:15.000000000', '2021-01-07T18:24:15.000000000', '2021-01-07T18:34:15.000000000', '2021-01-07T18:39:15.000000000', '2021-01-07T18:44:14.000000000', '2021-01-07T18:49:14.000000000', '2021-01-07T18:54:15.000000000', '2021-01-07T19:04:15.000000000', '2021-01-07T19:09:15.000000000', '2021-01-07T19:14:15.000000000', '2021-01-07T19:19:15.000000000', '2021-01-07T19:24:16.000000000', '2021-01-07T19:29:17.000000000', '2021-01-07T19:29:17.000000000', '2021-01-07T19:34:18.000000000', '2021-01-07T19:34:18.000000000', '2021-01-07T19:39:18.000000000', '2021-01-07T19:44:18.000000000', '2021-01-07T19:49:17.000000000', '2021-01-07T19:54:16.000000000', '2021-01-07T17:09:16.000000000', '2021-01-07T17:29:15.000000000', '2021-01-07T18:29:15.000000000', '2021-01-07T18:59:15.000000000', '2021-01-07T19:59:16.000000000', '2021-01-07T20:04:16.000000000', '2021-01-07T20:09:16.000000000', '2021-01-07T20:04:16.000000000', '2021-01-07T20:09:16.000000000'], dtype='datetime64[ns]') variable () <U3 'HRV' array('HRV', dtype='<U3') x (x) float64 -3.088e+06 -3.084e+06 ... 4.388e+06 array([-3088000., -3084000., -3080000., ..., 4380000., 4384000., 4388000.]) y (y) float64 9.012e+06 9.008e+06 ... 1.692e+06 array([9012000., 9008000., 9004000., ..., 1700000., 1696000., 1692000.]) Attributes: (1) meta : {'orbital_parameters': {'projection_longitude': 9.5, 'projection_latitude': 0.0, 'projection_altitude': 35785831.0}, 'sun_earth_distance_correction_applied': True, 'sun_earth_distance_correction_factor': 0.9680361623200268, 'units': '%', 'wavelength': WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), 'standard_name': 'toa_bidirectional_reflectance', 'platform_name': 'Meteosat-10', 'sensor': 'seviri', 'start_time': datetime.datetime(2020, 12, 16, 18, 35, 8, 985163), 'end_time': datetime.datetime(2020, 12, 16, 18, 40, 8, 829133), 'area': Area ID: geos_seviri_hrv Description: SEVIRI high resolution channel area Projection ID: seviri_hrv Projection: {'a': '6378169', 'h': '35785831', 'lon_0': '9.5', 'no_defs': 'None', 'proj': 'geos', 'rf': '295.488065897014', 'type': 'crs', 'units': 'm', 'x_0': '0', 'y_0': '0'} Number of columns: 5568 Number of rows: 4176 Area extent: (2792875.1692, 5571248.3904, -2775872.8853, 1394687.3495), 'name': 'HRV', 'resolution': 1000.134348869, 'calibration': 'reflectance', 'modifiers': (), '_satpy_id': DataID(name='HRV', wavelength=WavelengthRange(min=0.5, central=0.7, max=0.9, unit='\u00c2\u00b5m'), resolution=1000.134348869, calibration=<calibration.reflectance>, modifiers=()), 'ancillary_variables': []} da_HRV_sample . interp ( x = , y = )","title":"Loading Data"},{"location":"API/01-parsers/","text":"Parsers \u00b6 ::: satip.parsers","title":"Parsers"},{"location":"API/01-parsers/#parsers","text":"::: satip.parsers","title":"Parsers"},{"location":"about/OCF/","text":"Open Climate Fix \u00b6 Open Climate Fix is a new non-profit research and development lab, totally focused on reducing greenhouse gas emissions as rapidly as possible. Every part of the organisation is designed to maximise climate impact, such as our open and collaborative approach, our rapid prototyping, and our attention on finding scalable & practical solutions. By using an open-source approach, we can draw upon a much larger pool of expertise than any individual company, so combining existing islands of knowledge and accelerating progress. Our approach will be to search for ML (Machine Learning) problems where, if we solve a well-defined ML task, then there is likely to be a large climate impact. Then, for each of these challenges, we will: Collate & release data , and write software tools to make it super-easy for people to consume this data. Run a collaborative \u201cglobal research project\u201d where everyone from 16-year-olds to PhD students to corporate research labs can help solve the ML task (and, over the last 6 weeks, we have received over 300 emails from people who\u2019d love to get involved). Help to put good solutions into production , once the community has developed them, so we can be reducing emissions ASAP. :fontawesome-regular-envelope: Sign up to our newsletter","title":"OCF"},{"location":"about/OCF/#open-climate-fix","text":"Open Climate Fix is a new non-profit research and development lab, totally focused on reducing greenhouse gas emissions as rapidly as possible. Every part of the organisation is designed to maximise climate impact, such as our open and collaborative approach, our rapid prototyping, and our attention on finding scalable & practical solutions. By using an open-source approach, we can draw upon a much larger pool of expertise than any individual company, so combining existing islands of knowledge and accelerating progress. Our approach will be to search for ML (Machine Learning) problems where, if we solve a well-defined ML task, then there is likely to be a large climate impact. Then, for each of these challenges, we will: Collate & release data , and write software tools to make it super-easy for people to consume this data. Run a collaborative \u201cglobal research project\u201d where everyone from 16-year-olds to PhD students to corporate research labs can help solve the ML task (and, over the last 6 weeks, we have received over 300 emails from people who\u2019d love to get involved). Help to put good solutions into production , once the community has developed them, so we can be reducing emissions ASAP. :fontawesome-regular-envelope: Sign up to our newsletter","title":"Open Climate Fix"}]}